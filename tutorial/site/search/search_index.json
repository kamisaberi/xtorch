{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#motivation","title":"Motivation","text":"<p>PyTorch\u2019s C++ library (LibTorch) emerged as a powerful way to use PyTorch outside Python, but after 2019 it became challenging for developers to use it for end-to-end model development. Early on, LibTorch aimed to mirror the high-level Python API, yet many convenient abstractions and examples never fully materialized or were later removed.</p> <p>As of 2020, the C++ API had achieved near feature-parity with Python\u2019s core operations, but it lagged in usability and community support. Fewer contributors focused on C++ meant that only low-level building blocks were provided, with high-level components (e.g. ready-made network architectures, datasets) largely absent. This left C++ practitioners to rewrite common tools from scratch \u2013 implementing standard models or data loaders manually \u2013 which is time-consuming and error-prone.</p> <p>Another factor was PyTorch\u2019s emphasis on the Python-to-C++ workflow. The official recommended path for production was to prototype in Python, then convert models to TorchScript for C++ deployment. This approach deprioritized making the pure C++ experience as friendly as Python\u2019s.</p> <p>As a result, developers who preferred or needed to work in C++ (for integration with existing systems, performance, or deployment constraints) found LibTorch cumbersome. Simple tasks like data augmentation (e.g. random crops or flips) had no built-in support in LibTorch C++. Defining neural network modules in C++ involved boilerplate macros and manual registration, an awkward process compared to Python\u2019s concise syntax. Crucial functionality for model serialization was limited \u2013 for instance, LibTorch could load Python-exported models but not easily export its own models to a portable format.</p> <p>xTorch was created to address this gap. It is a C++ library that extends LibTorch with the high-level abstractions and utilities that were missing or removed after 2019. By building on LibTorch\u2019s robust computational core, xTorch restores ease-of-use without sacrificing performance. The motivation is to empower C++ developers with a productive experience similar to PyTorch in Python \u2013 enabling them to build, train, and deploy models with minimal fuss. In essence, xTorch revives and modernizes the \u201cbatteries-included\u201d ethos for C++ deep learning, providing an all-in-one toolkit where the base library left off.</p>"},{"location":"#design-and-architecture","title":"Design and Architecture","text":"<p>xTorch is architected as a thin layer on top of LibTorch\u2019s C++ API, carefully integrating with it rather than reinventing it. The design follows a modular approach, adding a higher-level API that wraps around LibTorch\u2019s lower-level classes. At its core, xTorch relies on LibTorch for tensor operations, autograd, and neural network primitives \u2013 effectively using LibTorch as the computational engine. The extended library then introduces its own set of C++ classes that encapsulate common patterns (model definitions, training loops, data handling, etc.), providing a cleaner interface to the developer.</p>"},{"location":"#architecture-layers","title":"Architecture Layers","text":"<ul> <li>LibTorch Core (Bottom Layer): Provides <code>torch::Tensor</code>, <code>torch::autograd</code>, <code>torch::nn</code>, optimizers, etc.</li> <li>Extended Abstraction Layer (Middle): Simplified classes inheriting from LibTorch core (e.g., <code>ExtendedModel</code>, <code>Trainer</code>).</li> <li>User Interface (Top Layer): Intuitive APIs and boilerplate-free interaction.</li> </ul>"},{"location":"#modules","title":"Modules","text":"<ul> <li>Model Module: High-level model class extensions.</li> <li>Data Module: Enhanced datasets and DataLoader.</li> <li>Training Module: Training logic, checkpointing, metrics.</li> <li>Utilities Module: Logging, device helpers, summaries.</li> </ul>"},{"location":"#features-and-enhancements","title":"Features and Enhancements","text":"<ul> <li>High-Level Model Classes: <code>XTModule</code>, prebuilt models like <code>ResNetExtended</code>, <code>XTCNN</code>.</li> <li>Simplified Training Loop (Trainer): Full training abstraction with callbacks and metrics.</li> <li>Enhanced Data Handling: <code>ImageFolderDataset</code>, <code>CSVDataset</code>, OpenCV-backed support.</li> <li>Utility Functions: Logging, metrics, summary, device utils.</li> <li>Extended Optimizers: AdamW, RAdam, schedulers, learning rate strategies.</li> <li>Model Serialization &amp; Deployment: <code>save_model()</code>, <code>export_to_jit()</code>, inference helpers.</li> </ul>"},{"location":"#use-cases-and-examples","title":"Use Cases and Examples","text":""},{"location":"#example-cnn-training-pipeline-simplified","title":"Example: CNN Training Pipeline (Simplified)","text":"<pre><code>#include &lt;xtorch/xtorch.hpp&gt;\n\nint main() {\n    std::cout.precision(10);\n    auto dataset = xt::data::datasets::MNIST(\n        \"/home/kami/Documents/temp/\", DataMode::TRAIN, true,\n        {\n            xt::data::transforms::Resize({32, 32}),\n            torch::data::transforms::Normalize&lt;&gt;(0.5, 0.5)\n        }).map(torch::data::transforms::Stack&lt;&gt;());\n\n\n    xt::DataLoader&lt;decltype(dataset)&gt; loader(\n        std::move(dataset),\n        torch::data::DataLoaderOptions().batch_size(64).drop_last(false),\n        true);\n\n    xt::models::LeNet5 model(10);\n    model.to(torch::Device(torch::kCPU));\n    model.train();\n\n    torch::optim::Adam optimizer(model.parameters(), torch::optim::AdamOptions(1e-3));\n\n    xt::Trainer trainer;\n    trainer.set_optimizer(&amp;optimizer)\n            .set_max_epochs(5)\n            .set_loss_fn([](auto output, auto target) {\n                return torch::nll_loss(output, target);\n            });\n\n    trainer.fit&lt;decltype(dataset)&gt;(&amp;model, loader);\n\n    return 0;\n}\n</code></pre>"},{"location":"#example-c-inference-pipeline","title":"Example: C++ Inference Pipeline","text":"<pre><code>auto model = xt::load_model(\"resnet18_script.pt\");\nauto tensor = xt::utils::imageToTensor(\"input.jpg\");\nauto outputs = xt::utils::predict(model, tensor);\nint predictedClass = xt::utils::argmax(outputs);\nstd::cout &lt;&lt; \"Predicted class = \" &lt;&lt; predictedClass &lt;&lt; std::endl;\n</code></pre>"},{"location":"#impact-and-potential-applications","title":"Impact and Potential Applications","text":"<ul> <li>C++ Developers: Enables use of PyTorch-like training without Python.</li> <li>Research in Embedded / HPC: Pure C++ training and deployment possible.</li> <li>Industrial Use: On-device training, edge deployment workflows.</li> <li>Education: Useful for teaching performance-aware ML in C++.</li> <li>Ecosystem Growth: Boosts community contributions, reuse, and experimentation.</li> </ul>"},{"location":"#comparison-with-related-tools","title":"Comparison with Related Tools","text":"Feature LibTorch xTorch PyTorch Lightning (Python) Training Loop Abstraction \u274c \u2705 \u2705 Data Augmentation Built-in \u274c \u2705 \u2705 Built-in Model Zoo Limited \u2705 \u2705 Target Language C++ C++ Python TorchScript Export Limited \u2705 \u2705 <p>xTorch complements PyTorch\u2019s C++ API like PyTorch Lightning does in Python, enabling expressive ML development in C++ with clean, modular code structures.</p>"},{"location":"api/","title":"API","text":""},{"location":"contributing/","title":"Contributing","text":""},{"location":"examples/","title":"Examples","text":""},{"location":"features/","title":"Features","text":""},{"location":"license/","title":"License","text":""},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"api/","title":"Class xt::data::transforms::Compose","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Compose</p> <p>A class to compose multiple tensor transformations into a single callable pipeline. More...</p> <ul> <li><code>#include &lt;compose.h&gt;</code></li> </ul>"},{"location":"api/#public-types","title":"Public Types","text":"Type Name typedef std::function&lt; torch::Tensor(torch::Tensor)&gt; TransformFunc Alias for a transformation function that takes a tensor and returns a tensor."},{"location":"api/#public-functions","title":"Public Functions","text":"Type Name Compose () Default constructor, initializing an empty transformation pipeline. Compose (std::vector&lt; TransformFunc &gt; transforms) Constructs a Compose object with a vector of transformation functions. torch::Tensor operator() (torch::Tensor input) constApplies the sequence of transformations to the input tensor."},{"location":"api/#detailed-description","title":"Detailed Description","text":"<p>The Compose class allows chaining of multiple transformation functions, each operating on a <code>torch::Tensor</code>, into a single operation. It is designed to facilitate preprocessing or augmentation of tensor data (e.g., images) by applying a sequence of transforms in the order they are provided. The transformations are stored as a vector of function objects and applied via the call operator. </p>"},{"location":"api/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"api/#typedef-transformfunc","title":"typedef TransformFunc","text":"<p>Alias for a transformation function that takes a tensor and returns a tensor. </p> <pre><code>using xt::data::transforms::Compose::TransformFunc =  std::function&lt;torch::Tensor(torch::Tensor)&gt;;\n</code></pre> <p>This type alias defines a function signature for transformations that operate on <code>torch::Tensor</code> objects, enabling flexible composition of operations. </p>"},{"location":"api/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"api/#function-compose-12","title":"function Compose [1/2]","text":"<p>Default constructor, initializing an empty transformation pipeline. </p> <pre><code>xt::data::transforms::Compose::Compose () \n</code></pre> <p>Creates a Compose object with no transformations, allowing subsequent addition of transforms if needed. </p>"},{"location":"api/#function-compose-22","title":"function Compose [2/2]","text":"<p>Constructs a Compose object with a vector of transformation functions.</p> <pre><code>xt::data::transforms::Compose::Compose (\n    std::vector&lt; TransformFunc &gt; transforms\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>transforms</code> A vector of TransformFunc objects specifying the sequence of transformations.</li> </ul> <p>Initializes the Compose object with a predefined set of transformations to be applied in order. </p>"},{"location":"api/#function-operator","title":"function operator()","text":"<p>Applies the sequence of transformations to the input tensor. </p> <pre><code>torch::Tensor xt::data::transforms::Compose::operator() (\n    torch::Tensor input\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>input</code> The input tensor to be transformed. </li> </ul> <p>Returns:</p> <p>A tensor resulting from applying all transformations in sequence.</p> <p>This operator applies each transformation in the <code>transforms</code> vector to the input tensor, passing the output of one transformation as the input to the next, and returns the final result. </p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/compose.h</code></p>"},{"location":"api/cpp/core_classes/","title":"core_classes.md","text":""},{"location":"api/cpp/native/","title":"native.md","text":""},{"location":"api/cpp/tensor/","title":"tensor.md","text":""},{"location":"api/python/core/","title":"core.md","text":""},{"location":"api/python/nn/","title":"nn.md","text":""},{"location":"api/python/optim/","title":"optim.md","text":""},{"location":"api/python/utils/","title":"utils.md","text":""},{"location":"community/code_of_conduct/","title":"code_of_conduct.md","text":""},{"location":"community/faq/","title":"faq.md","text":""},{"location":"developer/benchmarks/","title":"benchmarks.md","text":""},{"location":"developer/contributing/","title":"contributing.md","text":""},{"location":"developer/testing/","title":"testing.md","text":""},{"location":"ecosystem/integration/","title":"integration.md","text":""},{"location":"ecosystem/nlp/","title":"nlp.md","text":""},{"location":"ecosystem/vision/","title":"vision.md","text":""},{"location":"getting_started/installation/","title":"xTorch Installation Guide","text":""},{"location":"getting_started/installation/#supported-operating-systems","title":"Supported Operating Systems","text":"<p>xTorch supports the following Linux distributions: - Ubuntu - Linux Mint - Manjaro (Arch-based)</p>"},{"location":"getting_started/installation/#step-1-install-required-packages","title":"Step 1: Install Required Packages","text":""},{"location":"getting_started/installation/#on-ubuntu-linux-mint","title":"On Ubuntu / Linux Mint","text":"<pre><code>sudo apt-get update\nsudo apt-get install -y libcurl4-openssl-dev libopencv-dev zlib1g-dev libssl-dev \\\n    liblzma-dev libarchive-dev libtar-dev libzip-dev libsndfile1-dev \\\n    build-essential cmake git\n</code></pre>"},{"location":"getting_started/installation/#on-manjaro-arch","title":"On Manjaro / Arch","text":"<pre><code>sudo pacman -Syu --needed curl opencv zlib openssl xz libarchive libtar libzip libsndfile base-devel cmake git\n</code></pre>"},{"location":"getting_started/installation/#step-2-download-and-install-libtorch-pytorch-c","title":"Step 2: Download and Install LibTorch (PyTorch C++)","text":"<ol> <li>Go to: https://pytorch.org/get-started/locally/</li> <li>Choose:<ul> <li>Stable</li> <li>Linux</li> <li>Language: C++/Java</li> <li>Compute Platform: CPU or CUDA</li> </ul> </li> <li>Download and extract the <code>libtorch</code> archive:</li> </ol> <pre><code>unzip libtorch-cxx11-abi-shared-with-deps-*.zip -d ~/libtorch\n</code></pre>"},{"location":"getting_started/installation/#optional-set-environment-variables","title":"Optional: Set Environment Variables","text":"<pre><code>export CMAKE_PREFIX_PATH=~/libtorch/libtorch\nexport LD_LIBRARY_PATH=~/libtorch/libtorch/lib:$LD_LIBRARY_PATH\n</code></pre>"},{"location":"getting_started/installation/#step-3-build-xtorch","title":"Step 3: Build xTorch","text":""},{"location":"getting_started/installation/#clone-the-repo","title":"Clone the repo","text":"<pre><code>git clone &lt;your-xTorch-repo-url&gt;\ncd xtorch\n</code></pre>"},{"location":"getting_started/installation/#create-a-build-directory-and-configure","title":"Create a build directory and configure","text":"<pre><code>mkdir build &amp;&amp; cd build\ncmake -DCMAKE_PREFIX_PATH=~/libtorch/libtorch -DCMAKE_BUILD_TYPE=Release ..\n</code></pre>"},{"location":"getting_started/installation/#compile","title":"Compile","text":"<pre><code>make -j$(nproc)\n</code></pre>"},{"location":"getting_started/installation/#step-4-install-xtorch","title":"Step 4: Install xTorch","text":"<pre><code>sudo make install\nsudo ldconfig\n</code></pre>"},{"location":"getting_started/installation/#step-5-use-xtorch-in-your-project","title":"Step 5: Use xTorch in Your Project","text":""},{"location":"getting_started/installation/#with-cmake","title":"With CMake","text":"<pre><code>find_package(xTorch REQUIRED)\ntarget_link_libraries(MyApp PRIVATE xTorch::xTorch)\n</code></pre>"},{"location":"getting_started/installation/#manually-if-no-package-config","title":"Manually (if no package config)","text":"<pre><code>target_include_directories(MyApp PRIVATE /usr/local/include/xtorch)\ntarget_link_libraries(MyApp PRIVATE /usr/local/lib/libxTorch.so)\n</code></pre>"},{"location":"getting_started/installation/#notes","title":"Notes","text":"<ul> <li>Make sure all dependencies are installed.</li> <li>Recompile xTorch if you upgrade major dependencies.</li> <li>Use the correct ABI version of LibTorch for your system (C++11 recommended).</li> </ul> <p>Enjoy building deep learning apps in C++ with xTorch!</p>"},{"location":"getting_started/migration_guide/","title":"migration_guide.md","text":""},{"location":"getting_started/quickstart_tutorial/","title":"quickstart_tutorial.md","text":""},{"location":"tutorials/settings/","title":"Settings","text":""},{"location":"tutorials/advanced/cpp_extensions/","title":"cpp_extensions.md","text":""},{"location":"tutorials/advanced/jit_compilation/","title":"jit_compilation.md","text":""},{"location":"tutorials/basics/custom_layers/","title":"custom_layers.md","text":""},{"location":"tutorials/basics/hello_world/","title":"Hello World","text":""},{"location":"tutorials/basics/working_with_tensors/","title":"working_with_tensors.md","text":""},{"location":"tutorials/intermediate/gpu_acceleration/","title":"gpu_acceleration.md","text":""},{"location":"tutorials/intermediate/mixed_precision/","title":"mixed_precision.md","text":""},{"location":"xTorch/annotated/","title":"Class List","text":"<p>Here are the classes, structs, unions and interfaces with brief descriptions:</p> <ul> <li>struct DatasetArguments </li> <li>class NotImplementedException </li> <li>namespace std </li> <li>namespace torch <ul> <li>namespace data <ul> <li>namespace datasets </li> </ul> </li> <li>namespace ext <ul> <li>namespace media <ul> <li>namespace image </li> <li>namespace opencv <ul> <li>namespace videos </li> </ul> </li> </ul> </li> </ul> </li> <li>namespace nn </li> </ul> </li> <li>namespace xt <ul> <li>class DataLoader </li> <li>class Trainer </li> <li>namespace data <ul> <li>namespace datasets <ul> <li>class AgNews </li> <li>class AmazonReview </li> <li>class AudioDataset </li> <li>class BaseDataset </li> <li>class CIFAR10 </li> <li>class CIFAR100 </li> <li>class CMUArctic </li> <li>class COLA </li> <li>class CREStereo </li> <li>class CSVDataset </li> <li>class Caltech101 </li> <li>class Caltech256 </li> <li>class CarlaStereo </li> <li>class CelebA </li> <li>class Cityscapes </li> <li>class CoNLL2000Chunking </li> <li>class CocoCaptions </li> <li>class CocoDetection </li> <li>class CommonVoice </li> <li>class Country211 </li> <li>class CremaD </li> <li>class DBPedia </li> <li>class DTD </li> <li>class EDFDataset </li> <li>class EMNIST </li> <li>class ESC </li> <li>class ETH3DStereo </li> <li>class EnWik </li> <li>class EuroSAT </li> <li>class FER2013 </li> <li>class FGVCAircraft </li> <li>class FakeData </li> <li>class FallingThingsStereo </li> <li>class FashionMNIST </li> <li>class Flickr30k </li> <li>class Flickr8k </li> <li>class Flowers102 </li> <li>class FlyingChairs </li> <li>class FlyingThings3D </li> <li>class Food101 </li> <li>class GTSRB </li> <li>class GTZAN </li> <li>class HD1K </li> <li>class HMDB51 </li> <li>class IMDB </li> <li>class INaturalist </li> <li>class IWSLT </li> <li>class ImageFolder </li> <li>class ImageNet </li> <li>class Imagenette </li> <li>class InStereo2k </li> <li>class KMNIST </li> <li>class Kinetics </li> <li>class Kitti </li> <li>class Kitti2012Stereo </li> <li>class Kitti2015Stereo </li> <li>class KittiFlow </li> <li>class LFW </li> <li>class LFWPairs </li> <li>class LFWPeople </li> <li>class LSUN </li> <li>class LibriSpeech </li> <li>class LjSpeech </li> <li>class MNIST </li> <li>class MNISTBase </li> <li>class MNLI </li> <li>class MRPC </li> <li>class MULTI </li> <li>class Middlebury2014Stereo </li> <li>class MovingMNIST </li> <li>class Omniglot </li> <li>class OxfordIIITPet </li> <li>class PCAM </li> <li>class PennTreebank </li> <li>class PhotoTour </li> <li>class Places365 </li> <li>class QMNIST </li> <li>class QNLI </li> <li>class QQP </li> <li>class RTE </li> <li>class RenderedSST2 </li> <li>class SBDataset </li> <li>class SBU </li> <li>class SEMEION </li> <li>class SNLI </li> <li>class SST </li> <li>class STL10 </li> <li>class STSB </li> <li>class SUN397 </li> <li>class SVHN </li> <li>class SceneFlowStereo </li> <li>class Sintel </li> <li>class SintelStereo </li> <li>class SogouNews </li> <li>class SpeechCommands </li> <li>class StackedAudioDataset </li> <li>class StackedCSVDataset </li> <li>class StackedEDFDataset </li> <li>class StackedTextDataset </li> <li>class StackedTimeSeriesDataset </li> <li>class StackedVideoDataset </li> <li>class StanfordCars </li> <li>class TIMIT </li> <li>class Tedlium </li> <li>class TensorDataset </li> <li>class TextDataset </li> <li>class TimeSeriesDataset </li> <li>class UCF101 </li> <li>class UDPOS </li> <li>class USPS </li> <li>class UrbanSound </li> <li>class VCTK </li> <li>class VOCDetection </li> <li>class VOCSegmentation </li> <li>class VideoDataset </li> <li>class VoxCeleb </li> <li>class WIDERFace </li> <li>class WMT </li> <li>class WNLI </li> <li>class WikiText </li> <li>class YahooAnswers </li> <li>class YelpReview </li> <li>class YesNo </li> </ul> </li> <li>namespace transforms <ul> <li>struct CenterCrop </li> <li>struct ColorJitter </li> <li>class Compose A class to compose multiple tensor transformations into a single callable pipeline. </li> <li>struct Cutout </li> <li>struct GaussianBlur </li> <li>struct GaussianBlurOpenCV </li> <li>struct GaussianNoise </li> <li>struct Grayscale </li> <li>struct GrayscaleToRGB A functor to convert a grayscale tensor to an RGB tensor. </li> <li>struct HorizontalFlip </li> <li>struct Lambda </li> <li>struct Normalize </li> <li>struct Pad A functor to pad a tensor with a specified padding configuration. </li> <li>struct RandomCrop </li> <li>struct RandomCrop2 </li> <li>struct RandomFlip </li> <li>struct RandomGaussianBlur </li> <li>struct Resize A functor to resize a tensor image to a specified size. </li> <li>struct Rotation </li> <li>struct ToGray </li> <li>struct ToTensor </li> <li>struct VerticalFlip </li> </ul> </li> </ul> </li> <li>namespace models <ul> <li>struct AlexNet </li> <li>class BaseModel </li> <li>struct Bottleneck </li> <li>struct DoubleConv </li> <li>struct DownSample </li> <li>struct HSigmoid </li> <li>struct HSwish </li> <li>struct LeNet5 </li> <li>struct MobileNetV3 </li> <li>class Model </li> <li>struct ResNet </li> <li>struct SqueezeExcite </li> <li>struct UNet </li> <li>struct UpSample </li> <li>struct VggNet16 </li> </ul> </li> <li>namespace temp <ul> <li>class TestDataset </li> </ul> </li> <li>namespace utils <ul> <li>namespace fs </li> <li>namespace string </li> </ul> </li> </ul> </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> </ul>"},{"location":"xTorch/files/","title":"File List","text":"<p>Here is a list of all files with brief descriptions:</p> <ul> <li>dir include <ul> <li>dir data-loaders <ul> <li>file data-loader.h </li> <li>file data-loaders.h </li> </ul> </li> <li>dir datasets <ul> <li>dir audio-speech <ul> <li>file audio-speech.h </li> <li>file cmu-arctic.h </li> <li>file common-voice.h </li> <li>file crema-d.h </li> <li>file esc.h </li> <li>file gtzan.h </li> <li>file librispeech.h </li> <li>file lj-speech.h </li> <li>file speech-commands.h </li> <li>file tedlium.h </li> <li>file timit.h </li> <li>file urban-sound.h </li> <li>file vctk.h </li> <li>file vox-celeb.h </li> <li>file yes-no.h </li> </ul> </li> <li>dir base <ul> <li>file base.h </li> </ul> </li> <li>dir definitions <ul> <li>file definitions.h </li> <li>file functions.h </li> </ul> </li> <li>dir face-recognition <ul> <li>file face-recognition.h </li> <li>file lfw.h </li> <li>file wider-face.h </li> </ul> </li> <li>dir general <ul> <li>file audio-dataset.h </li> <li>file csv-dataset.h </li> <li>file edf-dataset.h </li> <li>file general.h </li> <li>file image-folder.h </li> <li>file tensor-dataset.h </li> <li>file text-dataset.h </li> <li>file time-series-dataset.h </li> <li>file video-dataset.h </li> </ul> </li> <li>dir image-classification <ul> <li>file caltech.h </li> <li>file celeba.h </li> <li>file cifar.h </li> <li>file country.h </li> <li>file dtd.h </li> <li>file euro-sat.h </li> <li>file fake-data.h </li> <li>file fer.h </li> <li>file fgvc-aircraft.h </li> <li>file flickr.h </li> <li>file flowers.h </li> <li>file food.h </li> <li>file gtsrb.h </li> <li>file image-classification.h </li> <li>file imagenet.h </li> <li>file imagenette.h </li> <li>file inaturalist.h </li> <li>file mnist.h </li> <li>file omniglot.h </li> <li>file pcam.h </li> <li>file places.h </li> <li>file rendered-sst2.h </li> <li>file semeion.h </li> <li>file stanford-cars.h </li> <li>file stl.h </li> <li>file sun.h </li> <li>file svhn.h </li> <li>file usps.h </li> </ul> </li> <li>dir language-modeling <ul> <li>file en-wik.h </li> <li>file language-modeling.h </li> <li>file penn-treebank.h </li> <li>file wiki-text.h </li> </ul> </li> <li>dir machine-translation <ul> <li>file iwslt.h </li> <li>file machine-translation.h </li> <li>file multi.h </li> <li>file wmt.h </li> </ul> </li> <li>dir natural-language-inference <ul> <li>file cola.h </li> <li>file mnli.h </li> <li>file mrpc.h </li> <li>file natural-language-inference.h </li> <li>file qnli.h </li> <li>file qqp.h </li> <li>file rte.h </li> <li>file snli.h </li> <li>file stsb.h </li> <li>file wnli.h </li> </ul> </li> <li>dir object-detection-and-segmentation <ul> <li>file cityscapes.h </li> <li>file coco.h </li> <li>file object-detection-and-segmentation.h </li> <li>file oxfordIII-t-pet.h </li> <li>file sb-dataset.h </li> </ul> </li> <li>dir optical-flow <ul> <li>file flying-chairs.h </li> <li>file hd1k.h </li> <li>file optical-flow.h </li> </ul> </li> <li>dir patch-matching-descriptor-learning <ul> <li>file patch-matching-descriptor-learning.h </li> <li>file photo-tour.h </li> </ul> </li> <li>dir scene-flow <ul> <li>file flying-things-3d.h </li> <li>file scene-flow.h </li> </ul> </li> <li>dir sentiment-analysis <ul> <li>file imdb.h </li> <li>file sentiment-analysis.h </li> <li>file sst.h </li> </ul> </li> <li>dir sequence-tagging <ul> <li>file con-ll-2000-chunking.h </li> <li>file sequence-tagging.h </li> <li>file udpos.h </li> </ul> </li> <li>dir specific <ul> <li>file kitti.h </li> <li>file lsun.h </li> <li>file sbu.h </li> <li>file sintel.h </li> <li>file specific.h </li> <li>file voc.h </li> </ul> </li> <li>dir stereo-matching-depth-estimation <ul> <li>file cre-stereo.h </li> <li>file eth-3d-stereo.h </li> <li>file falling-things-stereo.h </li> <li>file in-stereo.h </li> <li>file middlebury.h </li> <li>file scene-flow-stereo.h </li> <li>file stereo-matching-depth-estimation.h </li> </ul> </li> <li>dir text-classification <ul> <li>file ag-news.h </li> <li>file amazon-review.h </li> <li>file db-pedia.h </li> <li>file sogou-news.h </li> <li>file text-classification.h </li> <li>file yahoo-answers.h </li> <li>file yelp-review.h </li> </ul> </li> <li>dir video <ul> <li>file hmdb.h </li> <li>file kinetics.h </li> <li>file moving-mnist.h </li> <li>file ucf.h </li> <li>file video.h </li> </ul> </li> <li>file datasets.h </li> </ul> </li> <li>dir definitions <ul> <li>file transforms.h </li> </ul> </li> <li>dir exceptions <ul> <li>file implementation.h </li> </ul> </li> <li>dir headers <ul> <li>file datasets.h </li> <li>file transforms.h </li> </ul> </li> <li>dir media <ul> <li>dir image <ul> <li>file image.h </li> <li>file processing.h </li> </ul> </li> <li>dir opencv <ul> <li>file images.h </li> <li>file opencv.h </li> <li>file videos.h </li> </ul> </li> <li>dir video <ul> <li>file processing.h </li> <li>file video.h </li> </ul> </li> <li>file media.h </li> </ul> </li> <li>dir models <ul> <li>dir cnn <ul> <li>dir alexnet <ul> <li>file alexnet.h </li> </ul> </li> <li>dir dense-net <ul> <li>file dense-net-121.h </li> <li>file dense-net-169.h </li> <li>file dense-net-201.h </li> <li>file dense-net-264.h </li> </ul> </li> <li>dir efficient-net <ul> <li>file efficient-net-b0.h </li> <li>file efficient-net-b1.h </li> <li>file efficient-net-b2.h </li> <li>file efficient-net-b3.h </li> <li>file efficient-net-b4.h </li> <li>file efficient-net-b5.h </li> <li>file efficient-net-b6.h </li> <li>file efficient-net-b7.h </li> <li>file efficient-net-v2.h </li> </ul> </li> <li>dir inception <ul> <li>file inception-rsnet.h </li> <li>file inception-v1.h </li> <li>file inception-v2.h </li> <li>file inception-v3.h </li> <li>file inception-v4.h </li> </ul> </li> <li>dir lenet <ul> <li>file lenet5.h </li> </ul> </li> <li>dir mobilenet <ul> <li>file mobilenet-v1.h </li> <li>file mobilenet-v2.h </li> <li>file mobilenet-v3.h </li> </ul> </li> <li>dir nas-net <ul> <li>file nas-net-a.h </li> <li>file nas-net-b.h </li> <li>file nas-net-c.h </li> </ul> </li> <li>dir reg-net <ul> <li>file reg-net-x.h </li> <li>file reg-net-y.h </li> </ul> </li> <li>dir resnet <ul> <li>file res2net.h </li> <li>file resnet-rs.h </li> <li>file resnet-v1.5.h </li> <li>file resnet101.h </li> <li>file resnet1202.h </li> <li>file resnet152.h </li> <li>file resnet18.h </li> <li>file resnet200.h </li> <li>file resnet34.h </li> <li>file resnet50.h </li> <li>file resnext.h </li> <li>file wide-resnet.h </li> </ul> </li> <li>dir shuffle-net <ul> <li>file shuffle-net-v1.h </li> <li>file shuffle-net-v2.h </li> </ul> </li> <li>dir squeeze-net <ul> <li>file squeeze-net-v1.0.h </li> <li>file squeeze-net-v1.1.h </li> </ul> </li> <li>dir unet <ul> <li>file unet.h </li> </ul> </li> <li>dir vggnet <ul> <li>file vggnet11.h </li> <li>file vggnet13.h </li> <li>file vggnet16.h </li> <li>file vggnet19.h </li> </ul> </li> <li>file cnn.h </li> </ul> </li> <li>file base.h </li> <li>file models.h </li> </ul> </li> <li>dir temp <ul> <li>file temp.h </li> <li>file test-dataset.h </li> </ul> </li> <li>dir trainers <ul> <li>file trainer.h </li> <li>file trainers.h </li> </ul> </li> <li>dir transforms <ul> <li>dir base <ul> <li>file base.h </li> </ul> </li> <li>file compose.h </li> <li>file convert.h </li> <li>file crop.h </li> <li>file cutout.h </li> <li>file flip.h </li> <li>file gaussian.h </li> <li>file grayscale.h </li> <li>file jitter.h </li> <li>file lambda.h </li> <li>file normalize.h </li> <li>file pad.h </li> <li>file resize.h </li> <li>file rotation.h </li> <li>file transforms.h </li> </ul> </li> <li>dir types <ul> <li>file arguments.h </li> <li>file enums.h </li> <li>file types.h </li> </ul> </li> <li>dir utils <ul> <li>file base.h </li> <li>file downloader.h </li> <li>file extract.h </li> <li>file filesystem.h </li> <li>file md5.h </li> <li>file string.h </li> <li>file utils.h </li> </ul> </li> <li>file xtorch.h </li> </ul> </li> </ul>"},{"location":"xTorch/structDatasetArguments/","title":"Struct DatasetArguments","text":"<p>ClassList &gt; DatasetArguments</p>"},{"location":"xTorch/structDatasetArguments/#public-attributes","title":"Public Attributes","text":"Type Name bool download   = <code>false</code> DataMode mode   = <code>DataMode::TRAIN</code> vector&lt; torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/structDatasetArguments/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"xTorch/structDatasetArguments/#variable-download","title":"variable download","text":"<pre><code>bool DatasetArguments::download;\n</code></pre>"},{"location":"xTorch/structDatasetArguments/#variable-mode","title":"variable mode","text":"<pre><code>DataMode DatasetArguments::mode;\n</code></pre>"},{"location":"xTorch/structDatasetArguments/#variable-transforms","title":"variable transforms","text":"<pre><code>vector&lt;torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; &gt; DatasetArguments::transforms;\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/types/arguments.h</code></p>"},{"location":"xTorch/classNotImplementedException/","title":"Class NotImplementedException","text":"<p>ClassList &gt; NotImplementedException</p> <p>Inherits the following classes: std::logic_error</p>"},{"location":"xTorch/classNotImplementedException/#public-functions","title":"Public Functions","text":"Type Name NotImplementedException ()"},{"location":"xTorch/classNotImplementedException/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classNotImplementedException/#function-notimplementedexception","title":"function NotImplementedException","text":"<pre><code>inline NotImplementedException::NotImplementedException () \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/exceptions/implementation.h</code></p>"},{"location":"xTorch/namespacestd/","title":"Namespace std","text":"<p>Namespace List &gt; std</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/data-loaders/data-loader.h</code></p>"},{"location":"xTorch/namespacetorch/","title":"Namespace torch","text":"<p>Namespace List &gt; torch</p>"},{"location":"xTorch/namespacetorch/#namespaces","title":"Namespaces","text":"Type Name namespace data namespace ext namespace nn <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/processing.h</code></p>"},{"location":"xTorch/namespacetorch_1_1data/","title":"Namespace torch::data","text":"<p>Namespace List &gt; torch &gt; data</p>"},{"location":"xTorch/namespacetorch_1_1data/#namespaces","title":"Namespaces","text":"Type Name namespace datasets <p>The documentation for this class was generated from the following file <code>[generated]</code></p>"},{"location":"xTorch/namespacetorch_1_1data_1_1datasets/","title":"Namespace torch::data::datasets","text":"<p>Namespace List &gt; torch &gt; data &gt; datasets</p> <p>The documentation for this class was generated from the following file <code>[generated]</code></p>"},{"location":"xTorch/namespacetorch_1_1ext/","title":"Namespace torch::ext","text":"<p>Namespace List &gt; torch &gt; ext</p>"},{"location":"xTorch/namespacetorch_1_1ext/#namespaces","title":"Namespaces","text":"Type Name namespace media <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/processing.h</code></p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media/","title":"Namespace torch::ext::media","text":"<p>Namespace List &gt; torch &gt; ext &gt; media</p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media/#namespaces","title":"Namespaces","text":"Type Name namespace image namespace opencv <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/processing.h</code></p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1image/","title":"Namespace torch::ext::media::image","text":"<p>Namespace List &gt; torch &gt; ext &gt; media &gt; image</p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1image/#public-functions","title":"Public Functions","text":"Type Name torch::Tensor resize (const torch::Tensor &amp; tensor, const std::vector&lt; int64_t &gt; &amp; size)"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1image/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1image/#function-resize","title":"function resize","text":"<pre><code>torch::Tensor torch::ext::media::image::resize (\n    const torch::Tensor &amp; tensor,\n    const std::vector&lt; int64_t &gt; &amp; size\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/processing.h</code></p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv/","title":"Namespace torch::ext::media::opencv","text":"<p>Namespace List &gt; torch &gt; ext &gt; media &gt; opencv</p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv/#namespaces","title":"Namespaces","text":"Type Name namespace videos"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv/#public-functions","title":"Public Functions","text":"Type Name torch::Tensor convertImageToTensor (fs::path image, vector&lt; int &gt; size={0, 0})"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv/#function-convertimagetotensor","title":"function convertImageToTensor","text":"<pre><code>torch::Tensor torch::ext::media::opencv::convertImageToTensor (\n    fs::path image,\n    vector&lt; int &gt; size={0, 0}\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/opencv/images.h</code></p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv_1_1videos/","title":"Namespace torch::ext::media::opencv::videos","text":"<p>Namespace List &gt; torch &gt; ext &gt; media &gt; opencv &gt; videos</p>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv_1_1videos/#public-functions","title":"Public Functions","text":"Type Name std::vector&lt; cv::Mat &gt; extractFrames (const std::string &amp; videoFilePath)  std::vector&lt; torch::Tensor &gt; extractVideoFramesAsTensor (fs::path videoFilePath)"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv_1_1videos/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv_1_1videos/#function-extractframes","title":"function extractFrames","text":"<pre><code>std::vector&lt; cv::Mat &gt; torch::ext::media::opencv::videos::extractFrames (\n    const std::string &amp; videoFilePath\n) \n</code></pre>"},{"location":"xTorch/namespacetorch_1_1ext_1_1media_1_1opencv_1_1videos/#function-extractvideoframesastensor","title":"function extractVideoFramesAsTensor","text":"<pre><code>std::vector&lt; torch::Tensor &gt; torch::ext::media::opencv::videos::extractVideoFramesAsTensor (\n    fs::path videoFilePath\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/opencv/videos.h</code></p>"},{"location":"xTorch/namespacetorch_1_1nn/","title":"Namespace torch::nn","text":"<p>Namespace List &gt; torch &gt; nn</p> <p>The documentation for this class was generated from the following file <code>[generated]</code></p>"},{"location":"xTorch/namespacext/","title":"Namespace xt","text":"<p>Namespace List &gt; xt</p>"},{"location":"xTorch/namespacext/#namespaces","title":"Namespaces","text":"Type Name namespace data namespace models namespace temp namespace utils"},{"location":"xTorch/namespacext/#classes","title":"Classes","text":"Type Name class DataLoader &lt;typename Dataset&gt; class Trainer"},{"location":"xTorch/namespacext/#public-functions","title":"Public Functions","text":"Type Name bool is_transformed_dataset (const Dataset &amp; dataset)"},{"location":"xTorch/namespacext/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext/#function-is_transformed_dataset","title":"function is_transformed_dataset","text":"<pre><code>template&lt;typename Dataset&gt;\nbool xt::is_transformed_dataset (\n    const Dataset &amp; dataset\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/data-loaders/data-loader.h</code></p>"},{"location":"xTorch/classxt_1_1DataLoader/","title":"Class xt::DataLoader","text":"<p>template &lt;typename Dataset&gt;</p> <p>ClassList &gt; xt &gt; DataLoader</p> <p>Inherits the following classes: torch::data::DataLoaderBase&lt; Dataset, Dataset::BatchType, std::vector&lt; size_t &gt; &gt;</p>"},{"location":"xTorch/classxt_1_1DataLoader/#public-types","title":"Public Types","text":"Type Name typedef torch::data::DataLoaderBase&lt; Dataset, BatchType, BatchRequestType &gt; Base typedef std::vector&lt; size_t &gt; BatchRequestType typedef typename Dataset::BatchType BatchType"},{"location":"xTorch/classxt_1_1DataLoader/#public-functions","title":"Public Functions","text":"Type Name DataLoader (Dataset dataset, const torch::data::DataLoaderOptions &amp; options, bool shuffle=false)"},{"location":"xTorch/classxt_1_1DataLoader/#protected-functions","title":"Protected Functions","text":"Type Name std::optional&lt; BatchRequestType &gt; get_batch_request () override void reset () override void reset_indices ()"},{"location":"xTorch/classxt_1_1DataLoader/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"xTorch/classxt_1_1DataLoader/#typedef-base","title":"typedef Base","text":"<pre><code>using xt::DataLoader&lt; Dataset &gt;::Base =  torch::data::DataLoaderBase&lt;Dataset, BatchType, BatchRequestType&gt;;\n</code></pre>"},{"location":"xTorch/classxt_1_1DataLoader/#typedef-batchrequesttype","title":"typedef BatchRequestType","text":"<pre><code>using xt::DataLoader&lt; Dataset &gt;::BatchRequestType =  std::vector&lt;size_t&gt;;\n</code></pre>"},{"location":"xTorch/classxt_1_1DataLoader/#typedef-batchtype","title":"typedef BatchType","text":"<pre><code>using xt::DataLoader&lt; Dataset &gt;::BatchType =  typename Dataset::BatchType;\n</code></pre>"},{"location":"xTorch/classxt_1_1DataLoader/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1DataLoader/#function-dataloader","title":"function DataLoader","text":"<pre><code>xt::DataLoader::DataLoader (\n    Dataset dataset,\n    const torch::data::DataLoaderOptions &amp; options,\n    bool shuffle=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1DataLoader/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"xTorch/classxt_1_1DataLoader/#function-get_batch_request","title":"function get_batch_request","text":"<pre><code>std::optional&lt; BatchRequestType &gt; xt::DataLoader::get_batch_request () override\n</code></pre>"},{"location":"xTorch/classxt_1_1DataLoader/#function-reset","title":"function reset","text":"<pre><code>void xt::DataLoader::reset () override\n</code></pre>"},{"location":"xTorch/classxt_1_1DataLoader/#function-reset_indices","title":"function reset_indices","text":"<pre><code>void xt::DataLoader::reset_indices () \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/data-loaders/data-loader.h</code></p>"},{"location":"xTorch/classxt_1_1Trainer/","title":"Class xt::Trainer","text":"<p>ClassList &gt; xt &gt; Trainer</p>"},{"location":"xTorch/classxt_1_1Trainer/#public-functions","title":"Public Functions","text":"Type Name Trainer ()  Trainer &amp; enable_checkpoint (const std::string &amp; path, int interval)  void fit (xt::models::BaseModel * model, xt::DataLoader&lt; Dataset &gt; &amp; train_loader)  Trainer &amp; set_loss_fn (std::function&lt; torch::Tensor(torch::Tensor, torch::Tensor)&gt; lossFn)  Trainer &amp; set_max_epochs (int maxEpochs)  Trainer &amp; set_optimizer (torch::optim::Optimizer * optimizer)"},{"location":"xTorch/classxt_1_1Trainer/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1Trainer/#function-trainer","title":"function Trainer","text":"<pre><code>xt::Trainer::Trainer () \n</code></pre>"},{"location":"xTorch/classxt_1_1Trainer/#function-enable_checkpoint","title":"function enable_checkpoint","text":"<pre><code>Trainer &amp; xt::Trainer::enable_checkpoint (\n    const std::string &amp; path,\n    int interval\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1Trainer/#function-fit","title":"function fit","text":"<pre><code>template&lt;typename Dataset&gt;\ninline void xt::Trainer::fit (\n    xt::models::BaseModel * model,\n    xt::DataLoader &lt; Dataset &gt; &amp; train_loader\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1Trainer/#function-set_loss_fn","title":"function set_loss_fn","text":"<pre><code>Trainer &amp; xt::Trainer::set_loss_fn (\n    std::function&lt; torch::Tensor(torch::Tensor, torch::Tensor)&gt; lossFn\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1Trainer/#function-set_max_epochs","title":"function set_max_epochs","text":"<pre><code>Trainer &amp; xt::Trainer::set_max_epochs (\n    int maxEpochs\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1Trainer/#function-set_optimizer","title":"function set_optimizer","text":"<pre><code>Trainer &amp; xt::Trainer::set_optimizer (\n    torch::optim::Optimizer * optimizer\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/trainers/trainer.h</code></p>"},{"location":"xTorch/namespacext_1_1data/","title":"Namespace xt::data","text":"<p>Namespace List &gt; xt &gt; data</p>"},{"location":"xTorch/namespacext_1_1data/#namespaces","title":"Namespaces","text":"Type Name namespace datasets namespace transforms"},{"location":"xTorch/namespacext_1_1data/#public-functions","title":"Public Functions","text":"Type Name torch::data::datasets::MapDataset&lt; xt::data::datasets::BaseDataset, torch::data::transforms::Stack&lt;&gt;()&gt; transform_dataset (xt::data::datasets::BaseDataset dataset, vector&lt; torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; &gt; transforms)"},{"location":"xTorch/namespacext_1_1data/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext_1_1data/#function-transform_dataset","title":"function transform_dataset","text":"<pre><code>torch::data::datasets::MapDataset&lt; xt::data::datasets::BaseDataset , torch::data::transforms::Stack&lt;&gt;()&gt; xt::data::transform_dataset (\n    xt::data::datasets::BaseDataset dataset,\n    vector&lt; torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/cmu-arctic.h</code></p>"},{"location":"xTorch/namespacext_1_1data_1_1datasets/","title":"Namespace xt::data::datasets","text":"<p>Namespace List &gt; xt &gt; data &gt; datasets</p>"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#classes","title":"Classes","text":"Type Name class AgNews class AmazonReview class AudioDataset class BaseDataset class CIFAR10 class CIFAR100 class CMUArctic class COLA class CREStereo class CSVDataset class Caltech101 class Caltech256 class CarlaStereo class CelebA class Cityscapes class CoNLL2000Chunking class CocoCaptions class CocoDetection class CommonVoice class Country211 class CremaD class DBPedia class DTD class EDFDataset class EMNIST class ESC class ETH3DStereo class EnWik class EuroSAT class FER2013 class FGVCAircraft class FakeData class FallingThingsStereo class FashionMNIST class Flickr30k class Flickr8k class Flowers102 class FlyingChairs class FlyingThings3D class Food101 class GTSRB class GTZAN class HD1K class HMDB51 class IMDB class INaturalist class IWSLT class ImageFolder class ImageNet class Imagenette class InStereo2k class KMNIST class Kinetics class Kitti class Kitti2012Stereo class Kitti2015Stereo class KittiFlow class LFW class LFWPairs class LFWPeople class LSUN class LibriSpeech class LjSpeech class MNIST class MNISTBase class MNLI class MRPC class MULTI class Middlebury2014Stereo class MovingMNIST class Omniglot class OxfordIIITPet class PCAM class PennTreebank class PhotoTour class Places365 class QMNIST class QNLI class QQP class RTE class RenderedSST2 class SBDataset class SBU class SEMEION class SNLI class SST class STL10 class STSB class SUN397 class SVHN class SceneFlowStereo class Sintel class SintelStereo class SogouNews class SpeechCommands class StackedAudioDataset class StackedCSVDataset class StackedEDFDataset class StackedTextDataset class StackedTimeSeriesDataset class StackedVideoDataset class StanfordCars class TIMIT class Tedlium class TensorDataset class TextDataset class TimeSeriesDataset class UCF101 class UDPOS class USPS class UrbanSound class VCTK class VOCDetection class VOCSegmentation class VideoDataset class VoxCeleb class WIDERFace class WMT class WNLI class WikiText class YahooAnswers class YelpReview class YesNo"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#public-types","title":"Public Types","text":"Type Name enum ImageType enum LabelsType"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#public-attributes","title":"Public Attributes","text":"Type Name const std::unordered_map&lt; ImageType, std::string &gt; ImageTypeToString   = <code>/* multi line expression */</code>"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#public-functions","title":"Public Functions","text":"Type Name std::string getImageTypeValue (ImageType type)"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"xTorch/namespacext_1_1data_1_1datasets/#enum-imagetype","title":"enum ImageType","text":"<pre><code>enum xt::data::datasets::ImageType {\n    FULL = 0,\n    PX320 = 1,\n    PX160 = 2\n};\n</code></pre>"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#enum-labelstype","title":"enum LabelsType","text":"<pre><code>enum xt::data::datasets::LabelsType {\n    BY_FOLDER = 0,\n    BY_NAME = 1\n};\n</code></pre>"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"xTorch/namespacext_1_1data_1_1datasets/#variable-imagetypetostring","title":"variable ImageTypeToString","text":"<pre><code>const std::unordered_map&lt;ImageType, std::string&gt; xt::data::datasets::ImageTypeToString;\n</code></pre>"},{"location":"xTorch/namespacext_1_1data_1_1datasets/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext_1_1data_1_1datasets/#function-getimagetypevalue","title":"function getImageTypeValue","text":"<pre><code>inline std::string xt::data::datasets::getImageTypeValue (\n    ImageType type\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/cmu-arctic.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/","title":"Class xt::data::datasets::AgNews","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; AgNews</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#public-functions","title":"Public Functions","text":"Type Name AgNews (const std::string &amp; root)  AgNews (const std::string &amp; root, DataMode mode)  AgNews (const std::string &amp; root, DataMode mode, bool download)  AgNews (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#function-agnews-14","title":"function AgNews [1/4]","text":"<pre><code>explicit xt::data::datasets::AgNews::AgNews (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#function-agnews-24","title":"function AgNews [2/4]","text":"<pre><code>xt::data::datasets::AgNews::AgNews (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#function-agnews-34","title":"function AgNews [3/4]","text":"<pre><code>xt::data::datasets::AgNews::AgNews (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AgNews/#function-agnews-44","title":"function AgNews [4/4]","text":"<pre><code>xt::data::datasets::AgNews::AgNews (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/ag-news.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/","title":"Class xt::data::datasets::AmazonReview","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; AmazonReview</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#public-functions","title":"Public Functions","text":"Type Name AmazonReview (const std::string &amp; root)  AmazonReview (const std::string &amp; root, DataMode mode)  AmazonReview (const std::string &amp; root, DataMode mode, bool download)  AmazonReview (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#function-amazonreview-14","title":"function AmazonReview [1/4]","text":"<pre><code>explicit xt::data::datasets::AmazonReview::AmazonReview (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#function-amazonreview-24","title":"function AmazonReview [2/4]","text":"<pre><code>xt::data::datasets::AmazonReview::AmazonReview (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#function-amazonreview-34","title":"function AmazonReview [3/4]","text":"<pre><code>xt::data::datasets::AmazonReview::AmazonReview (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AmazonReview/#function-amazonreview-44","title":"function AmazonReview [4/4]","text":"<pre><code>xt::data::datasets::AmazonReview::AmazonReview (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/amazon-review.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AudioDataset/","title":"Class xt::data::datasets::AudioDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; AudioDataset</p> <p>Inherits the following classes: torch::data::datasets::Dataset&lt; AudioDataset &gt;</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AudioDataset/#public-functions","title":"Public Functions","text":"Type Name AudioDataset (const std::string &amp; audio_dir, const std::string &amp; label_file)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AudioDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AudioDataset/#function-audiodataset","title":"function AudioDataset","text":"<pre><code>inline xt::data::datasets::AudioDataset::AudioDataset (\n    const std::string &amp; audio_dir,\n    const std::string &amp; label_file\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AudioDataset/#function-get","title":"function get","text":"<pre><code>inline torch::data::Example xt::data::datasets::AudioDataset::get (\n    size_t index\n) override\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1AudioDataset/#function-size","title":"function size","text":"<pre><code>inline torch::optional&lt; size_t &gt; xt::data::datasets::AudioDataset::size () override const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/audio-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/","title":"Class xt::data::datasets::BaseDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; BaseDataset</p> <p>Inherits the following classes: torch::data::Dataset&lt; BaseDataset &gt;</p> <p>Inherited by the following classes: xt::data::datasets::AgNews,  xt::data::datasets::AmazonReview,  xt::data::datasets::CIFAR10,  xt::data::datasets::CIFAR100,  xt::data::datasets::CMUArctic,  xt::data::datasets::COLA,  xt::data::datasets::CREStereo,  xt::data::datasets::CSVDataset,  xt::data::datasets::Caltech101,  xt::data::datasets::Caltech256,  xt::data::datasets::CarlaStereo,  xt::data::datasets::CelebA,  xt::data::datasets::Cityscapes,  xt::data::datasets::CoNLL2000Chunking,  xt::data::datasets::CocoCaptions,  xt::data::datasets::CocoDetection,  xt::data::datasets::CommonVoice,  xt::data::datasets::Country211,  xt::data::datasets::CremaD,  xt::data::datasets::DBPedia,  xt::data::datasets::DTD,  xt::data::datasets::EDFDataset,  xt::data::datasets::ESC,  xt::data::datasets::ETH3DStereo,  xt::data::datasets::EnWik,  xt::data::datasets::EuroSAT,  xt::data::datasets::FER2013,  xt::data::datasets::FGVCAircraft,  xt::data::datasets::FakeData,  xt::data::datasets::FallingThingsStereo,  xt::data::datasets::Flickr30k,  xt::data::datasets::Flickr8k,  xt::data::datasets::Flowers102,  xt::data::datasets::FlyingChairs,  xt::data::datasets::FlyingThings3D,  xt::data::datasets::Food101,  xt::data::datasets::GTSRB,  xt::data::datasets::GTZAN,  xt::data::datasets::HD1K,  xt::data::datasets::HMDB51,  xt::data::datasets::IMDB,  xt::data::datasets::INaturalist,  xt::data::datasets::IWSLT,  xt::data::datasets::ImageFolder,  xt::data::datasets::ImageNet,  xt::data::datasets::Imagenette,  xt::data::datasets::InStereo2k,  xt::data::datasets::Kinetics,  xt::data::datasets::Kitti,  xt::data::datasets::Kitti2012Stereo,  xt::data::datasets::Kitti2015Stereo,  xt::data::datasets::KittiFlow,  xt::data::datasets::LFW,  xt::data::datasets::LSUN,  xt::data::datasets::LibriSpeech,  xt::data::datasets::LjSpeech,  xt::data::datasets::MNISTBase,  xt::data::datasets::MNLI,  xt::data::datasets::MRPC,  xt::data::datasets::MULTI,  xt::data::datasets::Middlebury2014Stereo,  xt::data::datasets::MovingMNIST,  xt::data::datasets::Omniglot,  xt::data::datasets::OxfordIIITPet,  xt::data::datasets::PCAM,  xt::data::datasets::PennTreebank,  xt::data::datasets::PhotoTour,  xt::data::datasets::Places365,  xt::data::datasets::QNLI,  xt::data::datasets::QQP,  xt::data::datasets::RTE,  xt::data::datasets::RenderedSST2,  xt::data::datasets::SBDataset,  xt::data::datasets::SBU,  xt::data::datasets::SEMEION,  xt::data::datasets::SNLI,  xt::data::datasets::SST,  xt::data::datasets::STL10,  xt::data::datasets::STSB,  xt::data::datasets::SUN397,  xt::data::datasets::SVHN,  xt::data::datasets::SceneFlowStereo,  xt::data::datasets::Sintel,  xt::data::datasets::SintelStereo,  xt::data::datasets::SogouNews,  xt::data::datasets::SpeechCommands,  xt::data::datasets::StackedAudioDataset,  xt::data::datasets::StackedCSVDataset,  xt::data::datasets::StackedEDFDataset,  xt::data::datasets::StackedTextDataset,  xt::data::datasets::StackedTimeSeriesDataset,  xt::data::datasets::StackedVideoDataset,  xt::data::datasets::StanfordCars,  xt::data::datasets::TIMIT,  xt::data::datasets::Tedlium,  xt::data::datasets::TensorDataset,  xt::data::datasets::TextDataset,  xt::data::datasets::TimeSeriesDataset,  xt::data::datasets::UCF101,  xt::data::datasets::UDPOS,  xt::data::datasets::USPS,  xt::data::datasets::UrbanSound,  xt::data::datasets::VCTK,  xt::data::datasets::VOCDetection,  xt::data::datasets::VOCSegmentation,  xt::data::datasets::VideoDataset,  xt::data::datasets::VoxCeleb,  xt::data::datasets::WIDERFace,  xt::data::datasets::WMT,  xt::data::datasets::WNLI,  xt::data::datasets::WikiText,  xt::data::datasets::YahooAnswers,  xt::data::datasets::YelpReview,  xt::data::datasets::YesNo</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#public-types","title":"Public Types","text":"Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#public-attributes","title":"Public Attributes","text":"Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#public-functions","title":"Public Functions","text":"Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#typedef-transformtype","title":"typedef TransformType","text":"<pre><code>using xt::data::datasets::BaseDataset::TransformType =  vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt; &gt;;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-compose","title":"variable compose","text":"<pre><code>xt::data::transforms::Compose xt::data::datasets::BaseDataset::compose;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-data","title":"variable data","text":"<pre><code>std::vector&lt;torch::Tensor&gt; xt::data::datasets::BaseDataset::data;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-dataset_path","title":"variable dataset_path","text":"<pre><code>fs::path xt::data::datasets::BaseDataset::dataset_path;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-download","title":"variable download","text":"<pre><code>bool xt::data::datasets::BaseDataset::download;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-labels","title":"variable labels","text":"<pre><code>std::vector&lt;uint8_t&gt; xt::data::datasets::BaseDataset::labels;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-mode","title":"variable mode","text":"<pre><code>DataMode xt::data::datasets::BaseDataset::mode;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-root","title":"variable root","text":"<pre><code>fs::path xt::data::datasets::BaseDataset::root;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#variable-transforms","title":"variable transforms","text":"<pre><code>vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt; &gt; xt::data::datasets::BaseDataset::transforms;\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#function-basedataset-14","title":"function BaseDataset [1/4]","text":"<pre><code>xt::data::datasets::BaseDataset::BaseDataset (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#function-basedataset-24","title":"function BaseDataset [2/4]","text":"<pre><code>xt::data::datasets::BaseDataset::BaseDataset (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#function-basedataset-34","title":"function BaseDataset [3/4]","text":"<pre><code>xt::data::datasets::BaseDataset::BaseDataset (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#function-basedataset-44","title":"function BaseDataset [4/4]","text":"<pre><code>xt::data::datasets::BaseDataset::BaseDataset (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#function-get","title":"function get","text":"<pre><code>torch::data::Example xt::data::datasets::BaseDataset::get (\n    size_t index\n) override\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1BaseDataset/#function-size","title":"function size","text":"<pre><code>torch::optional&lt; size_t &gt; xt::data::datasets::BaseDataset::size () override const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/base/base.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/","title":"Class xt::data::datasets::CIFAR10","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CIFAR10</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#public-functions","title":"Public Functions","text":"Type Name CIFAR10 (const std::string &amp; root)  CIFAR10 (const std::string &amp; root, DataMode mode)  CIFAR10 (const std::string &amp; root, DataMode mode, bool download)  CIFAR10 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#function-cifar10-14","title":"function CIFAR10 [1/4]","text":"<pre><code>explicit xt::data::datasets::CIFAR10::CIFAR10 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#function-cifar10-24","title":"function CIFAR10 [2/4]","text":"<pre><code>xt::data::datasets::CIFAR10::CIFAR10 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#function-cifar10-34","title":"function CIFAR10 [3/4]","text":"<pre><code>xt::data::datasets::CIFAR10::CIFAR10 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#function-cifar10-44","title":"function CIFAR10 [4/4]","text":"<pre><code>xt::data::datasets::CIFAR10::CIFAR10 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#function-get","title":"function get","text":"<pre><code>torch::data::Example xt::data::datasets::CIFAR10::get (\n    size_t index\n) override\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR10/#function-size","title":"function size","text":"<pre><code>torch::optional&lt; size_t &gt; xt::data::datasets::CIFAR10::size () override const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/cifar.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/","title":"Class xt::data::datasets::CIFAR100","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CIFAR100</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#public-functions","title":"Public Functions","text":"Type Name CIFAR100 (const std::string &amp; root)  CIFAR100 (const std::string &amp; root, DataMode mode)  CIFAR100 (const std::string &amp; root, DataMode mode, bool download)  CIFAR100 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#function-cifar100-14","title":"function CIFAR100 [1/4]","text":"<pre><code>explicit xt::data::datasets::CIFAR100::CIFAR100 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#function-cifar100-24","title":"function CIFAR100 [2/4]","text":"<pre><code>xt::data::datasets::CIFAR100::CIFAR100 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#function-cifar100-34","title":"function CIFAR100 [3/4]","text":"<pre><code>xt::data::datasets::CIFAR100::CIFAR100 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#function-cifar100-44","title":"function CIFAR100 [4/4]","text":"<pre><code>xt::data::datasets::CIFAR100::CIFAR100 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#function-get","title":"function get","text":"<pre><code>torch::data::Example xt::data::datasets::CIFAR100::get (\n    size_t index\n) override\n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CIFAR100/#function-size","title":"function size","text":"<pre><code>torch::optional&lt; size_t &gt; xt::data::datasets::CIFAR100::size () override const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/cifar.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/","title":"Class xt::data::datasets::CMUArctic","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CMUArctic</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#public-functions","title":"Public Functions","text":"Type Name CMUArctic (const std::string &amp; root)  CMUArctic (const std::string &amp; root, DataMode mode)  CMUArctic (const std::string &amp; root, DataMode mode, bool download)  CMUArctic (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#function-cmuarctic-14","title":"function CMUArctic [1/4]","text":"<pre><code>explicit xt::data::datasets::CMUArctic::CMUArctic (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#function-cmuarctic-24","title":"function CMUArctic [2/4]","text":"<pre><code>xt::data::datasets::CMUArctic::CMUArctic (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#function-cmuarctic-34","title":"function CMUArctic [3/4]","text":"<pre><code>xt::data::datasets::CMUArctic::CMUArctic (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CMUArctic/#function-cmuarctic-44","title":"function CMUArctic [4/4]","text":"<pre><code>xt::data::datasets::CMUArctic::CMUArctic (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/cmu-arctic.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/","title":"Class xt::data::datasets::COLA","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; COLA</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#public-functions","title":"Public Functions","text":"Type Name COLA (const std::string &amp; root)  COLA (const std::string &amp; root, DataMode mode)  COLA (const std::string &amp; root, DataMode mode, bool download)  COLA (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#function-cola-14","title":"function COLA [1/4]","text":"<pre><code>explicit xt::data::datasets::COLA::COLA (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#function-cola-24","title":"function COLA [2/4]","text":"<pre><code>xt::data::datasets::COLA::COLA (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#function-cola-34","title":"function COLA [3/4]","text":"<pre><code>xt::data::datasets::COLA::COLA (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1COLA/#function-cola-44","title":"function COLA [4/4]","text":"<pre><code>xt::data::datasets::COLA::COLA (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/cola.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/","title":"Class xt::data::datasets::CREStereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CREStereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#public-functions","title":"Public Functions","text":"Type Name CREStereo (const std::string &amp; root)  CREStereo (const std::string &amp; root, DataMode mode)  CREStereo (const std::string &amp; root, DataMode mode, bool download)  CREStereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#function-crestereo-14","title":"function CREStereo [1/4]","text":"<pre><code>explicit xt::data::datasets::CREStereo::CREStereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#function-crestereo-24","title":"function CREStereo [2/4]","text":"<pre><code>xt::data::datasets::CREStereo::CREStereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#function-crestereo-34","title":"function CREStereo [3/4]","text":"<pre><code>xt::data::datasets::CREStereo::CREStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CREStereo/#function-crestereo-44","title":"function CREStereo [4/4]","text":"<pre><code>xt::data::datasets::CREStereo::CREStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/cre-stereo.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/","title":"Class xt::data::datasets::CSVDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CSVDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#public-functions","title":"Public Functions","text":"Type Name CSVDataset (const std::string &amp; file_path)  CSVDataset (const std::string &amp; file_path, DataMode mode)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; int &gt; x_indices, int y_index)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; int &gt; x_indices, vector&lt; int &gt; y_indices)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; string &gt; x_titles, string y_title)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; string &gt; x_titles, vector&lt; string &gt; y_titles)  CSVDataset (const std::string &amp; file_path, DataMode mode, TransformType transforms)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; int &gt; x_indices, int y_index, TransformType transforms)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; int &gt; x_indices, vector&lt; int &gt; y_indices, TransformType transforms)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; string &gt; x_titles, string y_title, TransformType transforms)  CSVDataset (const std::string &amp; file_path, DataMode mode, vector&lt; string &gt; x_titles, vector&lt; string &gt; y_titles, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-111","title":"function CSVDataset [1/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-211","title":"function CSVDataset [2/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-311","title":"function CSVDataset [3/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; int &gt; x_indices,\n    int y_index\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-411","title":"function CSVDataset [4/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; int &gt; x_indices,\n    vector&lt; int &gt; y_indices\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-511","title":"function CSVDataset [5/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; string &gt; x_titles,\n    string y_title\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-611","title":"function CSVDataset [6/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; string &gt; x_titles,\n    vector&lt; string &gt; y_titles\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-711","title":"function CSVDataset [7/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    TransformType transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-811","title":"function CSVDataset [8/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; int &gt; x_indices,\n    int y_index,\n    TransformType transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-911","title":"function CSVDataset [9/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; int &gt; x_indices,\n    vector&lt; int &gt; y_indices,\n    TransformType transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-1011","title":"function CSVDataset [10/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; string &gt; x_titles,\n    string y_title,\n    TransformType transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CSVDataset/#function-csvdataset-1111","title":"function CSVDataset [11/11]","text":"<pre><code>xt::data::datasets::CSVDataset::CSVDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; string &gt; x_titles,\n    vector&lt; string &gt; y_titles,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/csv-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/","title":"Class xt::data::datasets::Caltech101","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Caltech101</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#public-functions","title":"Public Functions","text":"Type Name Caltech101 (const std::string &amp; root)  Caltech101 (const std::string &amp; root, DataMode mode)  Caltech101 (const std::string &amp; root, DataMode mode, bool download)  Caltech101 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#function-caltech101-14","title":"function Caltech101 [1/4]","text":"<pre><code>explicit xt::data::datasets::Caltech101::Caltech101 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#function-caltech101-24","title":"function Caltech101 [2/4]","text":"<pre><code>xt::data::datasets::Caltech101::Caltech101 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#function-caltech101-34","title":"function Caltech101 [3/4]","text":"<pre><code>xt::data::datasets::Caltech101::Caltech101 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech101/#function-caltech101-44","title":"function Caltech101 [4/4]","text":"<pre><code>xt::data::datasets::Caltech101::Caltech101 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/caltech.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/","title":"Class xt::data::datasets::Caltech256","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Caltech256</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#public-functions","title":"Public Functions","text":"Type Name Caltech256 (const std::string &amp; root)  Caltech256 (const std::string &amp; root, DataMode mode)  Caltech256 (const std::string &amp; root, DataMode mode, bool download)  Caltech256 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#function-caltech256-14","title":"function Caltech256 [1/4]","text":"<pre><code>explicit xt::data::datasets::Caltech256::Caltech256 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#function-caltech256-24","title":"function Caltech256 [2/4]","text":"<pre><code>xt::data::datasets::Caltech256::Caltech256 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#function-caltech256-34","title":"function Caltech256 [3/4]","text":"<pre><code>xt::data::datasets::Caltech256::Caltech256 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Caltech256/#function-caltech256-44","title":"function Caltech256 [4/4]","text":"<pre><code>xt::data::datasets::Caltech256::Caltech256 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/caltech.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/","title":"Class xt::data::datasets::CarlaStereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CarlaStereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#public-functions","title":"Public Functions","text":"Type Name CarlaStereo (const std::string &amp; root)  CarlaStereo (const std::string &amp; root, DataMode mode)  CarlaStereo (const std::string &amp; root, DataMode mode, bool download)  CarlaStereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#function-carlastereo-14","title":"function CarlaStereo [1/4]","text":"<pre><code>explicit xt::data::datasets::CarlaStereo::CarlaStereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#function-carlastereo-24","title":"function CarlaStereo [2/4]","text":"<pre><code>xt::data::datasets::CarlaStereo::CarlaStereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#function-carlastereo-34","title":"function CarlaStereo [3/4]","text":"<pre><code>xt::data::datasets::CarlaStereo::CarlaStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CarlaStereo/#function-carlastereo-44","title":"function CarlaStereo [4/4]","text":"<pre><code>xt::data::datasets::CarlaStereo::CarlaStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/cre-stereo.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/","title":"Class xt::data::datasets::CelebA","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CelebA</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#public-functions","title":"Public Functions","text":"Type Name CelebA (const std::string &amp; root)  CelebA (const std::string &amp; root, DataMode mode)  CelebA (const std::string &amp; root, DataMode mode, bool download)  CelebA (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#function-celeba-14","title":"function CelebA [1/4]","text":"<pre><code>explicit xt::data::datasets::CelebA::CelebA (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#function-celeba-24","title":"function CelebA [2/4]","text":"<pre><code>xt::data::datasets::CelebA::CelebA (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#function-celeba-34","title":"function CelebA [3/4]","text":"<pre><code>xt::data::datasets::CelebA::CelebA (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CelebA/#function-celeba-44","title":"function CelebA [4/4]","text":"<pre><code>xt::data::datasets::CelebA::CelebA (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/celeba.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/","title":"Class xt::data::datasets::Cityscapes","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Cityscapes</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#public-functions","title":"Public Functions","text":"Type Name Cityscapes (const std::string &amp; root)  Cityscapes (const std::string &amp; root, DataMode mode)  Cityscapes (const std::string &amp; root, DataMode mode, bool download)  Cityscapes (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#function-cityscapes-14","title":"function Cityscapes [1/4]","text":"<pre><code>explicit xt::data::datasets::Cityscapes::Cityscapes (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#function-cityscapes-24","title":"function Cityscapes [2/4]","text":"<pre><code>xt::data::datasets::Cityscapes::Cityscapes (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#function-cityscapes-34","title":"function Cityscapes [3/4]","text":"<pre><code>xt::data::datasets::Cityscapes::Cityscapes (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Cityscapes/#function-cityscapes-44","title":"function Cityscapes [4/4]","text":"<pre><code>xt::data::datasets::Cityscapes::Cityscapes (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/cityscapes.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/","title":"Class xt::data::datasets::CoNLL2000Chunking","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CoNLL2000Chunking</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#public-functions","title":"Public Functions","text":"Type Name CoNLL2000Chunking (const std::string &amp; root)  CoNLL2000Chunking (const std::string &amp; root, DataMode mode)  CoNLL2000Chunking (const std::string &amp; root, DataMode mode, bool download)  CoNLL2000Chunking (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#function-conll2000chunking-14","title":"function CoNLL2000Chunking [1/4]","text":"<pre><code>explicit xt::data::datasets::CoNLL2000Chunking::CoNLL2000Chunking (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#function-conll2000chunking-24","title":"function CoNLL2000Chunking [2/4]","text":"<pre><code>xt::data::datasets::CoNLL2000Chunking::CoNLL2000Chunking (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#function-conll2000chunking-34","title":"function CoNLL2000Chunking [3/4]","text":"<pre><code>xt::data::datasets::CoNLL2000Chunking::CoNLL2000Chunking (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CoNLL2000Chunking/#function-conll2000chunking-44","title":"function CoNLL2000Chunking [4/4]","text":"<pre><code>xt::data::datasets::CoNLL2000Chunking::CoNLL2000Chunking (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sequence-tagging/con-ll-2000-chunking.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/","title":"Class xt::data::datasets::CocoCaptions","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CocoCaptions</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#public-functions","title":"Public Functions","text":"Type Name CocoCaptions (const std::string &amp; root)  CocoCaptions (const std::string &amp; root, DataMode mode)  CocoCaptions (const std::string &amp; root, DataMode mode, bool download)  CocoCaptions (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#function-cococaptions-14","title":"function CocoCaptions [1/4]","text":"<pre><code>explicit xt::data::datasets::CocoCaptions::CocoCaptions (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#function-cococaptions-24","title":"function CocoCaptions [2/4]","text":"<pre><code>xt::data::datasets::CocoCaptions::CocoCaptions (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#function-cococaptions-34","title":"function CocoCaptions [3/4]","text":"<pre><code>xt::data::datasets::CocoCaptions::CocoCaptions (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoCaptions/#function-cococaptions-44","title":"function CocoCaptions [4/4]","text":"<pre><code>xt::data::datasets::CocoCaptions::CocoCaptions (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/coco.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/","title":"Class xt::data::datasets::CocoDetection","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CocoDetection</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#public-functions","title":"Public Functions","text":"Type Name CocoDetection (const std::string &amp; root)  CocoDetection (const std::string &amp; root, DataMode mode)  CocoDetection (const std::string &amp; root, DataMode mode, bool download)  CocoDetection (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#function-cocodetection-14","title":"function CocoDetection [1/4]","text":"<pre><code>explicit xt::data::datasets::CocoDetection::CocoDetection (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#function-cocodetection-24","title":"function CocoDetection [2/4]","text":"<pre><code>xt::data::datasets::CocoDetection::CocoDetection (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#function-cocodetection-34","title":"function CocoDetection [3/4]","text":"<pre><code>xt::data::datasets::CocoDetection::CocoDetection (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CocoDetection/#function-cocodetection-44","title":"function CocoDetection [4/4]","text":"<pre><code>xt::data::datasets::CocoDetection::CocoDetection (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/coco.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/","title":"Class xt::data::datasets::CommonVoice","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CommonVoice</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#public-functions","title":"Public Functions","text":"Type Name CommonVoice (const std::string &amp; root)  CommonVoice (const std::string &amp; root, DataMode mode)  CommonVoice (const std::string &amp; root, DataMode mode, bool download)  CommonVoice (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#function-commonvoice-14","title":"function CommonVoice [1/4]","text":"<pre><code>explicit xt::data::datasets::CommonVoice::CommonVoice (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#function-commonvoice-24","title":"function CommonVoice [2/4]","text":"<pre><code>xt::data::datasets::CommonVoice::CommonVoice (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#function-commonvoice-34","title":"function CommonVoice [3/4]","text":"<pre><code>xt::data::datasets::CommonVoice::CommonVoice (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CommonVoice/#function-commonvoice-44","title":"function CommonVoice [4/4]","text":"<pre><code>xt::data::datasets::CommonVoice::CommonVoice (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/common-voice.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/","title":"Class xt::data::datasets::Country211","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Country211</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#public-functions","title":"Public Functions","text":"Type Name Country211 (const std::string &amp; root)  Country211 (const std::string &amp; root, DataMode mode)  Country211 (const std::string &amp; root, DataMode mode, bool download)  Country211 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#function-country211-14","title":"function Country211 [1/4]","text":"<pre><code>explicit xt::data::datasets::Country211::Country211 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#function-country211-24","title":"function Country211 [2/4]","text":"<pre><code>xt::data::datasets::Country211::Country211 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#function-country211-34","title":"function Country211 [3/4]","text":"<pre><code>xt::data::datasets::Country211::Country211 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Country211/#function-country211-44","title":"function Country211 [4/4]","text":"<pre><code>xt::data::datasets::Country211::Country211 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/country.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/","title":"Class xt::data::datasets::CremaD","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; CremaD</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#public-functions","title":"Public Functions","text":"Type Name CremaD (const std::string &amp; root)  CremaD (const std::string &amp; root, DataMode mode)  CremaD (const std::string &amp; root, DataMode mode, bool download)  CremaD (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#function-cremad-14","title":"function CremaD [1/4]","text":"<pre><code>explicit xt::data::datasets::CremaD::CremaD (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#function-cremad-24","title":"function CremaD [2/4]","text":"<pre><code>xt::data::datasets::CremaD::CremaD (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#function-cremad-34","title":"function CremaD [3/4]","text":"<pre><code>xt::data::datasets::CremaD::CremaD (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1CremaD/#function-cremad-44","title":"function CremaD [4/4]","text":"<pre><code>xt::data::datasets::CremaD::CremaD (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/crema-d.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/","title":"Class xt::data::datasets::DBPedia","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; DBPedia</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#public-functions","title":"Public Functions","text":"Type Name DBPedia (const std::string &amp; root)  DBPedia (const std::string &amp; root, DataMode mode)  DBPedia (const std::string &amp; root, DataMode mode, bool download)  DBPedia (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#function-dbpedia-14","title":"function DBPedia [1/4]","text":"<pre><code>explicit xt::data::datasets::DBPedia::DBPedia (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#function-dbpedia-24","title":"function DBPedia [2/4]","text":"<pre><code>xt::data::datasets::DBPedia::DBPedia (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#function-dbpedia-34","title":"function DBPedia [3/4]","text":"<pre><code>xt::data::datasets::DBPedia::DBPedia (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DBPedia/#function-dbpedia-44","title":"function DBPedia [4/4]","text":"<pre><code>xt::data::datasets::DBPedia::DBPedia (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/db-pedia.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/","title":"Class xt::data::datasets::DTD","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; DTD</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#public-functions","title":"Public Functions","text":"Type Name DTD (const std::string &amp; root)  DTD (const std::string &amp; root, DataMode mode)  DTD (const std::string &amp; root, DataMode mode, bool download)  DTD (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#function-dtd-14","title":"function DTD [1/4]","text":"<pre><code>explicit xt::data::datasets::DTD::DTD (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#function-dtd-24","title":"function DTD [2/4]","text":"<pre><code>xt::data::datasets::DTD::DTD (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#function-dtd-34","title":"function DTD [3/4]","text":"<pre><code>xt::data::datasets::DTD::DTD (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1DTD/#function-dtd-44","title":"function DTD [4/4]","text":"<pre><code>xt::data::datasets::DTD::DTD (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/dtd.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/","title":"Class xt::data::datasets::EDFDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; EDFDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#public-functions","title":"Public Functions","text":"Type Name EDFDataset (const std::string &amp; file_path)  EDFDataset (const std::string &amp; file_path, DataMode mode)  EDFDataset (const std::string &amp; file_path, DataMode mode, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#function-edfdataset-13","title":"function EDFDataset [1/3]","text":"<pre><code>xt::data::datasets::EDFDataset::EDFDataset (\n    const std::string &amp; file_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#function-edfdataset-23","title":"function EDFDataset [2/3]","text":"<pre><code>xt::data::datasets::EDFDataset::EDFDataset (\n    const std::string &amp; file_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EDFDataset/#function-edfdataset-33","title":"function EDFDataset [3/3]","text":"<pre><code>xt::data::datasets::EDFDataset::EDFDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/edf-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/","title":"Class xt::data::datasets::EMNIST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; EMNIST</p> <p>Inherits the following classes: xt::data::datasets::MNISTBase</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#public-functions","title":"Public Functions","text":"Type Name EMNIST (const std::string &amp; root, DataMode mode=DataMode::TRAIN, bool download=false)  EMNIST (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#public-functions-inherited-from-xtdatadatasetsmnistbase","title":"Public Functions inherited from xt::data::datasets::MNISTBase","text":"<p>See xt::data::datasets::MNISTBase</p> Type Name MNISTBase (const std::string &amp; root)  MNISTBase (const std::string &amp; root, DataMode mode)  MNISTBase (const std::string &amp; root, DataMode mode, bool download)  MNISTBase (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  void read_images (const std::string &amp; file_path, int num_images)  void read_labels (const std::string &amp; file_path, int num_labels)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#function-emnist-12","title":"function EMNIST [1/2]","text":"<pre><code>xt::data::datasets::EMNIST::EMNIST (\n    const std::string &amp; root,\n    DataMode mode=DataMode::TRAIN,\n    bool download=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EMNIST/#function-emnist-22","title":"function EMNIST [2/2]","text":"<pre><code>xt::data::datasets::EMNIST::EMNIST (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/","title":"Class xt::data::datasets::ESC","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; ESC</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#public-functions","title":"Public Functions","text":"Type Name ESC (const std::string &amp; root)  ESC (const std::string &amp; root, DataMode mode)  ESC (const std::string &amp; root, DataMode mode, bool download)  ESC (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#function-esc-14","title":"function ESC [1/4]","text":"<pre><code>explicit xt::data::datasets::ESC::ESC (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#function-esc-24","title":"function ESC [2/4]","text":"<pre><code>xt::data::datasets::ESC::ESC (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#function-esc-34","title":"function ESC [3/4]","text":"<pre><code>xt::data::datasets::ESC::ESC (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ESC/#function-esc-44","title":"function ESC [4/4]","text":"<pre><code>xt::data::datasets::ESC::ESC (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/esc.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/","title":"Class xt::data::datasets::ETH3DStereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; ETH3DStereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#public-functions","title":"Public Functions","text":"Type Name ETH3DStereo (const std::string &amp; root)  ETH3DStereo (const std::string &amp; root, DataMode mode)  ETH3DStereo (const std::string &amp; root, DataMode mode, bool download)  ETH3DStereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#function-eth3dstereo-14","title":"function ETH3DStereo [1/4]","text":"<pre><code>explicit xt::data::datasets::ETH3DStereo::ETH3DStereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#function-eth3dstereo-24","title":"function ETH3DStereo [2/4]","text":"<pre><code>xt::data::datasets::ETH3DStereo::ETH3DStereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#function-eth3dstereo-34","title":"function ETH3DStereo [3/4]","text":"<pre><code>xt::data::datasets::ETH3DStereo::ETH3DStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ETH3DStereo/#function-eth3dstereo-44","title":"function ETH3DStereo [4/4]","text":"<pre><code>xt::data::datasets::ETH3DStereo::ETH3DStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/eth-3d-stereo.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/","title":"Class xt::data::datasets::EnWik","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; EnWik</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#public-functions","title":"Public Functions","text":"Type Name EnWik (const std::string &amp; root)  EnWik (const std::string &amp; root, DataMode mode)  EnWik (const std::string &amp; root, DataMode mode, bool download)  EnWik (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#function-enwik-14","title":"function EnWik [1/4]","text":"<pre><code>explicit xt::data::datasets::EnWik::EnWik (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#function-enwik-24","title":"function EnWik [2/4]","text":"<pre><code>xt::data::datasets::EnWik::EnWik (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#function-enwik-34","title":"function EnWik [3/4]","text":"<pre><code>xt::data::datasets::EnWik::EnWik (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EnWik/#function-enwik-44","title":"function EnWik [4/4]","text":"<pre><code>xt::data::datasets::EnWik::EnWik (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/en-wik.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/","title":"Class xt::data::datasets::EuroSAT","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; EuroSAT</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#public-functions","title":"Public Functions","text":"Type Name EuroSAT (const std::string &amp; root)  EuroSAT (const std::string &amp; root, DataMode mode)  EuroSAT (const std::string &amp; root, DataMode mode, bool download)  EuroSAT (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#function-eurosat-14","title":"function EuroSAT [1/4]","text":"<pre><code>explicit xt::data::datasets::EuroSAT::EuroSAT (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#function-eurosat-24","title":"function EuroSAT [2/4]","text":"<pre><code>xt::data::datasets::EuroSAT::EuroSAT (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#function-eurosat-34","title":"function EuroSAT [3/4]","text":"<pre><code>xt::data::datasets::EuroSAT::EuroSAT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1EuroSAT/#function-eurosat-44","title":"function EuroSAT [4/4]","text":"<pre><code>xt::data::datasets::EuroSAT::EuroSAT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/euro-sat.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/","title":"Class xt::data::datasets::FER2013","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FER2013</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#public-functions","title":"Public Functions","text":"Type Name FER2013 (const std::string &amp; root)  FER2013 (const std::string &amp; root, DataMode mode)  FER2013 (const std::string &amp; root, DataMode mode, bool download)  FER2013 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#function-fer2013-14","title":"function FER2013 [1/4]","text":"<pre><code>explicit xt::data::datasets::FER2013::FER2013 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#function-fer2013-24","title":"function FER2013 [2/4]","text":"<pre><code>xt::data::datasets::FER2013::FER2013 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#function-fer2013-34","title":"function FER2013 [3/4]","text":"<pre><code>xt::data::datasets::FER2013::FER2013 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FER2013/#function-fer2013-44","title":"function FER2013 [4/4]","text":"<pre><code>xt::data::datasets::FER2013::FER2013 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/fer.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/","title":"Class xt::data::datasets::FGVCAircraft","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FGVCAircraft</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#public-functions","title":"Public Functions","text":"Type Name FGVCAircraft (const std::string &amp; root)  FGVCAircraft (const std::string &amp; root, DataMode mode)  FGVCAircraft (const std::string &amp; root, DataMode mode, bool download)  FGVCAircraft (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#function-fgvcaircraft-14","title":"function FGVCAircraft [1/4]","text":"<pre><code>explicit xt::data::datasets::FGVCAircraft::FGVCAircraft (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#function-fgvcaircraft-24","title":"function FGVCAircraft [2/4]","text":"<pre><code>xt::data::datasets::FGVCAircraft::FGVCAircraft (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#function-fgvcaircraft-34","title":"function FGVCAircraft [3/4]","text":"<pre><code>xt::data::datasets::FGVCAircraft::FGVCAircraft (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FGVCAircraft/#function-fgvcaircraft-44","title":"function FGVCAircraft [4/4]","text":"<pre><code>xt::data::datasets::FGVCAircraft::FGVCAircraft (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/fgvc-aircraft.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/","title":"Class xt::data::datasets::FakeData","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FakeData</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#public-functions","title":"Public Functions","text":"Type Name FakeData ()  FakeData (size_t size)  FakeData (size_t size, vector&lt; int64_t &gt; shape)  FakeData (size_t size, vector&lt; int64_t &gt; shape, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#function-fakedata-14","title":"function FakeData [1/4]","text":"<pre><code>xt::data::datasets::FakeData::FakeData () \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#function-fakedata-24","title":"function FakeData [2/4]","text":"<pre><code>xt::data::datasets::FakeData::FakeData (\n    size_t size\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#function-fakedata-34","title":"function FakeData [3/4]","text":"<pre><code>xt::data::datasets::FakeData::FakeData (\n    size_t size,\n    vector&lt; int64_t &gt; shape\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FakeData/#function-fakedata-44","title":"function FakeData [4/4]","text":"<pre><code>xt::data::datasets::FakeData::FakeData (\n    size_t size,\n    vector&lt; int64_t &gt; shape,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/fake-data.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/","title":"Class xt::data::datasets::FallingThingsStereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FallingThingsStereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#public-functions","title":"Public Functions","text":"Type Name FallingThingsStereo (const std::string &amp; root)  FallingThingsStereo (const std::string &amp; root, DataMode mode)  FallingThingsStereo (const std::string &amp; root, DataMode mode, bool download)  FallingThingsStereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#function-fallingthingsstereo-14","title":"function FallingThingsStereo [1/4]","text":"<pre><code>explicit xt::data::datasets::FallingThingsStereo::FallingThingsStereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#function-fallingthingsstereo-24","title":"function FallingThingsStereo [2/4]","text":"<pre><code>xt::data::datasets::FallingThingsStereo::FallingThingsStereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#function-fallingthingsstereo-34","title":"function FallingThingsStereo [3/4]","text":"<pre><code>xt::data::datasets::FallingThingsStereo::FallingThingsStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FallingThingsStereo/#function-fallingthingsstereo-44","title":"function FallingThingsStereo [4/4]","text":"<pre><code>xt::data::datasets::FallingThingsStereo::FallingThingsStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/falling-things-stereo.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/","title":"Class xt::data::datasets::FashionMNIST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FashionMNIST</p> <p>Inherits the following classes: xt::data::datasets::MNISTBase</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#public-functions","title":"Public Functions","text":"Type Name FashionMNIST (const std::string &amp; root)  FashionMNIST (const std::string &amp; root, DataMode mode)  FashionMNIST (const std::string &amp; root, DataMode mode, bool download)  FashionMNIST (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#public-functions-inherited-from-xtdatadatasetsmnistbase","title":"Public Functions inherited from xt::data::datasets::MNISTBase","text":"<p>See xt::data::datasets::MNISTBase</p> Type Name MNISTBase (const std::string &amp; root)  MNISTBase (const std::string &amp; root, DataMode mode)  MNISTBase (const std::string &amp; root, DataMode mode, bool download)  MNISTBase (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  void read_images (const std::string &amp; file_path, int num_images)  void read_labels (const std::string &amp; file_path, int num_labels)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#function-fashionmnist-14","title":"function FashionMNIST [1/4]","text":"<pre><code>explicit xt::data::datasets::FashionMNIST::FashionMNIST (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#function-fashionmnist-24","title":"function FashionMNIST [2/4]","text":"<pre><code>xt::data::datasets::FashionMNIST::FashionMNIST (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#function-fashionmnist-34","title":"function FashionMNIST [3/4]","text":"<pre><code>xt::data::datasets::FashionMNIST::FashionMNIST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FashionMNIST/#function-fashionmnist-44","title":"function FashionMNIST [4/4]","text":"<pre><code>xt::data::datasets::FashionMNIST::FashionMNIST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/","title":"Class xt::data::datasets::Flickr30k","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Flickr30k</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#public-functions","title":"Public Functions","text":"Type Name Flickr30k (const std::string &amp; root, DataMode mode=DataMode::TRAIN, bool download=false)  Flickr30k (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#function-flickr30k-12","title":"function Flickr30k [1/2]","text":"<pre><code>xt::data::datasets::Flickr30k::Flickr30k (\n    const std::string &amp; root,\n    DataMode mode=DataMode::TRAIN,\n    bool download=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr30k/#function-flickr30k-22","title":"function Flickr30k [2/2]","text":"<pre><code>xt::data::datasets::Flickr30k::Flickr30k (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/flickr.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/","title":"Class xt::data::datasets::Flickr8k","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Flickr8k</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#public-functions","title":"Public Functions","text":"Type Name Flickr8k (const std::string &amp; root, DataMode mode=DataMode::TRAIN, bool download=false)  Flickr8k (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#function-flickr8k-12","title":"function Flickr8k [1/2]","text":"<pre><code>xt::data::datasets::Flickr8k::Flickr8k (\n    const std::string &amp; root,\n    DataMode mode=DataMode::TRAIN,\n    bool download=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flickr8k/#function-flickr8k-22","title":"function Flickr8k [2/2]","text":"<pre><code>xt::data::datasets::Flickr8k::Flickr8k (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/flickr.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/","title":"Class xt::data::datasets::Flowers102","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Flowers102</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#public-functions","title":"Public Functions","text":"Type Name Flowers102 (const std::string &amp; root)  Flowers102 (const std::string &amp; root, DataMode mode)  Flowers102 (const std::string &amp; root, DataMode mode, bool download)  Flowers102 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#function-flowers102-14","title":"function Flowers102 [1/4]","text":"<pre><code>explicit xt::data::datasets::Flowers102::Flowers102 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#function-flowers102-24","title":"function Flowers102 [2/4]","text":"<pre><code>xt::data::datasets::Flowers102::Flowers102 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#function-flowers102-34","title":"function Flowers102 [3/4]","text":"<pre><code>xt::data::datasets::Flowers102::Flowers102 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Flowers102/#function-flowers102-44","title":"function Flowers102 [4/4]","text":"<pre><code>xt::data::datasets::Flowers102::Flowers102 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/flowers.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/","title":"Class xt::data::datasets::FlyingChairs","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FlyingChairs</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#public-functions","title":"Public Functions","text":"Type Name FlyingChairs (const std::string &amp; root)  FlyingChairs (const std::string &amp; root, DataMode mode)  FlyingChairs (const std::string &amp; root, DataMode mode, bool download)  FlyingChairs (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#function-flyingchairs-14","title":"function FlyingChairs [1/4]","text":"<pre><code>explicit xt::data::datasets::FlyingChairs::FlyingChairs (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#function-flyingchairs-24","title":"function FlyingChairs [2/4]","text":"<pre><code>xt::data::datasets::FlyingChairs::FlyingChairs (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#function-flyingchairs-34","title":"function FlyingChairs [3/4]","text":"<pre><code>xt::data::datasets::FlyingChairs::FlyingChairs (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingChairs/#function-flyingchairs-44","title":"function FlyingChairs [4/4]","text":"<pre><code>xt::data::datasets::FlyingChairs::FlyingChairs (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/optical-flow/flying-chairs.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/","title":"Class xt::data::datasets::FlyingThings3D","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; FlyingThings3D</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#public-functions","title":"Public Functions","text":"Type Name FlyingThings3D (const std::string &amp; root)  FlyingThings3D (const std::string &amp; root, DataMode mode)  FlyingThings3D (const std::string &amp; root, DataMode mode, bool download)  FlyingThings3D (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#function-flyingthings3d-14","title":"function FlyingThings3D [1/4]","text":"<pre><code>explicit xt::data::datasets::FlyingThings3D::FlyingThings3D (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#function-flyingthings3d-24","title":"function FlyingThings3D [2/4]","text":"<pre><code>xt::data::datasets::FlyingThings3D::FlyingThings3D (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#function-flyingthings3d-34","title":"function FlyingThings3D [3/4]","text":"<pre><code>xt::data::datasets::FlyingThings3D::FlyingThings3D (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1FlyingThings3D/#function-flyingthings3d-44","title":"function FlyingThings3D [4/4]","text":"<pre><code>xt::data::datasets::FlyingThings3D::FlyingThings3D (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/scene-flow/flying-things-3d.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/","title":"Class xt::data::datasets::Food101","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Food101</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#public-functions","title":"Public Functions","text":"Type Name Food101 (const std::string &amp; root)  Food101 (const std::string &amp; root, DataMode mode)  Food101 (const std::string &amp; root, DataMode mode, bool download)  Food101 (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#function-food101-14","title":"function Food101 [1/4]","text":"<pre><code>explicit xt::data::datasets::Food101::Food101 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#function-food101-24","title":"function Food101 [2/4]","text":"<pre><code>xt::data::datasets::Food101::Food101 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#function-food101-34","title":"function Food101 [3/4]","text":"<pre><code>xt::data::datasets::Food101::Food101 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Food101/#function-food101-44","title":"function Food101 [4/4]","text":"<pre><code>xt::data::datasets::Food101::Food101 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/food.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/","title":"Class xt::data::datasets::GTSRB","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; GTSRB</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#public-functions","title":"Public Functions","text":"Type Name GTSRB (const std::string &amp; root)  GTSRB (const std::string &amp; root, DataMode mode)  GTSRB (const std::string &amp; root, DataMode mode, bool download)  GTSRB (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#function-gtsrb-14","title":"function GTSRB [1/4]","text":"<pre><code>explicit xt::data::datasets::GTSRB::GTSRB (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#function-gtsrb-24","title":"function GTSRB [2/4]","text":"<pre><code>xt::data::datasets::GTSRB::GTSRB (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#function-gtsrb-34","title":"function GTSRB [3/4]","text":"<pre><code>xt::data::datasets::GTSRB::GTSRB (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTSRB/#function-gtsrb-44","title":"function GTSRB [4/4]","text":"<pre><code>xt::data::datasets::GTSRB::GTSRB (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/gtsrb.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/","title":"Class xt::data::datasets::GTZAN","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; GTZAN</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#public-functions","title":"Public Functions","text":"Type Name GTZAN (const std::string &amp; root)  GTZAN (const std::string &amp; root, DataMode mode)  GTZAN (const std::string &amp; root, DataMode mode, bool download)  GTZAN (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#function-gtzan-14","title":"function GTZAN [1/4]","text":"<pre><code>explicit xt::data::datasets::GTZAN::GTZAN (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#function-gtzan-24","title":"function GTZAN [2/4]","text":"<pre><code>xt::data::datasets::GTZAN::GTZAN (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#function-gtzan-34","title":"function GTZAN [3/4]","text":"<pre><code>xt::data::datasets::GTZAN::GTZAN (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1GTZAN/#function-gtzan-44","title":"function GTZAN [4/4]","text":"<pre><code>xt::data::datasets::GTZAN::GTZAN (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/gtzan.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/","title":"Class xt::data::datasets::HD1K","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; HD1K</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#public-functions","title":"Public Functions","text":"Type Name HD1K (const std::string &amp; root)  HD1K (const std::string &amp; root, DataMode mode)  HD1K (const std::string &amp; root, DataMode mode, bool download)  HD1K (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#function-hd1k-14","title":"function HD1K [1/4]","text":"<pre><code>explicit xt::data::datasets::HD1K::HD1K (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#function-hd1k-24","title":"function HD1K [2/4]","text":"<pre><code>xt::data::datasets::HD1K::HD1K (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#function-hd1k-34","title":"function HD1K [3/4]","text":"<pre><code>xt::data::datasets::HD1K::HD1K (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HD1K/#function-hd1k-44","title":"function HD1K [4/4]","text":"<pre><code>xt::data::datasets::HD1K::HD1K (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/optical-flow/hd1k.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/","title":"Class xt::data::datasets::HMDB51","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; HMDB51</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#public-functions","title":"Public Functions","text":"Type Name HMDB51 (const std::string &amp; root)  HMDB51 (const std::string &amp; root, DataMode mode)  HMDB51 (const std::string &amp; root, DataMode mode, bool download)  HMDB51 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#function-hmdb51-14","title":"function HMDB51 [1/4]","text":"<pre><code>explicit xt::data::datasets::HMDB51::HMDB51 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#function-hmdb51-24","title":"function HMDB51 [2/4]","text":"<pre><code>xt::data::datasets::HMDB51::HMDB51 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#function-hmdb51-34","title":"function HMDB51 [3/4]","text":"<pre><code>xt::data::datasets::HMDB51::HMDB51 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1HMDB51/#function-hmdb51-44","title":"function HMDB51 [4/4]","text":"<pre><code>xt::data::datasets::HMDB51::HMDB51 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/hmdb.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/","title":"Class xt::data::datasets::IMDB","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; IMDB</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#public-functions","title":"Public Functions","text":"Type Name IMDB (const std::string &amp; root)  IMDB (const std::string &amp; root, DataMode mode)  IMDB (const std::string &amp; root, DataMode mode, bool download)  IMDB (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#function-imdb-14","title":"function IMDB [1/4]","text":"<pre><code>explicit xt::data::datasets::IMDB::IMDB (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#function-imdb-24","title":"function IMDB [2/4]","text":"<pre><code>xt::data::datasets::IMDB::IMDB (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#function-imdb-34","title":"function IMDB [3/4]","text":"<pre><code>xt::data::datasets::IMDB::IMDB (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IMDB/#function-imdb-44","title":"function IMDB [4/4]","text":"<pre><code>xt::data::datasets::IMDB::IMDB (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sentiment-analysis/imdb.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/","title":"Class xt::data::datasets::INaturalist","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; INaturalist</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#public-functions","title":"Public Functions","text":"Type Name INaturalist (const std::string &amp; root)  INaturalist (const std::string &amp; root, DataMode mode)  INaturalist (const std::string &amp; root, DataMode mode, bool download)  INaturalist (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#function-inaturalist-14","title":"function INaturalist [1/4]","text":"<pre><code>explicit xt::data::datasets::INaturalist::INaturalist (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#function-inaturalist-24","title":"function INaturalist [2/4]","text":"<pre><code>xt::data::datasets::INaturalist::INaturalist (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#function-inaturalist-34","title":"function INaturalist [3/4]","text":"<pre><code>xt::data::datasets::INaturalist::INaturalist (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1INaturalist/#function-inaturalist-44","title":"function INaturalist [4/4]","text":"<pre><code>xt::data::datasets::INaturalist::INaturalist (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/inaturalist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/","title":"Class xt::data::datasets::IWSLT","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; IWSLT</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#public-functions","title":"Public Functions","text":"Type Name IWSLT (const std::string &amp; root)  IWSLT (const std::string &amp; root, DataMode mode)  IWSLT (const std::string &amp; root, DataMode mode, bool download)  IWSLT (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#function-iwslt-14","title":"function IWSLT [1/4]","text":"<pre><code>explicit xt::data::datasets::IWSLT::IWSLT (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#function-iwslt-24","title":"function IWSLT [2/4]","text":"<pre><code>xt::data::datasets::IWSLT::IWSLT (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#function-iwslt-34","title":"function IWSLT [3/4]","text":"<pre><code>xt::data::datasets::IWSLT::IWSLT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1IWSLT/#function-iwslt-44","title":"function IWSLT [4/4]","text":"<pre><code>xt::data::datasets::IWSLT::IWSLT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/iwslt.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/","title":"Class xt::data::datasets::ImageFolder","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; ImageFolder</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#public-functions","title":"Public Functions","text":"Type Name ImageFolder (const std::string &amp; root)  ImageFolder (const std::string &amp; root, bool load_sub_folders)  ImageFolder (const std::string &amp; root, bool load_sub_folders, DataMode mode)  ImageFolder (const std::string &amp; root, bool load_sub_folders, DataMode mode, LabelsType label_type)  ImageFolder (const std::string &amp; root, bool load_sub_folders, DataMode mode, LabelsType label_type, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#function-imagefolder-15","title":"function ImageFolder [1/5]","text":"<pre><code>xt::data::datasets::ImageFolder::ImageFolder (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#function-imagefolder-25","title":"function ImageFolder [2/5]","text":"<pre><code>xt::data::datasets::ImageFolder::ImageFolder (\n    const std::string &amp; root,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#function-imagefolder-35","title":"function ImageFolder [3/5]","text":"<pre><code>xt::data::datasets::ImageFolder::ImageFolder (\n    const std::string &amp; root,\n    bool load_sub_folders,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#function-imagefolder-45","title":"function ImageFolder [4/5]","text":"<pre><code>xt::data::datasets::ImageFolder::ImageFolder (\n    const std::string &amp; root,\n    bool load_sub_folders,\n    DataMode mode,\n    LabelsType label_type\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageFolder/#function-imagefolder-55","title":"function ImageFolder [5/5]","text":"<pre><code>xt::data::datasets::ImageFolder::ImageFolder (\n    const std::string &amp; root,\n    bool load_sub_folders,\n    DataMode mode,\n    LabelsType label_type,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/image-folder.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/","title":"Class xt::data::datasets::ImageNet","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; ImageNet</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#public-functions","title":"Public Functions","text":"Type Name ImageNet (const std::string &amp; root)  ImageNet (const std::string &amp; root, DataMode mode)  ImageNet (const std::string &amp; root, DataMode mode, bool download)  ImageNet (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#function-imagenet-14","title":"function ImageNet [1/4]","text":"<pre><code>explicit xt::data::datasets::ImageNet::ImageNet (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#function-imagenet-24","title":"function ImageNet [2/4]","text":"<pre><code>xt::data::datasets::ImageNet::ImageNet (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#function-imagenet-34","title":"function ImageNet [3/4]","text":"<pre><code>xt::data::datasets::ImageNet::ImageNet (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1ImageNet/#function-imagenet-44","title":"function ImageNet [4/4]","text":"<pre><code>xt::data::datasets::ImageNet::ImageNet (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/imagenet.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/","title":"Class xt::data::datasets::Imagenette","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Imagenette</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#public-functions","title":"Public Functions","text":"Type Name Imagenette (const std::string &amp; root)  Imagenette (const std::string &amp; root, DataMode mode)  Imagenette (const std::string &amp; root, DataMode mode, bool download)  Imagenette (const std::string &amp; root, DataMode mode, bool download, ImageType type)  Imagenette (const std::string &amp; root, DataMode mode, bool download, ImageType type, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#function-imagenette-15","title":"function Imagenette [1/5]","text":"<pre><code>explicit xt::data::datasets::Imagenette::Imagenette (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#function-imagenette-25","title":"function Imagenette [2/5]","text":"<pre><code>xt::data::datasets::Imagenette::Imagenette (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#function-imagenette-35","title":"function Imagenette [3/5]","text":"<pre><code>xt::data::datasets::Imagenette::Imagenette (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#function-imagenette-45","title":"function Imagenette [4/5]","text":"<pre><code>xt::data::datasets::Imagenette::Imagenette (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    ImageType type\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Imagenette/#function-imagenette-55","title":"function Imagenette [5/5]","text":"<pre><code>xt::data::datasets::Imagenette::Imagenette (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    ImageType type,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/imagenette.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/","title":"Class xt::data::datasets::InStereo2k","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; InStereo2k</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#public-functions","title":"Public Functions","text":"Type Name InStereo2k (const std::string &amp; root)  InStereo2k (const std::string &amp; root, DataMode mode)  InStereo2k (const std::string &amp; root, DataMode mode, bool download)  InStereo2k (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#function-instereo2k-14","title":"function InStereo2k [1/4]","text":"<pre><code>explicit xt::data::datasets::InStereo2k::InStereo2k (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#function-instereo2k-24","title":"function InStereo2k [2/4]","text":"<pre><code>xt::data::datasets::InStereo2k::InStereo2k (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#function-instereo2k-34","title":"function InStereo2k [3/4]","text":"<pre><code>xt::data::datasets::InStereo2k::InStereo2k (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1InStereo2k/#function-instereo2k-44","title":"function InStereo2k [4/4]","text":"<pre><code>xt::data::datasets::InStereo2k::InStereo2k (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/in-stereo.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/","title":"Class xt::data::datasets::KMNIST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; KMNIST</p> <p>Inherits the following classes: xt::data::datasets::MNISTBase</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#public-functions","title":"Public Functions","text":"Type Name KMNIST (const std::string &amp; root, DataMode mode=DataMode::TRAIN, bool download=false)  KMNIST (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#public-functions-inherited-from-xtdatadatasetsmnistbase","title":"Public Functions inherited from xt::data::datasets::MNISTBase","text":"<p>See xt::data::datasets::MNISTBase</p> Type Name MNISTBase (const std::string &amp; root)  MNISTBase (const std::string &amp; root, DataMode mode)  MNISTBase (const std::string &amp; root, DataMode mode, bool download)  MNISTBase (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  void read_images (const std::string &amp; file_path, int num_images)  void read_labels (const std::string &amp; file_path, int num_labels)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#function-kmnist-12","title":"function KMNIST [1/2]","text":"<pre><code>xt::data::datasets::KMNIST::KMNIST (\n    const std::string &amp; root,\n    DataMode mode=DataMode::TRAIN,\n    bool download=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KMNIST/#function-kmnist-22","title":"function KMNIST [2/2]","text":"<pre><code>xt::data::datasets::KMNIST::KMNIST (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/","title":"Class xt::data::datasets::Kinetics","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Kinetics</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#public-functions","title":"Public Functions","text":"Type Name Kinetics (const std::string &amp; root)  Kinetics (const std::string &amp; root, DataMode mode)  Kinetics (const std::string &amp; root, DataMode mode, bool download)  Kinetics (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#function-kinetics-14","title":"function Kinetics [1/4]","text":"<pre><code>explicit xt::data::datasets::Kinetics::Kinetics (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#function-kinetics-24","title":"function Kinetics [2/4]","text":"<pre><code>xt::data::datasets::Kinetics::Kinetics (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#function-kinetics-34","title":"function Kinetics [3/4]","text":"<pre><code>xt::data::datasets::Kinetics::Kinetics (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kinetics/#function-kinetics-44","title":"function Kinetics [4/4]","text":"<pre><code>xt::data::datasets::Kinetics::Kinetics (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/kinetics.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/","title":"Class xt::data::datasets::Kitti","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Kitti</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#public-functions","title":"Public Functions","text":"Type Name Kitti (const std::string &amp; root)  Kitti (const std::string &amp; root, DataMode mode)  Kitti (const std::string &amp; root, DataMode mode, bool download)  Kitti (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#function-kitti-14","title":"function Kitti [1/4]","text":"<pre><code>explicit xt::data::datasets::Kitti::Kitti (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#function-kitti-24","title":"function Kitti [2/4]","text":"<pre><code>xt::data::datasets::Kitti::Kitti (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#function-kitti-34","title":"function Kitti [3/4]","text":"<pre><code>xt::data::datasets::Kitti::Kitti (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti/#function-kitti-44","title":"function Kitti [4/4]","text":"<pre><code>xt::data::datasets::Kitti::Kitti (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/kitti.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/","title":"Class xt::data::datasets::Kitti2012Stereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Kitti2012Stereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#public-functions","title":"Public Functions","text":"Type Name Kitti2012Stereo (const std::string &amp; root)  Kitti2012Stereo (const std::string &amp; root, DataMode mode)  Kitti2012Stereo (const std::string &amp; root, DataMode mode, bool download)  Kitti2012Stereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#function-kitti2012stereo-14","title":"function Kitti2012Stereo [1/4]","text":"<pre><code>explicit xt::data::datasets::Kitti2012Stereo::Kitti2012Stereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#function-kitti2012stereo-24","title":"function Kitti2012Stereo [2/4]","text":"<pre><code>xt::data::datasets::Kitti2012Stereo::Kitti2012Stereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#function-kitti2012stereo-34","title":"function Kitti2012Stereo [3/4]","text":"<pre><code>xt::data::datasets::Kitti2012Stereo::Kitti2012Stereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2012Stereo/#function-kitti2012stereo-44","title":"function Kitti2012Stereo [4/4]","text":"<pre><code>xt::data::datasets::Kitti2012Stereo::Kitti2012Stereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/kitti.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/","title":"Class xt::data::datasets::Kitti2015Stereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Kitti2015Stereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#public-functions","title":"Public Functions","text":"Type Name Kitti2015Stereo (const std::string &amp; root)  Kitti2015Stereo (const std::string &amp; root, DataMode mode)  Kitti2015Stereo (const std::string &amp; root, DataMode mode, bool download)  Kitti2015Stereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#function-kitti2015stereo-14","title":"function Kitti2015Stereo [1/4]","text":"<pre><code>explicit xt::data::datasets::Kitti2015Stereo::Kitti2015Stereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#function-kitti2015stereo-24","title":"function Kitti2015Stereo [2/4]","text":"<pre><code>xt::data::datasets::Kitti2015Stereo::Kitti2015Stereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#function-kitti2015stereo-34","title":"function Kitti2015Stereo [3/4]","text":"<pre><code>xt::data::datasets::Kitti2015Stereo::Kitti2015Stereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Kitti2015Stereo/#function-kitti2015stereo-44","title":"function Kitti2015Stereo [4/4]","text":"<pre><code>xt::data::datasets::Kitti2015Stereo::Kitti2015Stereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/kitti.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/","title":"Class xt::data::datasets::KittiFlow","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; KittiFlow</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#public-functions","title":"Public Functions","text":"Type Name KittiFlow (const std::string &amp; root)  KittiFlow (const std::string &amp; root, DataMode mode)  KittiFlow (const std::string &amp; root, DataMode mode, bool download)  KittiFlow (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#function-kittiflow-14","title":"function KittiFlow [1/4]","text":"<pre><code>explicit xt::data::datasets::KittiFlow::KittiFlow (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#function-kittiflow-24","title":"function KittiFlow [2/4]","text":"<pre><code>xt::data::datasets::KittiFlow::KittiFlow (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#function-kittiflow-34","title":"function KittiFlow [3/4]","text":"<pre><code>xt::data::datasets::KittiFlow::KittiFlow (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1KittiFlow/#function-kittiflow-44","title":"function KittiFlow [4/4]","text":"<pre><code>xt::data::datasets::KittiFlow::KittiFlow (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/kitti.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/","title":"Class xt::data::datasets::LFW","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; LFW</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p> <p>Inherited by the following classes: xt::data::datasets::LFWPairs,  xt::data::datasets::LFWPeople</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#public-functions","title":"Public Functions","text":"Type Name LFW (const std::string &amp; root)  LFW (const std::string &amp; root, DataMode mode)  LFW (const std::string &amp; root, DataMode mode, bool download)  LFW (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#function-lfw-14","title":"function LFW [1/4]","text":"<pre><code>explicit xt::data::datasets::LFW::LFW (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#function-lfw-24","title":"function LFW [2/4]","text":"<pre><code>xt::data::datasets::LFW::LFW (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#function-lfw-34","title":"function LFW [3/4]","text":"<pre><code>xt::data::datasets::LFW::LFW (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFW/#function-lfw-44","title":"function LFW [4/4]","text":"<pre><code>xt::data::datasets::LFW::LFW (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/lfw.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/","title":"Class xt::data::datasets::LFWPairs","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; LFWPairs</p> <p>Inherits the following classes: xt::data::datasets::LFW</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#public-functions","title":"Public Functions","text":"Type Name LFWPairs (const std::string &amp; root)  LFWPairs (const std::string &amp; root, DataMode mode)  LFWPairs (const std::string &amp; root, DataMode mode, bool download)  LFWPairs (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#public-functions-inherited-from-xtdatadatasetslfw","title":"Public Functions inherited from xt::data::datasets::LFW","text":"<p>See xt::data::datasets::LFW</p> Type Name LFW (const std::string &amp; root)  LFW (const std::string &amp; root, DataMode mode)  LFW (const std::string &amp; root, DataMode mode, bool download)  LFW (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#function-lfwpairs-14","title":"function LFWPairs [1/4]","text":"<pre><code>explicit xt::data::datasets::LFWPairs::LFWPairs (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#function-lfwpairs-24","title":"function LFWPairs [2/4]","text":"<pre><code>xt::data::datasets::LFWPairs::LFWPairs (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#function-lfwpairs-34","title":"function LFWPairs [3/4]","text":"<pre><code>xt::data::datasets::LFWPairs::LFWPairs (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPairs/#function-lfwpairs-44","title":"function LFWPairs [4/4]","text":"<pre><code>xt::data::datasets::LFWPairs::LFWPairs (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/lfw.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/","title":"Class xt::data::datasets::LFWPeople","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; LFWPeople</p> <p>Inherits the following classes: xt::data::datasets::LFW</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#public-functions","title":"Public Functions","text":"Type Name LFWPeople (const std::string &amp; root)  LFWPeople (const std::string &amp; root, DataMode mode)  LFWPeople (const std::string &amp; root, DataMode mode, bool download)  LFWPeople (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#public-functions-inherited-from-xtdatadatasetslfw","title":"Public Functions inherited from xt::data::datasets::LFW","text":"<p>See xt::data::datasets::LFW</p> Type Name LFW (const std::string &amp; root)  LFW (const std::string &amp; root, DataMode mode)  LFW (const std::string &amp; root, DataMode mode, bool download)  LFW (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#function-lfwpeople-14","title":"function LFWPeople [1/4]","text":"<pre><code>explicit xt::data::datasets::LFWPeople::LFWPeople (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#function-lfwpeople-24","title":"function LFWPeople [2/4]","text":"<pre><code>xt::data::datasets::LFWPeople::LFWPeople (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#function-lfwpeople-34","title":"function LFWPeople [3/4]","text":"<pre><code>xt::data::datasets::LFWPeople::LFWPeople (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LFWPeople/#function-lfwpeople-44","title":"function LFWPeople [4/4]","text":"<pre><code>xt::data::datasets::LFWPeople::LFWPeople (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/lfw.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/","title":"Class xt::data::datasets::LSUN","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; LSUN</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#public-functions","title":"Public Functions","text":"Type Name LSUN (const std::string &amp; root, DataMode mode=DataMode::TRAIN, bool download=false)  LSUN (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#function-lsun-12","title":"function LSUN [1/2]","text":"<pre><code>xt::data::datasets::LSUN::LSUN (\n    const std::string &amp; root,\n    DataMode mode=DataMode::TRAIN,\n    bool download=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LSUN/#function-lsun-22","title":"function LSUN [2/2]","text":"<pre><code>xt::data::datasets::LSUN::LSUN (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/lsun.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/","title":"Class xt::data::datasets::LibriSpeech","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; LibriSpeech</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#public-functions","title":"Public Functions","text":"Type Name LibriSpeech (const std::string &amp; root)  LibriSpeech (const std::string &amp; root, DataMode mode)  LibriSpeech (const std::string &amp; root, DataMode mode, bool download)  LibriSpeech (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#function-librispeech-14","title":"function LibriSpeech [1/4]","text":"<pre><code>explicit xt::data::datasets::LibriSpeech::LibriSpeech (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#function-librispeech-24","title":"function LibriSpeech [2/4]","text":"<pre><code>xt::data::datasets::LibriSpeech::LibriSpeech (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#function-librispeech-34","title":"function LibriSpeech [3/4]","text":"<pre><code>xt::data::datasets::LibriSpeech::LibriSpeech (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LibriSpeech/#function-librispeech-44","title":"function LibriSpeech [4/4]","text":"<pre><code>xt::data::datasets::LibriSpeech::LibriSpeech (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/librispeech.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/","title":"Class xt::data::datasets::LjSpeech","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; LjSpeech</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#public-functions","title":"Public Functions","text":"Type Name LjSpeech (const std::string &amp; root)  LjSpeech (const std::string &amp; root, DataMode mode)  LjSpeech (const std::string &amp; root, DataMode mode, bool download)  LjSpeech (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#function-ljspeech-14","title":"function LjSpeech [1/4]","text":"<pre><code>explicit xt::data::datasets::LjSpeech::LjSpeech (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#function-ljspeech-24","title":"function LjSpeech [2/4]","text":"<pre><code>xt::data::datasets::LjSpeech::LjSpeech (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#function-ljspeech-34","title":"function LjSpeech [3/4]","text":"<pre><code>xt::data::datasets::LjSpeech::LjSpeech (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1LjSpeech/#function-ljspeech-44","title":"function LjSpeech [4/4]","text":"<pre><code>xt::data::datasets::LjSpeech::LjSpeech (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/lj-speech.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/","title":"Class xt::data::datasets::MNIST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; MNIST</p> <p>Inherits the following classes: xt::data::datasets::MNISTBase</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#public-functions","title":"Public Functions","text":"Type Name MNIST (const std::string &amp; root)  MNIST (const std::string &amp; root, DataMode mode)  MNIST (const std::string &amp; root, DataMode mode, bool download)  MNIST (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  MNIST (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#public-functions-inherited-from-xtdatadatasetsmnistbase","title":"Public Functions inherited from xt::data::datasets::MNISTBase","text":"<p>See xt::data::datasets::MNISTBase</p> Type Name MNISTBase (const std::string &amp; root)  MNISTBase (const std::string &amp; root, DataMode mode)  MNISTBase (const std::string &amp; root, DataMode mode, bool download)  MNISTBase (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  void read_images (const std::string &amp; file_path, int num_images)  void read_labels (const std::string &amp; file_path, int num_labels)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#function-mnist-15","title":"function MNIST [1/5]","text":"<pre><code>explicit xt::data::datasets::MNIST::MNIST (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#function-mnist-25","title":"function MNIST [2/5]","text":"<pre><code>xt::data::datasets::MNIST::MNIST (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#function-mnist-35","title":"function MNIST [3/5]","text":"<pre><code>xt::data::datasets::MNIST::MNIST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#function-mnist-45","title":"function MNIST [4/5]","text":"<pre><code>xt::data::datasets::MNIST::MNIST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNIST/#function-mnist-55","title":"function MNIST [5/5]","text":"<pre><code>xt::data::datasets::MNIST::MNIST (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/","title":"Class xt::data::datasets::MNISTBase","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; MNISTBase</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p> <p>Inherited by the following classes: xt::data::datasets::EMNIST,  xt::data::datasets::FashionMNIST,  xt::data::datasets::KMNIST,  xt::data::datasets::MNIST,  xt::data::datasets::QMNIST</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#public-functions","title":"Public Functions","text":"Type Name MNISTBase (const std::string &amp; root)  MNISTBase (const std::string &amp; root, DataMode mode)  MNISTBase (const std::string &amp; root, DataMode mode, bool download)  MNISTBase (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  void read_images (const std::string &amp; file_path, int num_images)  void read_labels (const std::string &amp; file_path, int num_labels)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#function-mnistbase-14","title":"function MNISTBase [1/4]","text":"<pre><code>explicit xt::data::datasets::MNISTBase::MNISTBase (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#function-mnistbase-24","title":"function MNISTBase [2/4]","text":"<pre><code>xt::data::datasets::MNISTBase::MNISTBase (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#function-mnistbase-34","title":"function MNISTBase [3/4]","text":"<pre><code>xt::data::datasets::MNISTBase::MNISTBase (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#function-mnistbase-44","title":"function MNISTBase [4/4]","text":"<pre><code>xt::data::datasets::MNISTBase::MNISTBase (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#function-read_images","title":"function read_images","text":"<pre><code>void xt::data::datasets::MNISTBase::read_images (\n    const std::string &amp; file_path,\n    int num_images\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNISTBase/#function-read_labels","title":"function read_labels","text":"<pre><code>void xt::data::datasets::MNISTBase::read_labels (\n    const std::string &amp; file_path,\n    int num_labels\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/","title":"Class xt::data::datasets::MNLI","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; MNLI</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#public-functions","title":"Public Functions","text":"Type Name MNLI (const std::string &amp; root)  MNLI (const std::string &amp; root, DataMode mode)  MNLI (const std::string &amp; root, DataMode mode, bool download)  MNLI (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#function-mnli-14","title":"function MNLI [1/4]","text":"<pre><code>explicit xt::data::datasets::MNLI::MNLI (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#function-mnli-24","title":"function MNLI [2/4]","text":"<pre><code>xt::data::datasets::MNLI::MNLI (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#function-mnli-34","title":"function MNLI [3/4]","text":"<pre><code>xt::data::datasets::MNLI::MNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MNLI/#function-mnli-44","title":"function MNLI [4/4]","text":"<pre><code>xt::data::datasets::MNLI::MNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/mnli.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/","title":"Class xt::data::datasets::MRPC","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; MRPC</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#public-functions","title":"Public Functions","text":"Type Name MRPC (const std::string &amp; root)  MRPC (const std::string &amp; root, DataMode mode)  MRPC (const std::string &amp; root, DataMode mode, bool download)  MRPC (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#function-mrpc-14","title":"function MRPC [1/4]","text":"<pre><code>explicit xt::data::datasets::MRPC::MRPC (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#function-mrpc-24","title":"function MRPC [2/4]","text":"<pre><code>xt::data::datasets::MRPC::MRPC (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#function-mrpc-34","title":"function MRPC [3/4]","text":"<pre><code>xt::data::datasets::MRPC::MRPC (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MRPC/#function-mrpc-44","title":"function MRPC [4/4]","text":"<pre><code>xt::data::datasets::MRPC::MRPC (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/mrpc.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/","title":"Class xt::data::datasets::MULTI","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; MULTI</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#public-functions","title":"Public Functions","text":"Type Name MULTI (const std::string &amp; root)  MULTI (const std::string &amp; root, DataMode mode)  MULTI (const std::string &amp; root, DataMode mode, bool download)  MULTI (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#function-multi-14","title":"function MULTI [1/4]","text":"<pre><code>explicit xt::data::datasets::MULTI::MULTI (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#function-multi-24","title":"function MULTI [2/4]","text":"<pre><code>xt::data::datasets::MULTI::MULTI (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#function-multi-34","title":"function MULTI [3/4]","text":"<pre><code>xt::data::datasets::MULTI::MULTI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MULTI/#function-multi-44","title":"function MULTI [4/4]","text":"<pre><code>xt::data::datasets::MULTI::MULTI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/multi.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/","title":"Class xt::data::datasets::Middlebury2014Stereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Middlebury2014Stereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#public-functions","title":"Public Functions","text":"Type Name Middlebury2014Stereo (const std::string &amp; root)  Middlebury2014Stereo (const std::string &amp; root, DataMode mode)  Middlebury2014Stereo (const std::string &amp; root, DataMode mode, bool download)  Middlebury2014Stereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#function-middlebury2014stereo-14","title":"function Middlebury2014Stereo [1/4]","text":"<pre><code>explicit xt::data::datasets::Middlebury2014Stereo::Middlebury2014Stereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#function-middlebury2014stereo-24","title":"function Middlebury2014Stereo [2/4]","text":"<pre><code>xt::data::datasets::Middlebury2014Stereo::Middlebury2014Stereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#function-middlebury2014stereo-34","title":"function Middlebury2014Stereo [3/4]","text":"<pre><code>xt::data::datasets::Middlebury2014Stereo::Middlebury2014Stereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Middlebury2014Stereo/#function-middlebury2014stereo-44","title":"function Middlebury2014Stereo [4/4]","text":"<pre><code>xt::data::datasets::Middlebury2014Stereo::Middlebury2014Stereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/middlebury.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/","title":"Class xt::data::datasets::MovingMNIST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; MovingMNIST</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#public-functions","title":"Public Functions","text":"Type Name MovingMNIST (const std::string &amp; root)  MovingMNIST (const std::string &amp; root, DataMode mode)  MovingMNIST (const std::string &amp; root, DataMode mode, bool download)  MovingMNIST (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#function-movingmnist-14","title":"function MovingMNIST [1/4]","text":"<pre><code>explicit xt::data::datasets::MovingMNIST::MovingMNIST (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#function-movingmnist-24","title":"function MovingMNIST [2/4]","text":"<pre><code>xt::data::datasets::MovingMNIST::MovingMNIST (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#function-movingmnist-34","title":"function MovingMNIST [3/4]","text":"<pre><code>xt::data::datasets::MovingMNIST::MovingMNIST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1MovingMNIST/#function-movingmnist-44","title":"function MovingMNIST [4/4]","text":"<pre><code>xt::data::datasets::MovingMNIST::MovingMNIST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/moving-mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/","title":"Class xt::data::datasets::Omniglot","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Omniglot</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#public-functions","title":"Public Functions","text":"Type Name Omniglot (const std::string &amp; root)  Omniglot (const std::string &amp; root, DataMode mode)  Omniglot (const std::string &amp; root, DataMode mode, bool download)  Omniglot (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#function-omniglot-14","title":"function Omniglot [1/4]","text":"<pre><code>explicit xt::data::datasets::Omniglot::Omniglot (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#function-omniglot-24","title":"function Omniglot [2/4]","text":"<pre><code>xt::data::datasets::Omniglot::Omniglot (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#function-omniglot-34","title":"function Omniglot [3/4]","text":"<pre><code>xt::data::datasets::Omniglot::Omniglot (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Omniglot/#function-omniglot-44","title":"function Omniglot [4/4]","text":"<pre><code>xt::data::datasets::Omniglot::Omniglot (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/omniglot.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/","title":"Class xt::data::datasets::OxfordIIITPet","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; OxfordIIITPet</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#public-functions","title":"Public Functions","text":"Type Name OxfordIIITPet (const std::string &amp; root)  OxfordIIITPet (const std::string &amp; root, DataMode mode)  OxfordIIITPet (const std::string &amp; root, DataMode mode, bool download)  OxfordIIITPet (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#function-oxfordiiitpet-14","title":"function OxfordIIITPet [1/4]","text":"<pre><code>explicit xt::data::datasets::OxfordIIITPet::OxfordIIITPet (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#function-oxfordiiitpet-24","title":"function OxfordIIITPet [2/4]","text":"<pre><code>xt::data::datasets::OxfordIIITPet::OxfordIIITPet (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#function-oxfordiiitpet-34","title":"function OxfordIIITPet [3/4]","text":"<pre><code>xt::data::datasets::OxfordIIITPet::OxfordIIITPet (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1OxfordIIITPet/#function-oxfordiiitpet-44","title":"function OxfordIIITPet [4/4]","text":"<pre><code>xt::data::datasets::OxfordIIITPet::OxfordIIITPet (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/oxfordIII-t-pet.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/","title":"Class xt::data::datasets::PCAM","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; PCAM</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#public-functions","title":"Public Functions","text":"Type Name PCAM (const std::string &amp; root)  PCAM (const std::string &amp; root, DataMode mode)  PCAM (const std::string &amp; root, DataMode mode, bool download)  PCAM (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#function-pcam-14","title":"function PCAM [1/4]","text":"<pre><code>explicit xt::data::datasets::PCAM::PCAM (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#function-pcam-24","title":"function PCAM [2/4]","text":"<pre><code>xt::data::datasets::PCAM::PCAM (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#function-pcam-34","title":"function PCAM [3/4]","text":"<pre><code>xt::data::datasets::PCAM::PCAM (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PCAM/#function-pcam-44","title":"function PCAM [4/4]","text":"<pre><code>xt::data::datasets::PCAM::PCAM (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/pcam.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/","title":"Class xt::data::datasets::PennTreebank","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; PennTreebank</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#public-functions","title":"Public Functions","text":"Type Name PennTreebank (const std::string &amp; root)  PennTreebank (const std::string &amp; root, DataMode mode)  PennTreebank (const std::string &amp; root, DataMode mode, bool download)  PennTreebank (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#function-penntreebank-14","title":"function PennTreebank [1/4]","text":"<pre><code>explicit xt::data::datasets::PennTreebank::PennTreebank (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#function-penntreebank-24","title":"function PennTreebank [2/4]","text":"<pre><code>xt::data::datasets::PennTreebank::PennTreebank (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#function-penntreebank-34","title":"function PennTreebank [3/4]","text":"<pre><code>xt::data::datasets::PennTreebank::PennTreebank (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PennTreebank/#function-penntreebank-44","title":"function PennTreebank [4/4]","text":"<pre><code>xt::data::datasets::PennTreebank::PennTreebank (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/penn-treebank.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/","title":"Class xt::data::datasets::PhotoTour","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; PhotoTour</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#public-functions","title":"Public Functions","text":"Type Name PhotoTour (const std::string &amp; root)  PhotoTour (const std::string &amp; root, DataMode mode)  PhotoTour (const std::string &amp; root, DataMode mode, bool download)  PhotoTour (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#function-phototour-14","title":"function PhotoTour [1/4]","text":"<pre><code>explicit xt::data::datasets::PhotoTour::PhotoTour (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#function-phototour-24","title":"function PhotoTour [2/4]","text":"<pre><code>xt::data::datasets::PhotoTour::PhotoTour (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#function-phototour-34","title":"function PhotoTour [3/4]","text":"<pre><code>xt::data::datasets::PhotoTour::PhotoTour (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1PhotoTour/#function-phototour-44","title":"function PhotoTour [4/4]","text":"<pre><code>xt::data::datasets::PhotoTour::PhotoTour (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/patch-matching-descriptor-learning/photo-tour.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/","title":"Class xt::data::datasets::Places365","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Places365</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#public-functions","title":"Public Functions","text":"Type Name Places365 (const std::string &amp; root)  Places365 (const std::string &amp; root, DataMode mode)  Places365 (const std::string &amp; root, DataMode mode, bool download)  Places365 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#function-places365-14","title":"function Places365 [1/4]","text":"<pre><code>explicit xt::data::datasets::Places365::Places365 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#function-places365-24","title":"function Places365 [2/4]","text":"<pre><code>xt::data::datasets::Places365::Places365 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#function-places365-34","title":"function Places365 [3/4]","text":"<pre><code>xt::data::datasets::Places365::Places365 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Places365/#function-places365-44","title":"function Places365 [4/4]","text":"<pre><code>xt::data::datasets::Places365::Places365 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/places.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/","title":"Class xt::data::datasets::QMNIST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; QMNIST</p> <p>Inherits the following classes: xt::data::datasets::MNISTBase</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#public-functions","title":"Public Functions","text":"Type Name QMNIST (const std::string &amp; root, DataMode mode=DataMode::TRAIN, bool download=false)  QMNIST (const fs::path &amp; root, DatasetArguments args)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#public-functions-inherited-from-xtdatadatasetsmnistbase","title":"Public Functions inherited from xt::data::datasets::MNISTBase","text":"<p>See xt::data::datasets::MNISTBase</p> Type Name MNISTBase (const std::string &amp; root)  MNISTBase (const std::string &amp; root, DataMode mode)  MNISTBase (const std::string &amp; root, DataMode mode, bool download)  MNISTBase (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  void read_images (const std::string &amp; file_path, int num_images)  void read_labels (const std::string &amp; file_path, int num_labels)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#function-qmnist-12","title":"function QMNIST [1/2]","text":"<pre><code>xt::data::datasets::QMNIST::QMNIST (\n    const std::string &amp; root,\n    DataMode mode=DataMode::TRAIN,\n    bool download=false\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QMNIST/#function-qmnist-22","title":"function QMNIST [2/2]","text":"<pre><code>xt::data::datasets::QMNIST::QMNIST (\n    const fs::path &amp; root,\n    DatasetArguments args\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/","title":"Class xt::data::datasets::QNLI","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; QNLI</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#public-functions","title":"Public Functions","text":"Type Name QNLI (const std::string &amp; root)  QNLI (const std::string &amp; root, DataMode mode)  QNLI (const std::string &amp; root, DataMode mode, bool download)  QNLI (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#function-qnli-14","title":"function QNLI [1/4]","text":"<pre><code>explicit xt::data::datasets::QNLI::QNLI (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#function-qnli-24","title":"function QNLI [2/4]","text":"<pre><code>xt::data::datasets::QNLI::QNLI (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#function-qnli-34","title":"function QNLI [3/4]","text":"<pre><code>xt::data::datasets::QNLI::QNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QNLI/#function-qnli-44","title":"function QNLI [4/4]","text":"<pre><code>xt::data::datasets::QNLI::QNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/qnli.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/","title":"Class xt::data::datasets::QQP","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; QQP</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#public-functions","title":"Public Functions","text":"Type Name QQP (const std::string &amp; root)  QQP (const std::string &amp; root, DataMode mode)  QQP (const std::string &amp; root, DataMode mode, bool download)  QQP (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#function-qqp-14","title":"function QQP [1/4]","text":"<pre><code>explicit xt::data::datasets::QQP::QQP (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#function-qqp-24","title":"function QQP [2/4]","text":"<pre><code>xt::data::datasets::QQP::QQP (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#function-qqp-34","title":"function QQP [3/4]","text":"<pre><code>xt::data::datasets::QQP::QQP (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1QQP/#function-qqp-44","title":"function QQP [4/4]","text":"<pre><code>xt::data::datasets::QQP::QQP (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/qqp.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/","title":"Class xt::data::datasets::RTE","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; RTE</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#public-functions","title":"Public Functions","text":"Type Name RTE (const std::string &amp; root)  RTE (const std::string &amp; root, DataMode mode)  RTE (const std::string &amp; root, DataMode mode, bool download)  RTE (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#function-rte-14","title":"function RTE [1/4]","text":"<pre><code>explicit xt::data::datasets::RTE::RTE (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#function-rte-24","title":"function RTE [2/4]","text":"<pre><code>xt::data::datasets::RTE::RTE (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#function-rte-34","title":"function RTE [3/4]","text":"<pre><code>xt::data::datasets::RTE::RTE (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RTE/#function-rte-44","title":"function RTE [4/4]","text":"<pre><code>xt::data::datasets::RTE::RTE (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/rte.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/","title":"Class xt::data::datasets::RenderedSST2","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; RenderedSST2</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#public-functions","title":"Public Functions","text":"Type Name RenderedSST2 (const std::string &amp; root)  RenderedSST2 (const std::string &amp; root, DataMode mode)  RenderedSST2 (const std::string &amp; root, DataMode mode, bool download)  RenderedSST2 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#function-renderedsst2-14","title":"function RenderedSST2 [1/4]","text":"<pre><code>explicit xt::data::datasets::RenderedSST2::RenderedSST2 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#function-renderedsst2-24","title":"function RenderedSST2 [2/4]","text":"<pre><code>xt::data::datasets::RenderedSST2::RenderedSST2 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#function-renderedsst2-34","title":"function RenderedSST2 [3/4]","text":"<pre><code>xt::data::datasets::RenderedSST2::RenderedSST2 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1RenderedSST2/#function-renderedsst2-44","title":"function RenderedSST2 [4/4]","text":"<pre><code>xt::data::datasets::RenderedSST2::RenderedSST2 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/rendered-sst2.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/","title":"Class xt::data::datasets::SBDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SBDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#public-functions","title":"Public Functions","text":"Type Name SBDataset (const std::string &amp; root)  SBDataset (const std::string &amp; root, DataMode mode)  SBDataset (const std::string &amp; root, DataMode mode, bool download)  SBDataset (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#function-sbdataset-14","title":"function SBDataset [1/4]","text":"<pre><code>explicit xt::data::datasets::SBDataset::SBDataset (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#function-sbdataset-24","title":"function SBDataset [2/4]","text":"<pre><code>xt::data::datasets::SBDataset::SBDataset (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#function-sbdataset-34","title":"function SBDataset [3/4]","text":"<pre><code>xt::data::datasets::SBDataset::SBDataset (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBDataset/#function-sbdataset-44","title":"function SBDataset [4/4]","text":"<pre><code>xt::data::datasets::SBDataset::SBDataset (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/sb-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/","title":"Class xt::data::datasets::SBU","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SBU</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#public-functions","title":"Public Functions","text":"Type Name SBU (const std::string &amp; root)  SBU (const std::string &amp; root, DataMode mode)  SBU (const std::string &amp; root, DataMode mode, bool download)  SBU (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#function-sbu-14","title":"function SBU [1/4]","text":"<pre><code>explicit xt::data::datasets::SBU::SBU (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#function-sbu-24","title":"function SBU [2/4]","text":"<pre><code>xt::data::datasets::SBU::SBU (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#function-sbu-34","title":"function SBU [3/4]","text":"<pre><code>xt::data::datasets::SBU::SBU (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SBU/#function-sbu-44","title":"function SBU [4/4]","text":"<pre><code>xt::data::datasets::SBU::SBU (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/sbu.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/","title":"Class xt::data::datasets::SEMEION","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SEMEION</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#public-functions","title":"Public Functions","text":"Type Name SEMEION (const std::string &amp; root)  SEMEION (const std::string &amp; root, DataMode mode)  SEMEION (const std::string &amp; root, DataMode mode, bool download)  SEMEION (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#function-semeion-14","title":"function SEMEION [1/4]","text":"<pre><code>explicit xt::data::datasets::SEMEION::SEMEION (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#function-semeion-24","title":"function SEMEION [2/4]","text":"<pre><code>xt::data::datasets::SEMEION::SEMEION (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#function-semeion-34","title":"function SEMEION [3/4]","text":"<pre><code>xt::data::datasets::SEMEION::SEMEION (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SEMEION/#function-semeion-44","title":"function SEMEION [4/4]","text":"<pre><code>xt::data::datasets::SEMEION::SEMEION (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/semeion.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/","title":"Class xt::data::datasets::SNLI","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SNLI</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#public-functions","title":"Public Functions","text":"Type Name SNLI (const std::string &amp; root)  SNLI (const std::string &amp; root, DataMode mode)  SNLI (const std::string &amp; root, DataMode mode, bool download)  SNLI (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#function-snli-14","title":"function SNLI [1/4]","text":"<pre><code>explicit xt::data::datasets::SNLI::SNLI (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#function-snli-24","title":"function SNLI [2/4]","text":"<pre><code>xt::data::datasets::SNLI::SNLI (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#function-snli-34","title":"function SNLI [3/4]","text":"<pre><code>xt::data::datasets::SNLI::SNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SNLI/#function-snli-44","title":"function SNLI [4/4]","text":"<pre><code>xt::data::datasets::SNLI::SNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/snli.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/","title":"Class xt::data::datasets::SST","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SST</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#public-functions","title":"Public Functions","text":"Type Name SST (const std::string &amp; root)  SST (const std::string &amp; root, DataMode mode)  SST (const std::string &amp; root, DataMode mode, bool download)  SST (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#function-sst-14","title":"function SST [1/4]","text":"<pre><code>explicit xt::data::datasets::SST::SST (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#function-sst-24","title":"function SST [2/4]","text":"<pre><code>xt::data::datasets::SST::SST (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#function-sst-34","title":"function SST [3/4]","text":"<pre><code>xt::data::datasets::SST::SST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SST/#function-sst-44","title":"function SST [4/4]","text":"<pre><code>xt::data::datasets::SST::SST (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sentiment-analysis/sst.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/","title":"Class xt::data::datasets::STL10","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; STL10</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#public-functions","title":"Public Functions","text":"Type Name STL10 (const std::string &amp; root)  STL10 (const std::string &amp; root, DataMode mode)  STL10 (const std::string &amp; root, DataMode mode, bool download)  STL10 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#function-stl10-14","title":"function STL10 [1/4]","text":"<pre><code>explicit xt::data::datasets::STL10::STL10 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#function-stl10-24","title":"function STL10 [2/4]","text":"<pre><code>xt::data::datasets::STL10::STL10 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#function-stl10-34","title":"function STL10 [3/4]","text":"<pre><code>xt::data::datasets::STL10::STL10 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STL10/#function-stl10-44","title":"function STL10 [4/4]","text":"<pre><code>xt::data::datasets::STL10::STL10 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/stl.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/","title":"Class xt::data::datasets::STSB","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; STSB</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#public-functions","title":"Public Functions","text":"Type Name STSB (const std::string &amp; root)  STSB (const std::string &amp; root, DataMode mode)  STSB (const std::string &amp; root, DataMode mode, bool download)  STSB (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#function-stsb-14","title":"function STSB [1/4]","text":"<pre><code>explicit xt::data::datasets::STSB::STSB (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#function-stsb-24","title":"function STSB [2/4]","text":"<pre><code>xt::data::datasets::STSB::STSB (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#function-stsb-34","title":"function STSB [3/4]","text":"<pre><code>xt::data::datasets::STSB::STSB (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1STSB/#function-stsb-44","title":"function STSB [4/4]","text":"<pre><code>xt::data::datasets::STSB::STSB (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/stsb.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/","title":"Class xt::data::datasets::SUN397","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SUN397</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#public-functions","title":"Public Functions","text":"Type Name SUN397 (const std::string &amp; root)  SUN397 (const std::string &amp; root, DataMode mode)  SUN397 (const std::string &amp; root, DataMode mode, bool download)  SUN397 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#function-sun397-14","title":"function SUN397 [1/4]","text":"<pre><code>explicit xt::data::datasets::SUN397::SUN397 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#function-sun397-24","title":"function SUN397 [2/4]","text":"<pre><code>xt::data::datasets::SUN397::SUN397 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#function-sun397-34","title":"function SUN397 [3/4]","text":"<pre><code>xt::data::datasets::SUN397::SUN397 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SUN397/#function-sun397-44","title":"function SUN397 [4/4]","text":"<pre><code>xt::data::datasets::SUN397::SUN397 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/sun.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/","title":"Class xt::data::datasets::SVHN","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SVHN</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#public-functions","title":"Public Functions","text":"Type Name SVHN (const std::string &amp; root)  SVHN (const std::string &amp; root, DataMode mode)  SVHN (const std::string &amp; root, DataMode mode, bool download)  SVHN (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#function-svhn-14","title":"function SVHN [1/4]","text":"<pre><code>explicit xt::data::datasets::SVHN::SVHN (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#function-svhn-24","title":"function SVHN [2/4]","text":"<pre><code>xt::data::datasets::SVHN::SVHN (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#function-svhn-34","title":"function SVHN [3/4]","text":"<pre><code>xt::data::datasets::SVHN::SVHN (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SVHN/#function-svhn-44","title":"function SVHN [4/4]","text":"<pre><code>xt::data::datasets::SVHN::SVHN (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/svhn.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/","title":"Class xt::data::datasets::SceneFlowStereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SceneFlowStereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#public-functions","title":"Public Functions","text":"Type Name SceneFlowStereo (const std::string &amp; root)  SceneFlowStereo (const std::string &amp; root, DataMode mode)  SceneFlowStereo (const std::string &amp; root, DataMode mode, bool download)  SceneFlowStereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#function-sceneflowstereo-14","title":"function SceneFlowStereo [1/4]","text":"<pre><code>explicit xt::data::datasets::SceneFlowStereo::SceneFlowStereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#function-sceneflowstereo-24","title":"function SceneFlowStereo [2/4]","text":"<pre><code>xt::data::datasets::SceneFlowStereo::SceneFlowStereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#function-sceneflowstereo-34","title":"function SceneFlowStereo [3/4]","text":"<pre><code>xt::data::datasets::SceneFlowStereo::SceneFlowStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SceneFlowStereo/#function-sceneflowstereo-44","title":"function SceneFlowStereo [4/4]","text":"<pre><code>xt::data::datasets::SceneFlowStereo::SceneFlowStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/scene-flow-stereo.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/","title":"Class xt::data::datasets::Sintel","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Sintel</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#public-functions","title":"Public Functions","text":"Type Name Sintel (const std::string &amp; root)  Sintel (const std::string &amp; root, DataMode mode)  Sintel (const std::string &amp; root, DataMode mode, bool download)  Sintel (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#function-sintel-14","title":"function Sintel [1/4]","text":"<pre><code>explicit xt::data::datasets::Sintel::Sintel (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#function-sintel-24","title":"function Sintel [2/4]","text":"<pre><code>xt::data::datasets::Sintel::Sintel (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#function-sintel-34","title":"function Sintel [3/4]","text":"<pre><code>xt::data::datasets::Sintel::Sintel (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Sintel/#function-sintel-44","title":"function Sintel [4/4]","text":"<pre><code>xt::data::datasets::Sintel::Sintel (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/sintel.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/","title":"Class xt::data::datasets::SintelStereo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SintelStereo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#public-functions","title":"Public Functions","text":"Type Name SintelStereo (const std::string &amp; root)  SintelStereo (const std::string &amp; root, DataMode mode)  SintelStereo (const std::string &amp; root, DataMode mode, bool download)  SintelStereo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#function-sintelstereo-14","title":"function SintelStereo [1/4]","text":"<pre><code>xt::data::datasets::SintelStereo::SintelStereo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#function-sintelstereo-24","title":"function SintelStereo [2/4]","text":"<pre><code>xt::data::datasets::SintelStereo::SintelStereo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#function-sintelstereo-34","title":"function SintelStereo [3/4]","text":"<pre><code>xt::data::datasets::SintelStereo::SintelStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SintelStereo/#function-sintelstereo-44","title":"function SintelStereo [4/4]","text":"<pre><code>xt::data::datasets::SintelStereo::SintelStereo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/sintel.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/","title":"Class xt::data::datasets::SogouNews","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SogouNews</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#public-functions","title":"Public Functions","text":"Type Name SogouNews (const std::string &amp; root)  SogouNews (const std::string &amp; root, DataMode mode)  SogouNews (const std::string &amp; root, DataMode mode, bool download)  SogouNews (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#function-sogounews-14","title":"function SogouNews [1/4]","text":"<pre><code>explicit xt::data::datasets::SogouNews::SogouNews (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#function-sogounews-24","title":"function SogouNews [2/4]","text":"<pre><code>xt::data::datasets::SogouNews::SogouNews (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#function-sogounews-34","title":"function SogouNews [3/4]","text":"<pre><code>xt::data::datasets::SogouNews::SogouNews (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SogouNews/#function-sogounews-44","title":"function SogouNews [4/4]","text":"<pre><code>xt::data::datasets::SogouNews::SogouNews (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/sogou-news.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/","title":"Class xt::data::datasets::SpeechCommands","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; SpeechCommands</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#public-functions","title":"Public Functions","text":"Type Name SpeechCommands (const std::string &amp; root)  SpeechCommands (const std::string &amp; root, DataMode mode)  SpeechCommands (const std::string &amp; root, DataMode mode, bool download)  SpeechCommands (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#function-speechcommands-14","title":"function SpeechCommands [1/4]","text":"<pre><code>explicit xt::data::datasets::SpeechCommands::SpeechCommands (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#function-speechcommands-24","title":"function SpeechCommands [2/4]","text":"<pre><code>xt::data::datasets::SpeechCommands::SpeechCommands (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#function-speechcommands-34","title":"function SpeechCommands [3/4]","text":"<pre><code>xt::data::datasets::SpeechCommands::SpeechCommands (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1SpeechCommands/#function-speechcommands-44","title":"function SpeechCommands [4/4]","text":"<pre><code>xt::data::datasets::SpeechCommands::SpeechCommands (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/speech-commands.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/","title":"Class xt::data::datasets::StackedAudioDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StackedAudioDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#public-functions","title":"Public Functions","text":"Type Name StackedAudioDataset (const std::string &amp; folder_path)  StackedAudioDataset (const std::string &amp; folder_path, DataMode mode)  StackedAudioDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders)  StackedAudioDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#function-stackedaudiodataset-14","title":"function StackedAudioDataset [1/4]","text":"<pre><code>xt::data::datasets::StackedAudioDataset::StackedAudioDataset (\n    const std::string &amp; folder_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#function-stackedaudiodataset-24","title":"function StackedAudioDataset [2/4]","text":"<pre><code>xt::data::datasets::StackedAudioDataset::StackedAudioDataset (\n    const std::string &amp; folder_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#function-stackedaudiodataset-34","title":"function StackedAudioDataset [3/4]","text":"<pre><code>xt::data::datasets::StackedAudioDataset::StackedAudioDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedAudioDataset/#function-stackedaudiodataset-44","title":"function StackedAudioDataset [4/4]","text":"<pre><code>xt::data::datasets::StackedAudioDataset::StackedAudioDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/audio-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/","title":"Class xt::data::datasets::StackedCSVDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StackedCSVDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#public-functions","title":"Public Functions","text":"Type Name StackedCSVDataset (const std::string &amp; folder_path)  StackedCSVDataset (const std::string &amp; folder_path, DataMode mode)  StackedCSVDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders)  StackedCSVDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#function-stackedcsvdataset-14","title":"function StackedCSVDataset [1/4]","text":"<pre><code>xt::data::datasets::StackedCSVDataset::StackedCSVDataset (\n    const std::string &amp; folder_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#function-stackedcsvdataset-24","title":"function StackedCSVDataset [2/4]","text":"<pre><code>xt::data::datasets::StackedCSVDataset::StackedCSVDataset (\n    const std::string &amp; folder_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#function-stackedcsvdataset-34","title":"function StackedCSVDataset [3/4]","text":"<pre><code>xt::data::datasets::StackedCSVDataset::StackedCSVDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedCSVDataset/#function-stackedcsvdataset-44","title":"function StackedCSVDataset [4/4]","text":"<pre><code>xt::data::datasets::StackedCSVDataset::StackedCSVDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/csv-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/","title":"Class xt::data::datasets::StackedEDFDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StackedEDFDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#public-functions","title":"Public Functions","text":"Type Name StackedEDFDataset (const std::string &amp; folder_path)  StackedEDFDataset (const std::string &amp; folder_path, DataMode mode)  StackedEDFDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders)  StackedEDFDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#function-stackededfdataset-14","title":"function StackedEDFDataset [1/4]","text":"<pre><code>xt::data::datasets::StackedEDFDataset::StackedEDFDataset (\n    const std::string &amp; folder_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#function-stackededfdataset-24","title":"function StackedEDFDataset [2/4]","text":"<pre><code>xt::data::datasets::StackedEDFDataset::StackedEDFDataset (\n    const std::string &amp; folder_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#function-stackededfdataset-34","title":"function StackedEDFDataset [3/4]","text":"<pre><code>xt::data::datasets::StackedEDFDataset::StackedEDFDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedEDFDataset/#function-stackededfdataset-44","title":"function StackedEDFDataset [4/4]","text":"<pre><code>xt::data::datasets::StackedEDFDataset::StackedEDFDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/edf-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/","title":"Class xt::data::datasets::StackedTextDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StackedTextDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#public-functions","title":"Public Functions","text":"Type Name StackedTextDataset (const std::string &amp; folder_path)  StackedTextDataset (const std::string &amp; folder_path, DataMode mode)  StackedTextDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders)  StackedTextDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#function-stackedtextdataset-14","title":"function StackedTextDataset [1/4]","text":"<pre><code>xt::data::datasets::StackedTextDataset::StackedTextDataset (\n    const std::string &amp; folder_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#function-stackedtextdataset-24","title":"function StackedTextDataset [2/4]","text":"<pre><code>xt::data::datasets::StackedTextDataset::StackedTextDataset (\n    const std::string &amp; folder_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#function-stackedtextdataset-34","title":"function StackedTextDataset [3/4]","text":"<pre><code>xt::data::datasets::StackedTextDataset::StackedTextDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTextDataset/#function-stackedtextdataset-44","title":"function StackedTextDataset [4/4]","text":"<pre><code>xt::data::datasets::StackedTextDataset::StackedTextDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/text-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/","title":"Class xt::data::datasets::StackedTimeSeriesDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StackedTimeSeriesDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#public-functions","title":"Public Functions","text":"Type Name StackedTimeSeriesDataset (const std::string &amp; folder_path)  StackedTimeSeriesDataset (const std::string &amp; folder_path, DataMode mode)  StackedTimeSeriesDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders)  StackedTimeSeriesDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#function-stackedtimeseriesdataset-14","title":"function StackedTimeSeriesDataset [1/4]","text":"<pre><code>xt::data::datasets::StackedTimeSeriesDataset::StackedTimeSeriesDataset (\n    const std::string &amp; folder_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#function-stackedtimeseriesdataset-24","title":"function StackedTimeSeriesDataset [2/4]","text":"<pre><code>xt::data::datasets::StackedTimeSeriesDataset::StackedTimeSeriesDataset (\n    const std::string &amp; folder_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#function-stackedtimeseriesdataset-34","title":"function StackedTimeSeriesDataset [3/4]","text":"<pre><code>xt::data::datasets::StackedTimeSeriesDataset::StackedTimeSeriesDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedTimeSeriesDataset/#function-stackedtimeseriesdataset-44","title":"function StackedTimeSeriesDataset [4/4]","text":"<pre><code>xt::data::datasets::StackedTimeSeriesDataset::StackedTimeSeriesDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/time-series-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/","title":"Class xt::data::datasets::StackedVideoDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StackedVideoDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#public-functions","title":"Public Functions","text":"Type Name StackedVideoDataset (const std::string &amp; folder_path)  StackedVideoDataset (const std::string &amp; folder_path, DataMode mode)  StackedVideoDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders)  StackedVideoDataset (const std::string &amp; folder_path, DataMode mode, bool load_sub_folders, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#function-stackedvideodataset-14","title":"function StackedVideoDataset [1/4]","text":"<pre><code>xt::data::datasets::StackedVideoDataset::StackedVideoDataset (\n    const std::string &amp; folder_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#function-stackedvideodataset-24","title":"function StackedVideoDataset [2/4]","text":"<pre><code>xt::data::datasets::StackedVideoDataset::StackedVideoDataset (\n    const std::string &amp; folder_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#function-stackedvideodataset-34","title":"function StackedVideoDataset [3/4]","text":"<pre><code>xt::data::datasets::StackedVideoDataset::StackedVideoDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StackedVideoDataset/#function-stackedvideodataset-44","title":"function StackedVideoDataset [4/4]","text":"<pre><code>xt::data::datasets::StackedVideoDataset::StackedVideoDataset (\n    const std::string &amp; folder_path,\n    DataMode mode,\n    bool load_sub_folders,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/video-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/","title":"Class xt::data::datasets::StanfordCars","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; StanfordCars</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#public-functions","title":"Public Functions","text":"Type Name StanfordCars (const std::string &amp; root)  StanfordCars (const std::string &amp; root, DataMode mode)  StanfordCars (const std::string &amp; root, DataMode mode, bool download)  StanfordCars (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#function-stanfordcars-14","title":"function StanfordCars [1/4]","text":"<pre><code>explicit xt::data::datasets::StanfordCars::StanfordCars (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#function-stanfordcars-24","title":"function StanfordCars [2/4]","text":"<pre><code>xt::data::datasets::StanfordCars::StanfordCars (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#function-stanfordcars-34","title":"function StanfordCars [3/4]","text":"<pre><code>xt::data::datasets::StanfordCars::StanfordCars (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1StanfordCars/#function-stanfordcars-44","title":"function StanfordCars [4/4]","text":"<pre><code>xt::data::datasets::StanfordCars::StanfordCars (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/stanford-cars.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/","title":"Class xt::data::datasets::TIMIT","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; TIMIT</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#public-functions","title":"Public Functions","text":"Type Name TIMIT (const std::string &amp; root)  TIMIT (const std::string &amp; root, DataMode mode)  TIMIT (const std::string &amp; root, DataMode mode, bool download)  TIMIT (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#function-timit-14","title":"function TIMIT [1/4]","text":"<pre><code>explicit xt::data::datasets::TIMIT::TIMIT (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#function-timit-24","title":"function TIMIT [2/4]","text":"<pre><code>xt::data::datasets::TIMIT::TIMIT (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#function-timit-34","title":"function TIMIT [3/4]","text":"<pre><code>xt::data::datasets::TIMIT::TIMIT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TIMIT/#function-timit-44","title":"function TIMIT [4/4]","text":"<pre><code>xt::data::datasets::TIMIT::TIMIT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/timit.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/","title":"Class xt::data::datasets::Tedlium","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; Tedlium</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#public-functions","title":"Public Functions","text":"Type Name Tedlium (const std::string &amp; root)  Tedlium (const std::string &amp; root, DataMode mode)  Tedlium (const std::string &amp; root, DataMode mode, bool download)  Tedlium (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#function-tedlium-14","title":"function Tedlium [1/4]","text":"<pre><code>explicit xt::data::datasets::Tedlium::Tedlium (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#function-tedlium-24","title":"function Tedlium [2/4]","text":"<pre><code>xt::data::datasets::Tedlium::Tedlium (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#function-tedlium-34","title":"function Tedlium [3/4]","text":"<pre><code>xt::data::datasets::Tedlium::Tedlium (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1Tedlium/#function-tedlium-44","title":"function Tedlium [4/4]","text":"<pre><code>xt::data::datasets::Tedlium::Tedlium (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/tedlium.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/","title":"Class xt::data::datasets::TensorDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; TensorDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#public-functions","title":"Public Functions","text":"Type Name TensorDataset (const std::string &amp; file_path)  TensorDataset (const std::string &amp; file_path, DataMode mode)  TensorDataset (const std::string &amp; file_path, DataMode mode, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#function-tensordataset-13","title":"function TensorDataset [1/3]","text":"<pre><code>xt::data::datasets::TensorDataset::TensorDataset (\n    const std::string &amp; file_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#function-tensordataset-23","title":"function TensorDataset [2/3]","text":"<pre><code>xt::data::datasets::TensorDataset::TensorDataset (\n    const std::string &amp; file_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TensorDataset/#function-tensordataset-33","title":"function TensorDataset [3/3]","text":"<pre><code>xt::data::datasets::TensorDataset::TensorDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/tensor-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/","title":"Class xt::data::datasets::TextDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; TextDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#public-functions","title":"Public Functions","text":"Type Name TextDataset (const std::string &amp; file_path)  TextDataset (const std::string &amp; file_path, DataMode mode)  TextDataset (const std::string &amp; file_path, DataMode mode, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#function-textdataset-13","title":"function TextDataset [1/3]","text":"<pre><code>xt::data::datasets::TextDataset::TextDataset (\n    const std::string &amp; file_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#function-textdataset-23","title":"function TextDataset [2/3]","text":"<pre><code>xt::data::datasets::TextDataset::TextDataset (\n    const std::string &amp; file_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TextDataset/#function-textdataset-33","title":"function TextDataset [3/3]","text":"<pre><code>xt::data::datasets::TextDataset::TextDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/text-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/","title":"Class xt::data::datasets::TimeSeriesDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; TimeSeriesDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#public-functions","title":"Public Functions","text":"Type Name TimeSeriesDataset (const std::string &amp; file_path)  TimeSeriesDataset (const std::string &amp; file_path, DataMode mode)  TimeSeriesDataset (const std::string &amp; file_path, DataMode mode, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#function-timeseriesdataset-13","title":"function TimeSeriesDataset [1/3]","text":"<pre><code>xt::data::datasets::TimeSeriesDataset::TimeSeriesDataset (\n    const std::string &amp; file_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#function-timeseriesdataset-23","title":"function TimeSeriesDataset [2/3]","text":"<pre><code>xt::data::datasets::TimeSeriesDataset::TimeSeriesDataset (\n    const std::string &amp; file_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1TimeSeriesDataset/#function-timeseriesdataset-33","title":"function TimeSeriesDataset [3/3]","text":"<pre><code>xt::data::datasets::TimeSeriesDataset::TimeSeriesDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/time-series-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/","title":"Class xt::data::datasets::UCF101","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; UCF101</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#public-functions","title":"Public Functions","text":"Type Name UCF101 (const std::string &amp; root)  UCF101 (const std::string &amp; root, DataMode mode)  UCF101 (const std::string &amp; root, DataMode mode, bool download)  UCF101 (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#function-ucf101-14","title":"function UCF101 [1/4]","text":"<pre><code>explicit xt::data::datasets::UCF101::UCF101 (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#function-ucf101-24","title":"function UCF101 [2/4]","text":"<pre><code>xt::data::datasets::UCF101::UCF101 (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#function-ucf101-34","title":"function UCF101 [3/4]","text":"<pre><code>xt::data::datasets::UCF101::UCF101 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UCF101/#function-ucf101-44","title":"function UCF101 [4/4]","text":"<pre><code>xt::data::datasets::UCF101::UCF101 (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/ucf.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/","title":"Class xt::data::datasets::UDPOS","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; UDPOS</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#public-functions","title":"Public Functions","text":"Type Name UDPOS (const std::string &amp; root)  UDPOS (const std::string &amp; root, DataMode mode)  UDPOS (const std::string &amp; root, DataMode mode, bool download)  UDPOS (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#function-udpos-14","title":"function UDPOS [1/4]","text":"<pre><code>explicit xt::data::datasets::UDPOS::UDPOS (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#function-udpos-24","title":"function UDPOS [2/4]","text":"<pre><code>xt::data::datasets::UDPOS::UDPOS (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#function-udpos-34","title":"function UDPOS [3/4]","text":"<pre><code>xt::data::datasets::UDPOS::UDPOS (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UDPOS/#function-udpos-44","title":"function UDPOS [4/4]","text":"<pre><code>xt::data::datasets::UDPOS::UDPOS (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sequence-tagging/udpos.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/","title":"Class xt::data::datasets::USPS","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; USPS</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#public-functions","title":"Public Functions","text":"Type Name USPS (const std::string &amp; root)  USPS (const std::string &amp; root, DataMode mode)  USPS (const std::string &amp; root, DataMode mode, bool download)  USPS (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#function-usps-14","title":"function USPS [1/4]","text":"<pre><code>explicit xt::data::datasets::USPS::USPS (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#function-usps-24","title":"function USPS [2/4]","text":"<pre><code>xt::data::datasets::USPS::USPS (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#function-usps-34","title":"function USPS [3/4]","text":"<pre><code>xt::data::datasets::USPS::USPS (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1USPS/#function-usps-44","title":"function USPS [4/4]","text":"<pre><code>xt::data::datasets::USPS::USPS (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/usps.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/","title":"Class xt::data::datasets::UrbanSound","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; UrbanSound</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#public-functions","title":"Public Functions","text":"Type Name UrbanSound (const std::string &amp; root)  UrbanSound (const std::string &amp; root, DataMode mode)  UrbanSound (const std::string &amp; root, DataMode mode, bool download)  UrbanSound (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#function-urbansound-14","title":"function UrbanSound [1/4]","text":"<pre><code>explicit xt::data::datasets::UrbanSound::UrbanSound (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#function-urbansound-24","title":"function UrbanSound [2/4]","text":"<pre><code>xt::data::datasets::UrbanSound::UrbanSound (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#function-urbansound-34","title":"function UrbanSound [3/4]","text":"<pre><code>xt::data::datasets::UrbanSound::UrbanSound (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1UrbanSound/#function-urbansound-44","title":"function UrbanSound [4/4]","text":"<pre><code>xt::data::datasets::UrbanSound::UrbanSound (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/urban-sound.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/","title":"Class xt::data::datasets::VCTK","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; VCTK</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#public-functions","title":"Public Functions","text":"Type Name VCTK (const std::string &amp; root)  VCTK (const std::string &amp; root, DataMode mode)  VCTK (const std::string &amp; root, DataMode mode, bool download)  VCTK (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#function-vctk-14","title":"function VCTK [1/4]","text":"<pre><code>explicit xt::data::datasets::VCTK::VCTK (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#function-vctk-24","title":"function VCTK [2/4]","text":"<pre><code>xt::data::datasets::VCTK::VCTK (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#function-vctk-34","title":"function VCTK [3/4]","text":"<pre><code>xt::data::datasets::VCTK::VCTK (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VCTK/#function-vctk-44","title":"function VCTK [4/4]","text":"<pre><code>xt::data::datasets::VCTK::VCTK (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/vctk.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/","title":"Class xt::data::datasets::VOCDetection","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; VOCDetection</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#public-functions","title":"Public Functions","text":"Type Name VOCDetection (const std::string &amp; root)  VOCDetection (const std::string &amp; root, DataMode mode)  VOCDetection (const std::string &amp; root, DataMode mode, bool download)  VOCDetection (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#function-vocdetection-14","title":"function VOCDetection [1/4]","text":"<pre><code>explicit xt::data::datasets::VOCDetection::VOCDetection (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#function-vocdetection-24","title":"function VOCDetection [2/4]","text":"<pre><code>xt::data::datasets::VOCDetection::VOCDetection (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#function-vocdetection-34","title":"function VOCDetection [3/4]","text":"<pre><code>xt::data::datasets::VOCDetection::VOCDetection (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCDetection/#function-vocdetection-44","title":"function VOCDetection [4/4]","text":"<pre><code>xt::data::datasets::VOCDetection::VOCDetection (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/voc.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/","title":"Class xt::data::datasets::VOCSegmentation","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; VOCSegmentation</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#public-functions","title":"Public Functions","text":"Type Name VOCSegmentation (const std::string &amp; root)  VOCSegmentation (const std::string &amp; root, DataMode mode)  VOCSegmentation (const std::string &amp; root, DataMode mode, bool download)  VOCSegmentation (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#function-vocsegmentation-14","title":"function VOCSegmentation [1/4]","text":"<pre><code>explicit xt::data::datasets::VOCSegmentation::VOCSegmentation (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#function-vocsegmentation-24","title":"function VOCSegmentation [2/4]","text":"<pre><code>xt::data::datasets::VOCSegmentation::VOCSegmentation (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#function-vocsegmentation-34","title":"function VOCSegmentation [3/4]","text":"<pre><code>xt::data::datasets::VOCSegmentation::VOCSegmentation (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VOCSegmentation/#function-vocsegmentation-44","title":"function VOCSegmentation [4/4]","text":"<pre><code>xt::data::datasets::VOCSegmentation::VOCSegmentation (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/voc.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/","title":"Class xt::data::datasets::VideoDataset","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; VideoDataset</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#public-functions","title":"Public Functions","text":"Type Name VideoDataset (const std::string &amp; file_path)  VideoDataset (const std::string &amp; file_path, DataMode mode)  VideoDataset (const std::string &amp; file_path, DataMode mode, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#function-videodataset-13","title":"function VideoDataset [1/3]","text":"<pre><code>xt::data::datasets::VideoDataset::VideoDataset (\n    const std::string &amp; file_path\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#function-videodataset-23","title":"function VideoDataset [2/3]","text":"<pre><code>xt::data::datasets::VideoDataset::VideoDataset (\n    const std::string &amp; file_path,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VideoDataset/#function-videodataset-33","title":"function VideoDataset [3/3]","text":"<pre><code>xt::data::datasets::VideoDataset::VideoDataset (\n    const std::string &amp; file_path,\n    DataMode mode,\n    vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/video-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/","title":"Class xt::data::datasets::VoxCeleb","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; VoxCeleb</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#public-functions","title":"Public Functions","text":"Type Name VoxCeleb (const std::string &amp; root)  VoxCeleb (const std::string &amp; root, DataMode mode)  VoxCeleb (const std::string &amp; root, DataMode mode, bool download)  VoxCeleb (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#function-voxceleb-14","title":"function VoxCeleb [1/4]","text":"<pre><code>explicit xt::data::datasets::VoxCeleb::VoxCeleb (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#function-voxceleb-24","title":"function VoxCeleb [2/4]","text":"<pre><code>xt::data::datasets::VoxCeleb::VoxCeleb (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#function-voxceleb-34","title":"function VoxCeleb [3/4]","text":"<pre><code>xt::data::datasets::VoxCeleb::VoxCeleb (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1VoxCeleb/#function-voxceleb-44","title":"function VoxCeleb [4/4]","text":"<pre><code>xt::data::datasets::VoxCeleb::VoxCeleb (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/vox-celeb.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/","title":"Class xt::data::datasets::WIDERFace","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; WIDERFace</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#public-functions","title":"Public Functions","text":"Type Name WIDERFace (const std::string &amp; root)  WIDERFace (const std::string &amp; root, DataMode mode)  WIDERFace (const std::string &amp; root, DataMode mode, bool download)  WIDERFace (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#function-widerface-14","title":"function WIDERFace [1/4]","text":"<pre><code>explicit xt::data::datasets::WIDERFace::WIDERFace (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#function-widerface-24","title":"function WIDERFace [2/4]","text":"<pre><code>xt::data::datasets::WIDERFace::WIDERFace (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#function-widerface-34","title":"function WIDERFace [3/4]","text":"<pre><code>xt::data::datasets::WIDERFace::WIDERFace (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WIDERFace/#function-widerface-44","title":"function WIDERFace [4/4]","text":"<pre><code>xt::data::datasets::WIDERFace::WIDERFace (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/wider-face.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/","title":"Class xt::data::datasets::WMT","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; WMT</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#public-functions","title":"Public Functions","text":"Type Name WMT (const std::string &amp; root)  WMT (const std::string &amp; root, DataMode mode)  WMT (const std::string &amp; root, DataMode mode, bool download)  WMT (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#function-wmt-14","title":"function WMT [1/4]","text":"<pre><code>explicit xt::data::datasets::WMT::WMT (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#function-wmt-24","title":"function WMT [2/4]","text":"<pre><code>xt::data::datasets::WMT::WMT (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#function-wmt-34","title":"function WMT [3/4]","text":"<pre><code>xt::data::datasets::WMT::WMT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WMT/#function-wmt-44","title":"function WMT [4/4]","text":"<pre><code>xt::data::datasets::WMT::WMT (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/wmt.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/","title":"Class xt::data::datasets::WNLI","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; WNLI</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#public-functions","title":"Public Functions","text":"Type Name WNLI (const std::string &amp; root)  WNLI (const std::string &amp; root, DataMode mode)  WNLI (const std::string &amp; root, DataMode mode, bool download)  WNLI (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#function-wnli-14","title":"function WNLI [1/4]","text":"<pre><code>explicit xt::data::datasets::WNLI::WNLI (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#function-wnli-24","title":"function WNLI [2/4]","text":"<pre><code>xt::data::datasets::WNLI::WNLI (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#function-wnli-34","title":"function WNLI [3/4]","text":"<pre><code>xt::data::datasets::WNLI::WNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WNLI/#function-wnli-44","title":"function WNLI [4/4]","text":"<pre><code>xt::data::datasets::WNLI::WNLI (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/wnli.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/","title":"Class xt::data::datasets::WikiText","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; WikiText</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#public-functions","title":"Public Functions","text":"Type Name WikiText (const std::string &amp; root)  WikiText (const std::string &amp; root, DataMode mode)  WikiText (const std::string &amp; root, DataMode mode, bool download)  WikiText (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#function-wikitext-14","title":"function WikiText [1/4]","text":"<pre><code>explicit xt::data::datasets::WikiText::WikiText (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#function-wikitext-24","title":"function WikiText [2/4]","text":"<pre><code>xt::data::datasets::WikiText::WikiText (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#function-wikitext-34","title":"function WikiText [3/4]","text":"<pre><code>xt::data::datasets::WikiText::WikiText (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1WikiText/#function-wikitext-44","title":"function WikiText [4/4]","text":"<pre><code>xt::data::datasets::WikiText::WikiText (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/wiki-text.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/","title":"Class xt::data::datasets::YahooAnswers","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; YahooAnswers</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#public-functions","title":"Public Functions","text":"Type Name YahooAnswers (const std::string &amp; root)  YahooAnswers (const std::string &amp; root, DataMode mode)  YahooAnswers (const std::string &amp; root, DataMode mode, bool download)  YahooAnswers (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#function-yahooanswers-14","title":"function YahooAnswers [1/4]","text":"<pre><code>explicit xt::data::datasets::YahooAnswers::YahooAnswers (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#function-yahooanswers-24","title":"function YahooAnswers [2/4]","text":"<pre><code>xt::data::datasets::YahooAnswers::YahooAnswers (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#function-yahooanswers-34","title":"function YahooAnswers [3/4]","text":"<pre><code>xt::data::datasets::YahooAnswers::YahooAnswers (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YahooAnswers/#function-yahooanswers-44","title":"function YahooAnswers [4/4]","text":"<pre><code>xt::data::datasets::YahooAnswers::YahooAnswers (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/yahoo-answers.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/","title":"Class xt::data::datasets::YelpReview","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; YelpReview</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#public-functions","title":"Public Functions","text":"Type Name YelpReview (const std::string &amp; root)  YelpReview (const std::string &amp; root, DataMode mode)  YelpReview (const std::string &amp; root, DataMode mode, bool download)  YelpReview (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#function-yelpreview-14","title":"function YelpReview [1/4]","text":"<pre><code>explicit xt::data::datasets::YelpReview::YelpReview (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#function-yelpreview-24","title":"function YelpReview [2/4]","text":"<pre><code>xt::data::datasets::YelpReview::YelpReview (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#function-yelpreview-34","title":"function YelpReview [3/4]","text":"<pre><code>xt::data::datasets::YelpReview::YelpReview (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YelpReview/#function-yelpreview-44","title":"function YelpReview [4/4]","text":"<pre><code>xt::data::datasets::YelpReview::YelpReview (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/yelp-review.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/","title":"Class xt::data::datasets::YesNo","text":"<p>ClassList &gt; xt &gt; data &gt; datasets &gt; YesNo</p> <p>Inherits the following classes: xt::data::datasets::BaseDataset</p>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#public-types-inherited-from-xtdatadatasetsbasedataset","title":"Public Types inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name typedef vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; TransformType"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#public-attributes-inherited-from-xtdatadatasetsbasedataset","title":"Public Attributes inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name xt::data::transforms::Compose compose std::vector&lt; torch::Tensor &gt; data fs::path dataset_path bool download   = <code>false</code> std::vector&lt; uint8_t &gt; labels DataMode mode   = <code>DataMode::TRAIN</code> fs::path root vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms   = <code>{}</code>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#public-functions","title":"Public Functions","text":"Type Name YesNo (const std::string &amp; root)  YesNo (const std::string &amp; root, DataMode mode)  YesNo (const std::string &amp; root, DataMode mode, bool download)  YesNo (const std::string &amp; root, DataMode mode, bool download, TransformType transforms)"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#public-functions-inherited-from-xtdatadatasetsbasedataset","title":"Public Functions inherited from xt::data::datasets::BaseDataset","text":"<p>See xt::data::datasets::BaseDataset</p> Type Name BaseDataset (const std::string &amp; root)  BaseDataset (const std::string &amp; root, DataMode mode)  BaseDataset (const std::string &amp; root, DataMode mode, bool download)  BaseDataset (const std::string &amp; root, DataMode mode, bool download, vector&lt; std::function&lt; torch::Tensor(torch::Tensor)&gt; &gt; transforms)  torch::data::Example get (size_t index) override torch::optional&lt; size_t &gt; size () override const"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#function-yesno-14","title":"function YesNo [1/4]","text":"<pre><code>explicit xt::data::datasets::YesNo::YesNo (\n    const std::string &amp; root\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#function-yesno-24","title":"function YesNo [2/4]","text":"<pre><code>xt::data::datasets::YesNo::YesNo (\n    const std::string &amp; root,\n    DataMode mode\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#function-yesno-34","title":"function YesNo [3/4]","text":"<pre><code>xt::data::datasets::YesNo::YesNo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1data_1_1datasets_1_1YesNo/#function-yesno-44","title":"function YesNo [4/4]","text":"<pre><code>xt::data::datasets::YesNo::YesNo (\n    const std::string &amp; root,\n    DataMode mode,\n    bool download,\n    TransformType transforms\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/yes-no.h</code></p>"},{"location":"xTorch/namespacext_1_1data_1_1transforms/","title":"Namespace xt::data::transforms","text":"<p>Namespace List &gt; xt &gt; data &gt; transforms</p>"},{"location":"xTorch/namespacext_1_1data_1_1transforms/#classes","title":"Classes","text":"Type Name struct CenterCrop struct ColorJitter class Compose A class to compose multiple tensor transformations into a single callable pipeline. struct Cutout struct GaussianBlur struct GaussianBlurOpenCV struct GaussianNoise struct Grayscale struct GrayscaleToRGB A functor to convert a grayscale tensor to an RGB tensor. struct HorizontalFlip struct Lambda struct Normalize struct Pad A functor to pad a tensor with a specified padding configuration. struct RandomCrop struct RandomCrop2 struct RandomFlip struct RandomGaussianBlur struct Resize A functor to resize a tensor image to a specified size. struct Rotation struct ToGray struct ToTensor struct VerticalFlip"},{"location":"xTorch/namespacext_1_1data_1_1transforms/#public-functions","title":"Public Functions","text":"Type Name std::function&lt; torch::Tensor(torch::Tensor input)&gt; create_resize_transform (std::vector&lt; int64_t &gt; size)  torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; normalize (double mean, double stddev)  torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; resize (std::vector&lt; int64_t &gt; size)  torch::Tensor resize_tensor (const torch::Tensor &amp; tensor, const std::vector&lt; int64_t &gt; &amp; size)"},{"location":"xTorch/namespacext_1_1data_1_1transforms/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext_1_1data_1_1transforms/#function-create_resize_transform","title":"function create_resize_transform","text":"<pre><code>std::function&lt; torch::Tensor(torch::Tensor input)&gt; xt::data::transforms::create_resize_transform (\n    std::vector&lt; int64_t &gt; size\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1data_1_1transforms/#function-normalize","title":"function normalize","text":"<pre><code>torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; xt::data::transforms::normalize (\n    double mean,\n    double stddev\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1data_1_1transforms/#function-resize","title":"function resize","text":"<pre><code>torch::data::transforms::Lambda&lt; torch::data::Example&lt;&gt; &gt; xt::data::transforms::resize (\n    std::vector&lt; int64_t &gt; size\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1data_1_1transforms/#function-resize_tensor","title":"function resize_tensor","text":"<pre><code>torch::Tensor xt::data::transforms::resize_tensor (\n    const torch::Tensor &amp; tensor,\n    const std::vector&lt; int64_t &gt; &amp; size\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/definitions/transforms.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1CenterCrop/","title":"Struct xt::data::transforms::CenterCrop","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; CenterCrop</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1CenterCrop/#public-functions","title":"Public Functions","text":"Type Name CenterCrop (std::vector&lt; int64_t &gt; size)  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1CenterCrop/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1CenterCrop/#function-centercrop","title":"function CenterCrop","text":"<pre><code>xt::data::transforms::CenterCrop::CenterCrop (\n    std::vector&lt; int64_t &gt; size\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1CenterCrop/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::CenterCrop::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/crop.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ColorJitter/","title":"Struct xt::data::transforms::ColorJitter","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; ColorJitter</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ColorJitter/#public-functions","title":"Public Functions","text":"Type Name ColorJitter (float brightness=0.0f, float contrast=0.0f, float saturation=0.0f)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor) const"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ColorJitter/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ColorJitter/#function-colorjitter","title":"function ColorJitter","text":"<pre><code>xt::data::transforms::ColorJitter::ColorJitter (\n    float brightness=0.0f,\n    float contrast=0.0f,\n    float saturation=0.0f\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ColorJitter/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::ColorJitter::operator() (\n    const torch::Tensor &amp; input_tensor\n) const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/jitter.h</code></p>"},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/","title":"Class xt::data::transforms::Compose","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Compose</p> <p>A class to compose multiple tensor transformations into a single callable pipeline. More...</p> <ul> <li><code>#include &lt;compose.h&gt;</code></li> </ul>"},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#public-types","title":"Public Types","text":"Type Name typedef std::function&lt; torch::Tensor(torch::Tensor)&gt; TransformFunc Alias for a transformation function that takes a tensor and returns a tensor."},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#public-functions","title":"Public Functions","text":"Type Name Compose () Default constructor, initializing an empty transformation pipeline. Compose (std::vector&lt; TransformFunc &gt; transforms) Constructs a Compose object with a vector of transformation functions. torch::Tensor operator() (torch::Tensor input) constApplies the sequence of transformations to the input tensor."},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#detailed-description","title":"Detailed Description","text":"<p>The Compose class allows chaining of multiple transformation functions, each operating on a <code>torch::Tensor</code>, into a single operation. It is designed to facilitate preprocessing or augmentation of tensor data (e.g., images) by applying a sequence of transforms in the order they are provided. The transformations are stored as a vector of function objects and applied via the call operator. </p>"},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#typedef-transformfunc","title":"typedef TransformFunc","text":"<p>Alias for a transformation function that takes a tensor and returns a tensor. </p> <pre><code>using xt::data::transforms::Compose::TransformFunc =  std::function&lt;torch::Tensor(torch::Tensor)&gt;;\n</code></pre> <p>This type alias defines a function signature for transformations that operate on <code>torch::Tensor</code> objects, enabling flexible composition of operations. </p>"},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#function-compose-12","title":"function Compose [1/2]","text":"<p>Default constructor, initializing an empty transformation pipeline. </p> <pre><code>xt::data::transforms::Compose::Compose () \n</code></pre> <p>Creates a Compose object with no transformations, allowing subsequent addition of transforms if needed. </p>"},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#function-compose-22","title":"function Compose [2/2]","text":"<p>Constructs a Compose object with a vector of transformation functions.</p> <pre><code>xt::data::transforms::Compose::Compose (\n    std::vector&lt; TransformFunc &gt; transforms\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>transforms</code> A vector of TransformFunc objects specifying the sequence of transformations.</li> </ul> <p>Initializes the Compose object with a predefined set of transformations to be applied in order. </p>"},{"location":"xTorch/classxt_1_1data_1_1transforms_1_1Compose/#function-operator","title":"function operator()","text":"<p>Applies the sequence of transformations to the input tensor. </p> <pre><code>torch::Tensor xt::data::transforms::Compose::operator() (\n    torch::Tensor input\n) const\n</code></pre> <p>Parameters:</p> <ul> <li><code>input</code> The input tensor to be transformed. </li> </ul> <p>Returns:</p> <p>A tensor resulting from applying all transformations in sequence.</p> <p>This operator applies each transformation in the <code>transforms</code> vector to the input tensor, passing the output of one transformation as the input to the next, and returns the final result. </p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/compose.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Cutout/","title":"Struct xt::data::transforms::Cutout","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Cutout</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Cutout/#public-functions","title":"Public Functions","text":"Type Name Cutout (int num_holes=1, int hole_size=16)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor) const"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Cutout/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Cutout/#function-cutout","title":"function Cutout","text":"<pre><code>xt::data::transforms::Cutout::Cutout (\n    int num_holes=1,\n    int hole_size=16\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Cutout/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::Cutout::operator() (\n    const torch::Tensor &amp; input_tensor\n) const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/cutout.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlur/","title":"Struct xt::data::transforms::GaussianBlur","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; GaussianBlur</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlur/#public-functions","title":"Public Functions","text":"Type Name GaussianBlur (std::vector&lt; int64_t &gt; kernel_size, float sigma)  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlur/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlur/#function-gaussianblur","title":"function GaussianBlur","text":"<pre><code>xt::data::transforms::GaussianBlur::GaussianBlur (\n    std::vector&lt; int64_t &gt; kernel_size,\n    float sigma\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlur/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::GaussianBlur::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/gaussian.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlurOpenCV/","title":"Struct xt::data::transforms::GaussianBlurOpenCV","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; GaussianBlurOpenCV</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlurOpenCV/#public-functions","title":"Public Functions","text":"Type Name GaussianBlurOpenCV (int ksize, double sigma_val)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlurOpenCV/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlurOpenCV/#function-gaussianbluropencv","title":"function GaussianBlurOpenCV","text":"<pre><code>xt::data::transforms::GaussianBlurOpenCV::GaussianBlurOpenCV (\n    int ksize,\n    double sigma_val\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianBlurOpenCV/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::GaussianBlurOpenCV::operator() (\n    const torch::Tensor &amp; input_tensor\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/gaussian.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianNoise/","title":"Struct xt::data::transforms::GaussianNoise","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; GaussianNoise</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianNoise/#public-functions","title":"Public Functions","text":"Type Name GaussianNoise (float mean, float std)  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianNoise/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianNoise/#function-gaussiannoise","title":"function GaussianNoise","text":"<pre><code>xt::data::transforms::GaussianNoise::GaussianNoise (\n    float mean,\n    float std\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GaussianNoise/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::GaussianNoise::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/gaussian.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Grayscale/","title":"Struct xt::data::transforms::Grayscale","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Grayscale</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Grayscale/#public-functions","title":"Public Functions","text":"Type Name Grayscale ()  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Grayscale/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Grayscale/#function-grayscale","title":"function Grayscale","text":"<pre><code>xt::data::transforms::Grayscale::Grayscale () \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Grayscale/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::Grayscale::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/grayscale.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GrayscaleToRGB/","title":"Struct xt::data::transforms::GrayscaleToRGB","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; GrayscaleToRGB</p> <p>A functor to convert a grayscale tensor to an RGB tensor. More...</p> <ul> <li><code>#include &lt;grayscale.h&gt;</code></li> </ul>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GrayscaleToRGB/#public-functions","title":"Public Functions","text":"Type Name torch::Tensor operator() (const torch::Tensor &amp; tensor) Converts a grayscale tensor to an RGB tensor."},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GrayscaleToRGB/#detailed-description","title":"Detailed Description","text":"<p>This struct provides a callable object that transforms a grayscale tensor, typically with a single channel (e.g., [H, W] or [1, H, W]), into an RGB tensor with three channels (e.g., [3, H, W]). The conversion is performed by replicating the grayscale channel across the RGB dimensions, suitable for preprocessing grayscale images in machine learning workflows using LibTorch. </p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GrayscaleToRGB/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1GrayscaleToRGB/#function-operator","title":"function operator()","text":"<p>Converts a grayscale tensor to an RGB tensor. </p> <pre><code>torch::Tensor xt::data::transforms::GrayscaleToRGB::operator() (\n    const torch::Tensor &amp; tensor\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>tensor</code> The input grayscale tensor, expected in format [H, W] or [1, H, W]. </li> </ul> <p>Returns:</p> <p>A new tensor in RGB format [3, H, W], with the grayscale values replicated across channels.</p> <p>This operator takes a grayscale tensor and produces an RGB tensor by duplicating the single channel\u2019s values into three identical channels (red, green, blue). The input tensor must have a single channel, either as a 2D tensor [H, W] or a 3D tensor with one channel [1, H, W]. </p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/grayscale.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1HorizontalFlip/","title":"Struct xt::data::transforms::HorizontalFlip","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; HorizontalFlip</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1HorizontalFlip/#public-functions","title":"Public Functions","text":"Type Name HorizontalFlip ()  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1HorizontalFlip/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1HorizontalFlip/#function-horizontalflip","title":"function HorizontalFlip","text":"<pre><code>xt::data::transforms::HorizontalFlip::HorizontalFlip () \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1HorizontalFlip/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::HorizontalFlip::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/flip.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Lambda/","title":"Struct xt::data::transforms::Lambda","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Lambda</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Lambda/#public-functions","title":"Public Functions","text":"Type Name Lambda (std::function&lt; torch::Tensor(torch::Tensor)&gt; transform)  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Lambda/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Lambda/#function-lambda","title":"function Lambda","text":"<pre><code>xt::data::transforms::Lambda::Lambda (\n    std::function&lt; torch::Tensor(torch::Tensor)&gt; transform\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Lambda/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::Lambda::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/lambda.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Normalize/","title":"Struct xt::data::transforms::Normalize","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Normalize</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Normalize/#public-functions","title":"Public Functions","text":"Type Name Normalize (std::vector&lt; float &gt; mean, std::vector&lt; float &gt; std)  torch::Tensor operator() (const torch::Tensor &amp; tensor) const"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Normalize/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Normalize/#function-normalize","title":"function Normalize","text":"<pre><code>xt::data::transforms::Normalize::Normalize (\n    std::vector&lt; float &gt; mean,\n    std::vector&lt; float &gt; std\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Normalize/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::Normalize::operator() (\n    const torch::Tensor &amp; tensor\n) const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/normalize.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Pad/","title":"Struct xt::data::transforms::Pad","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Pad</p> <p>A functor to pad a tensor with a specified padding configuration. More...</p> <ul> <li><code>#include &lt;pad.h&gt;</code></li> </ul>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Pad/#public-functions","title":"Public Functions","text":"Type Name Pad (std::vector&lt; int64_t &gt; padding) Constructs a Pad object with the specified padding sizes. torch::Tensor operator() (torch::Tensor input) Applies padding to the input tensor."},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Pad/#detailed-description","title":"Detailed Description","text":"<p>This struct provides a callable object that applies padding to a <code>torch::Tensor</code> based on a vector of padding sizes. It is designed to extend the dimensions of a tensor (e.g., images in machine learning workflows) by adding values (typically zeros) around its boundaries, using the padding amounts specified during construction. The padding is applied using LibTorch's functional padding utilities. </p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Pad/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Pad/#function-pad","title":"function Pad","text":"<p>Constructs a Pad object with the specified padding sizes.</p> <pre><code>xt::data::transforms::Pad::Pad (\n    std::vector&lt; int64_t &gt; padding\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>padding</code> A vector of 64-bit integers defining the padding amounts, in pairs (e.g., {left, right, top, bottom}).</li> </ul> <p>Initializes the Pad object with a vector specifying the padding to be applied to the tensor\u2019s dimensions. The vector must contain an even number of elements, where each pair corresponds to the left and right padding for a dimension, applied to the tensor\u2019s last dimensions in reverse order (e.g., width, then height for a 2D tensor). </p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Pad/#function-operator","title":"function operator()","text":"<p>Applies padding to the input tensor. </p> <pre><code>torch::Tensor xt::data::transforms::Pad::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>input</code> The input tensor to be padded, typically in format [N, C, H, W] or [H, W]. </li> </ul> <p>Returns:</p> <p>A new tensor with padded dimensions according to the stored padding configuration.</p> <p>This operator pads the input tensor using the padding sizes provided at construction, typically with zeros using constant mode padding. For a 4D tensor [N, C, H, W] and padding {p_left, p_right, p_top, p_bottom}, it pads width (W) and height (H), resulting in [N, C, H + p_top + p_bottom, W + p_left + p_right]. The padding is applied to the last dimensions corresponding to the number of pairs in the padding vector. </p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/pad.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop/","title":"Struct xt::data::transforms::RandomCrop","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; RandomCrop</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop/#public-functions","title":"Public Functions","text":"Type Name RandomCrop (std::vector&lt; int64_t &gt; size)  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop/#function-randomcrop","title":"function RandomCrop","text":"<pre><code>xt::data::transforms::RandomCrop::RandomCrop (\n    std::vector&lt; int64_t &gt; size\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::RandomCrop::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/crop.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop2/","title":"Struct xt::data::transforms::RandomCrop2","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; RandomCrop2</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop2/#public-functions","title":"Public Functions","text":"Type Name RandomCrop2 (int height, int width)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop2/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop2/#function-randomcrop2","title":"function RandomCrop2","text":"<pre><code>xt::data::transforms::RandomCrop2::RandomCrop2 (\n    int height,\n    int width\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomCrop2/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::RandomCrop2::operator() (\n    const torch::Tensor &amp; input_tensor\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/crop.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomFlip/","title":"Struct xt::data::transforms::RandomFlip","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; RandomFlip</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomFlip/#public-functions","title":"Public Functions","text":"Type Name RandomFlip (double h_prob=0.5, double v_prob=0.0)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomFlip/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomFlip/#function-randomflip","title":"function RandomFlip","text":"<pre><code>xt::data::transforms::RandomFlip::RandomFlip (\n    double h_prob=0.5,\n    double v_prob=0.0\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomFlip/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::RandomFlip::operator() (\n    const torch::Tensor &amp; input_tensor\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/flip.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomGaussianBlur/","title":"Struct xt::data::transforms::RandomGaussianBlur","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; RandomGaussianBlur</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomGaussianBlur/#public-functions","title":"Public Functions","text":"Type Name RandomGaussianBlur (std::vector&lt; int &gt; sizes={3, 5}, double sigma_min=0.1, double sigma_max=2.0)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomGaussianBlur/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomGaussianBlur/#function-randomgaussianblur","title":"function RandomGaussianBlur","text":"<pre><code>xt::data::transforms::RandomGaussianBlur::RandomGaussianBlur (\n    std::vector&lt; int &gt; sizes={3, 5},\n    double sigma_min=0.1,\n    double sigma_max=2.0\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1RandomGaussianBlur/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::RandomGaussianBlur::operator() (\n    const torch::Tensor &amp; input_tensor\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/gaussian.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Resize/","title":"Struct xt::data::transforms::Resize","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Resize</p> <p>A functor to resize a tensor image to a specified size. More...</p> <ul> <li><code>#include &lt;resize.h&gt;</code></li> </ul>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Resize/#public-functions","title":"Public Functions","text":"Type Name Resize (std::vector&lt; int64_t &gt; size) Constructs a Resize object with the target size. torch::Tensor operator() (torch::Tensor img) Resizes the input tensor image to the target size."},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Resize/#detailed-description","title":"Detailed Description","text":"<p>This struct provides a callable object that resizes a <code>torch::Tensor</code> representing an image to a target size specified as a vector of 64-bit integers. It uses the call operator to perform the resizing operation, making it suitable for use in functional pipelines or transformations. </p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Resize/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Resize/#function-resize","title":"function Resize","text":"<p>Constructs a Resize object with the target size.</p> <pre><code>xt::data::transforms::Resize::Resize (\n    std::vector&lt; int64_t &gt; size\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>size</code> A vector of 64-bit integers specifying the target dimensions (e.g., {height, width}). </li> </ul>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Resize/#function-operator","title":"function operator()","text":"<p>Resizes the input tensor image to the target size. </p> <pre><code>torch::Tensor xt::data::transforms::Resize::operator() (\n    torch::Tensor img\n) \n</code></pre> <p>Parameters:</p> <ul> <li><code>img</code> The input tensor image to be resized. </li> </ul> <p>Returns:</p> <p>A new tensor with the resized dimensions. </p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/resize.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Rotation/","title":"Struct xt::data::transforms::Rotation","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; Rotation</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Rotation/#public-functions","title":"Public Functions","text":"Type Name Rotation (double angle_deg)  torch::Tensor operator() (const torch::Tensor &amp; input_tensor)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Rotation/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Rotation/#function-rotation","title":"function Rotation","text":"<pre><code>xt::data::transforms::Rotation::Rotation (\n    double angle_deg\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1Rotation/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::Rotation::operator() (\n    const torch::Tensor &amp; input_tensor\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/rotation.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToGray/","title":"Struct xt::data::transforms::ToGray","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; ToGray</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToGray/#public-functions","title":"Public Functions","text":"Type Name torch::Tensor operator() (const torch::Tensor &amp; color_tensor) const"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToGray/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToGray/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::ToGray::operator() (\n    const torch::Tensor &amp; color_tensor\n) const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/grayscale.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToTensor/","title":"Struct xt::data::transforms::ToTensor","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; ToTensor</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToTensor/#public-functions","title":"Public Functions","text":"Type Name torch::Tensor operator() (const cv::Mat &amp; image) const"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToTensor/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1ToTensor/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::ToTensor::operator() (\n    const cv::Mat &amp; image\n) const\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/convert.h</code></p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1VerticalFlip/","title":"Struct xt::data::transforms::VerticalFlip","text":"<p>ClassList &gt; xt &gt; data &gt; transforms &gt; VerticalFlip</p>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1VerticalFlip/#public-functions","title":"Public Functions","text":"Type Name VerticalFlip ()  torch::Tensor operator() (torch::Tensor input)"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1VerticalFlip/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1VerticalFlip/#function-verticalflip","title":"function VerticalFlip","text":"<pre><code>xt::data::transforms::VerticalFlip::VerticalFlip () \n</code></pre>"},{"location":"xTorch/structxt_1_1data_1_1transforms_1_1VerticalFlip/#function-operator","title":"function operator()","text":"<pre><code>torch::Tensor xt::data::transforms::VerticalFlip::operator() (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/flip.h</code></p>"},{"location":"xTorch/namespacext_1_1models/","title":"Namespace xt::models","text":"<p>Namespace List &gt; xt &gt; models</p>"},{"location":"xTorch/namespacext_1_1models/#classes","title":"Classes","text":"Type Name struct AlexNet class BaseModel struct Bottleneck struct DoubleConv struct DownSample struct HSigmoid struct HSwish struct LeNet5 struct MobileNetV3 class Model struct ResNet struct SqueezeExcite struct UNet struct UpSample struct VggNet16 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/base.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/","title":"Struct xt::models::AlexNet","text":"<p>ClassList &gt; xt &gt; models &gt; AlexNet</p> <p>Inherits the following classes: xt::models::BaseModel</p>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#public-attributes","title":"Public Attributes","text":"Type Name torch::nn::Sequential fc   = <code>nullptr</code> torch::nn::Sequential fc1   = <code>nullptr</code> torch::nn::Sequential fc2   = <code>nullptr</code> torch::nn::Sequential layer1   = <code>nullptr</code> torch::nn::Sequential layer2   = <code>nullptr</code> torch::nn::Sequential layer3   = <code>nullptr</code> torch::nn::Sequential layer4   = <code>nullptr</code> torch::nn::Sequential layer5   = <code>/* multi line expression */</code>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#public-functions","title":"Public Functions","text":"Type Name AlexNet (int num_classes, int in_channels=3)  AlexNet (int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  virtual torch::Tensor forward (torch::Tensor x) override const"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-fc","title":"variable fc","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::fc;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-fc1","title":"variable fc1","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::fc1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-fc2","title":"variable fc2","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::fc2;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-layer1","title":"variable layer1","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::layer1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-layer2","title":"variable layer2","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::layer2;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-layer3","title":"variable layer3","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::layer3;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-layer4","title":"variable layer4","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::layer4;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#variable-layer5","title":"variable layer5","text":"<pre><code>torch::nn::Sequential xt::models::AlexNet::layer5;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#function-alexnet-12","title":"function AlexNet [1/2]","text":"<pre><code>xt::models::AlexNet::AlexNet (\n    int num_classes,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#function-alexnet-22","title":"function AlexNet [2/2]","text":"<pre><code>xt::models::AlexNet::AlexNet (\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1AlexNet/#function-forward","title":"function forward","text":"<pre><code>virtual torch::Tensor xt::models::AlexNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/alexnet/alexnet.h</code></p>"},{"location":"xTorch/classxt_1_1models_1_1BaseModel/","title":"Class xt::models::BaseModel","text":"<p>ClassList &gt; xt &gt; models &gt; BaseModel</p> <p>Inherits the following classes: torch::nn::Module</p> <p>Inherited by the following classes: xt::models::AlexNet,  xt::models::LeNet5,  xt::models::MobileNetV3,  xt::models::MobileNetV3,  xt::models::MobileNetV3,  xt::models::Model,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::ResNet,  xt::models::UNet,  xt::models::VggNet16,  xt::models::VggNet16,  xt::models::VggNet16,  xt::models::VggNet16</p>"},{"location":"xTorch/classxt_1_1models_1_1BaseModel/#public-functions","title":"Public Functions","text":"Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/classxt_1_1models_1_1BaseModel/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1models_1_1BaseModel/#function-basemodel","title":"function BaseModel","text":"<pre><code>xt::models::BaseModel::BaseModel () \n</code></pre>"},{"location":"xTorch/classxt_1_1models_1_1BaseModel/#function-forward","title":"function forward","text":"<pre><code>virtual torch::Tensor xt::models::BaseModel::forward (\n    torch::Tensor input\n) const = 0\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/base.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/","title":"Struct xt::models::Bottleneck","text":"<p>ClassList &gt; xt &gt; models &gt; Bottleneck</p> <p>Inherits the following classes: torch::nn::Module,  torch::nn::Module,  torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#public-functions","title":"Public Functions","text":"Type Name Bottleneck (int input_channels, int kernel, int stride, int expansion, int output_channels, torch::nn::Module activation, bool se=false)  Bottleneck (int input_channels, int kernel, int stride, int expansion, int output_channels, torch::nn::Module activation, bool se=false)  Bottleneck (int input_channels, int kernel, int stride, int expansion, int output_channels, torch::nn::Module activation, bool se=false)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#function-bottleneck-13","title":"function Bottleneck [1/3]","text":"<pre><code>xt::models::Bottleneck::Bottleneck (\n    int input_channels,\n    int kernel,\n    int stride,\n    int expansion,\n    int output_channels,\n    torch::nn::Module activation,\n    bool se=false\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#function-bottleneck-13_1","title":"function Bottleneck [1/3]","text":"<pre><code>xt::models::Bottleneck::Bottleneck (\n    int input_channels,\n    int kernel,\n    int stride,\n    int expansion,\n    int output_channels,\n    torch::nn::Module activation,\n    bool se=false\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#function-bottleneck-13_2","title":"function Bottleneck [1/3]","text":"<pre><code>xt::models::Bottleneck::Bottleneck (\n    int input_channels,\n    int kernel,\n    int stride,\n    int expansion,\n    int output_channels,\n    torch::nn::Module activation,\n    bool se=false\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#function-forward-13","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::Bottleneck::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#function-forward-13_1","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::Bottleneck::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1Bottleneck/#function-forward-13_2","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::Bottleneck::forward (\n    torch::Tensor x\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v1.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1DoubleConv/","title":"Struct xt::models::DoubleConv","text":"<p>ClassList &gt; xt &gt; models &gt; DoubleConv</p> <p>Inherits the following classes: torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1DoubleConv/#public-functions","title":"Public Functions","text":"Type Name DoubleConv (int in_channels, int out_channels)  torch::Tensor forward (torch::Tensor input)"},{"location":"xTorch/structxt_1_1models_1_1DoubleConv/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1DoubleConv/#function-doubleconv","title":"function DoubleConv","text":"<pre><code>xt::models::DoubleConv::DoubleConv (\n    int in_channels,\n    int out_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1DoubleConv/#function-forward","title":"function forward","text":"<pre><code>torch::Tensor xt::models::DoubleConv::forward (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/unet/unet.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1DownSample/","title":"Struct xt::models::DownSample","text":"<p>ClassList &gt; xt &gt; models &gt; DownSample</p> <p>Inherits the following classes: torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1DownSample/#public-functions","title":"Public Functions","text":"Type Name DownSample (int in_channels, int out_channels)  torch::Tensor forward (torch::Tensor input)"},{"location":"xTorch/structxt_1_1models_1_1DownSample/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1DownSample/#function-downsample","title":"function DownSample","text":"<pre><code>xt::models::DownSample::DownSample (\n    int in_channels,\n    int out_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1DownSample/#function-forward","title":"function forward","text":"<pre><code>torch::Tensor xt::models::DownSample::forward (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/unet/unet.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/","title":"Struct xt::models::HSigmoid","text":"<p>ClassList &gt; xt &gt; models &gt; HSigmoid</p> <p>Inherits the following classes: torch::nn::Module,  torch::nn::Module,  torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#public-functions","title":"Public Functions","text":"Type Name HSigmoid ()  HSigmoid ()  HSigmoid ()  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#function-hsigmoid-13","title":"function HSigmoid [1/3]","text":"<pre><code>xt::models::HSigmoid::HSigmoid () \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#function-hsigmoid-13_1","title":"function HSigmoid [1/3]","text":"<pre><code>xt::models::HSigmoid::HSigmoid () \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#function-hsigmoid-13_2","title":"function HSigmoid [1/3]","text":"<pre><code>xt::models::HSigmoid::HSigmoid () \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#function-forward-13","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::HSigmoid::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#function-forward-13_1","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::HSigmoid::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSigmoid/#function-forward-13_2","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::HSigmoid::forward (\n    torch::Tensor x\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v1.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/","title":"Struct xt::models::HSwish","text":"<p>ClassList &gt; xt &gt; models &gt; HSwish</p> <p>Inherits the following classes: torch::nn::Module,  torch::nn::Module,  torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#public-functions","title":"Public Functions","text":"Type Name HSwish ()  HSwish ()  HSwish ()  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1HSwish/#function-hswish-13","title":"function HSwish [1/3]","text":"<pre><code>xt::models::HSwish::HSwish () \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#function-hswish-13_1","title":"function HSwish [1/3]","text":"<pre><code>xt::models::HSwish::HSwish () \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#function-hswish-13_2","title":"function HSwish [1/3]","text":"<pre><code>xt::models::HSwish::HSwish () \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#function-forward-13","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::HSwish::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#function-forward-13_1","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::HSwish::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1HSwish/#function-forward-13_2","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::HSwish::forward (\n    torch::Tensor x\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v1.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/","title":"Struct xt::models::LeNet5","text":"<p>ClassList &gt; xt &gt; models &gt; LeNet5</p> <p>Inherits the following classes: xt::models::BaseModel</p>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#public-functions","title":"Public Functions","text":"Type Name LeNet5 (int num_classes, int in_channels=1)  LeNet5 (int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  virtual torch::Tensor forward (torch::Tensor x) override const"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#protected-attributes","title":"Protected Attributes","text":"Type Name torch::nn::Linear fc1   = <code>nullptr</code> torch::nn::Linear fc2   = <code>nullptr</code> torch::nn::Linear fc3   = <code>nullptr</code> torch::nn::Sequential layer1   = <code>nullptr</code> torch::nn::Sequential layer2   = <code>nullptr</code>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#function-lenet5-12","title":"function LeNet5 [1/2]","text":"<pre><code>xt::models::LeNet5::LeNet5 (\n    int num_classes,\n    int in_channels=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#function-lenet5-22","title":"function LeNet5 [2/2]","text":"<pre><code>xt::models::LeNet5::LeNet5 (\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#function-forward","title":"function forward","text":"<pre><code>virtual torch::Tensor xt::models::LeNet5::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#variable-fc1","title":"variable fc1","text":"<pre><code>torch::nn::Linear xt::models::LeNet5::fc1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#variable-fc2","title":"variable fc2","text":"<pre><code>torch::nn::Linear xt::models::LeNet5::fc2;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#variable-fc3","title":"variable fc3","text":"<pre><code>torch::nn::Linear xt::models::LeNet5::fc3;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#variable-layer1","title":"variable layer1","text":"<pre><code>torch::nn::Sequential xt::models::LeNet5::layer1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1LeNet5/#variable-layer2","title":"variable layer2","text":"<pre><code>torch::nn::Sequential xt::models::LeNet5::layer2;\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/lenet/lenet5.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/","title":"Struct xt::models::MobileNetV3","text":"<p>ClassList &gt; xt &gt; models &gt; MobileNetV3</p> <p>Inherits the following classes: xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel</p>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#public-functions","title":"Public Functions","text":"Type Name MobileNetV3 (int input_channels, int num_classes, float dropout_prob=0.5)  MobileNetV3 (int input_channels, int num_classes, float dropout_prob=0.5)  MobileNetV3 (int input_channels, int num_classes, float dropout_prob=0.5)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#public-functions-inherited-from-xtmodelsbasemodel_1","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#public-functions-inherited-from-xtmodelsbasemodel_2","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#function-mobilenetv3-13","title":"function MobileNetV3 [1/3]","text":"<pre><code>xt::models::MobileNetV3::MobileNetV3 (\n    int input_channels,\n    int num_classes,\n    float dropout_prob=0.5\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#function-mobilenetv3-13_1","title":"function MobileNetV3 [1/3]","text":"<pre><code>xt::models::MobileNetV3::MobileNetV3 (\n    int input_channels,\n    int num_classes,\n    float dropout_prob=0.5\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#function-mobilenetv3-13_2","title":"function MobileNetV3 [1/3]","text":"<pre><code>xt::models::MobileNetV3::MobileNetV3 (\n    int input_channels,\n    int num_classes,\n    float dropout_prob=0.5\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#function-forward-13","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::MobileNetV3::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#function-forward-13_1","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::MobileNetV3::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1MobileNetV3/#function-forward-13_2","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::MobileNetV3::forward (\n    torch::Tensor x\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v1.h</code></p>"},{"location":"xTorch/classxt_1_1models_1_1Model/","title":"Class xt::models::Model","text":"<p>ClassList &gt; xt &gt; models &gt; Model</p> <p>Inherits the following classes: xt::models::BaseModel</p>"},{"location":"xTorch/classxt_1_1models_1_1Model/#public-functions","title":"Public Functions","text":"Type Name Model (int a)  virtual torch::Tensor forward (torch::Tensor input) override const"},{"location":"xTorch/classxt_1_1models_1_1Model/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/classxt_1_1models_1_1Model/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1models_1_1Model/#function-model","title":"function Model","text":"<pre><code>xt::models::Model::Model (\n    int a\n) \n</code></pre>"},{"location":"xTorch/classxt_1_1models_1_1Model/#function-forward","title":"function forward","text":"<pre><code>virtual torch::Tensor xt::models::Model::forward (\n    torch::Tensor input\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/base.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/","title":"Struct xt::models::ResNet","text":"<p>ClassList &gt; xt &gt; models &gt; ResNet</p> <p>Inherits the following classes: xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-attributes","title":"Public Attributes","text":"Type Name torch::nn::AvgPool2d avgpool   = <code>nullptr</code> torch::nn::Sequential conv1   = <code>nullptr</code> torch::nn::Linear fc   = <code>nullptr</code> int inplanes   = <code>64</code> torch::nn::Sequential layer0   = <code>nullptr</code> torch::nn::Sequential layer1   = <code>nullptr</code> torch::nn::Sequential layer2   = <code>nullptr</code> torch::nn::Sequential layer3   = <code>nullptr</code> torch::nn::MaxPool2d maxpool   = <code>nullptr</code>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions","title":"Public Functions","text":"Type Name ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  ResNet (vector&lt; int &gt; layers, int num_classes=10, int in_channels=3)  ResNet (std::vector&lt; int &gt; layers, int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)  torch::nn::Sequential makeLayerFromResidualBlock (int planes, int blocks, int stride=1)"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_1","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_2","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_3","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_4","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_5","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_6","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_7","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_8","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_9","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_10","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-inherited-from-xtmodelsbasemodel_11","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-avgpool","title":"variable avgpool","text":"<pre><code>torch::nn::AvgPool2d xt::models::ResNet::avgpool;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-conv1","title":"variable conv1","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::conv1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-fc","title":"variable fc","text":"<pre><code>torch::nn::Linear xt::models::ResNet::fc;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-inplanes","title":"variable inplanes","text":"<pre><code>int xt::models::ResNet::inplanes;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-layer0","title":"variable layer0","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::layer0;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-layer1","title":"variable layer1","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::layer1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-layer2","title":"variable layer2","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::layer2;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-layer3","title":"variable layer3","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::layer3;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#variable-maxpool","title":"variable maxpool","text":"<pre><code>torch::nn::MaxPool2d xt::models::ResNet::maxpool;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_1","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_1","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_2","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_2","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_3","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_3","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_4","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_4","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_5","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_5","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_6","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_6","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_7","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_7","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_8","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_8","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_9","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_9","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_10","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_10","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-124_11","title":"function ResNet [1/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    vector&lt; int &gt; layers,\n    int num_classes=10,\n    int in_channels=3\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-resnet-224_11","title":"function ResNet [2/24]","text":"<pre><code>xt::models::ResNet::ResNet (\n    std::vector&lt; int &gt; layers,\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_1","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_2","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_3","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_4","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_5","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_6","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_7","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_8","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_9","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_10","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-forward-112_11","title":"function forward [1/12]","text":"<pre><code>virtual torch::Tensor xt::models::ResNet::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_1","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_2","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_3","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_4","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_5","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_6","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_7","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_8","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_9","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_10","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1ResNet/#function-makelayerfromresidualblock-112_11","title":"function makeLayerFromResidualBlock [1/12]","text":"<pre><code>torch::nn::Sequential xt::models::ResNet::makeLayerFromResidualBlock (\n    int planes,\n    int blocks,\n    int stride=1\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/res2net.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/","title":"Struct xt::models::SqueezeExcite","text":"<p>ClassList &gt; xt &gt; models &gt; SqueezeExcite</p> <p>Inherits the following classes: torch::nn::Module,  torch::nn::Module,  torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#public-functions","title":"Public Functions","text":"Type Name SqueezeExcite (int input_channels, int squeeze=4)  SqueezeExcite (int input_channels, int squeeze=4)  SqueezeExcite (int input_channels, int squeeze=4)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)  torch::Tensor forward (torch::Tensor x)"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#function-squeezeexcite-13","title":"function SqueezeExcite [1/3]","text":"<pre><code>xt::models::SqueezeExcite::SqueezeExcite (\n    int input_channels,\n    int squeeze=4\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#function-squeezeexcite-13_1","title":"function SqueezeExcite [1/3]","text":"<pre><code>xt::models::SqueezeExcite::SqueezeExcite (\n    int input_channels,\n    int squeeze=4\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#function-squeezeexcite-13_2","title":"function SqueezeExcite [1/3]","text":"<pre><code>xt::models::SqueezeExcite::SqueezeExcite (\n    int input_channels,\n    int squeeze=4\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#function-forward-13","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::SqueezeExcite::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#function-forward-13_1","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::SqueezeExcite::forward (\n    torch::Tensor x\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1SqueezeExcite/#function-forward-13_2","title":"function forward [1/3]","text":"<pre><code>torch::Tensor xt::models::SqueezeExcite::forward (\n    torch::Tensor x\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v1.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1UNet/","title":"Struct xt::models::UNet","text":"<p>ClassList &gt; xt &gt; models &gt; UNet</p> <p>Inherits the following classes: xt::models::BaseModel</p>"},{"location":"xTorch/structxt_1_1models_1_1UNet/#public-functions","title":"Public Functions","text":"Type Name UNet (int num_classes, int in_channels=1)  virtual torch::Tensor forward (torch::Tensor input) override const"},{"location":"xTorch/structxt_1_1models_1_1UNet/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1UNet/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1UNet/#function-unet","title":"function UNet","text":"<pre><code>xt::models::UNet::UNet (\n    int num_classes,\n    int in_channels=1\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1UNet/#function-forward","title":"function forward","text":"<pre><code>virtual torch::Tensor xt::models::UNet::forward (\n    torch::Tensor input\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/unet/unet.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1UpSample/","title":"Struct xt::models::UpSample","text":"<p>ClassList &gt; xt &gt; models &gt; UpSample</p> <p>Inherits the following classes: torch::nn::Module</p>"},{"location":"xTorch/structxt_1_1models_1_1UpSample/#public-functions","title":"Public Functions","text":"Type Name UpSample (int in_channels, int out_channels)  torch::Tensor forward (torch::Tensor x1, torch::Tensor x2)"},{"location":"xTorch/structxt_1_1models_1_1UpSample/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1UpSample/#function-upsample","title":"function UpSample","text":"<pre><code>xt::models::UpSample::UpSample (\n    int in_channels,\n    int out_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1UpSample/#function-forward","title":"function forward","text":"<pre><code>torch::Tensor xt::models::UpSample::forward (\n    torch::Tensor x1,\n    torch::Tensor x2\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/unet/unet.h</code></p>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/","title":"Struct xt::models::VggNet16","text":"<p>ClassList &gt; xt &gt; models &gt; VggNet16</p> <p>Inherits the following classes: xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel,  xt::models::BaseModel</p>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-attributes","title":"Public Attributes","text":"Type Name torch::nn::Sequential fc   = <code>nullptr</code> torch::nn::Sequential fc1   = <code>nullptr</code> torch::nn::Sequential fc2   = <code>nullptr</code> torch::nn::Sequential layer1   = <code>nullptr</code> torch::nn::Sequential layer10   = <code>nullptr</code> torch::nn::Sequential layer11   = <code>nullptr</code> torch::nn::Sequential layer12   = <code>nullptr</code> torch::nn::Sequential layer13   = <code>nullptr</code> torch::nn::Sequential layer2   = <code>nullptr</code> torch::nn::Sequential layer3   = <code>nullptr</code> torch::nn::Sequential layer4   = <code>nullptr</code> torch::nn::Sequential layer5   = <code>nullptr</code> torch::nn::Sequential layer6   = <code>nullptr</code> torch::nn::Sequential layer7   = <code>nullptr</code> torch::nn::Sequential layer8   = <code>nullptr</code> torch::nn::Sequential layer9   = <code>nullptr</code>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-functions","title":"Public Functions","text":"Type Name VggNet16 (int num_classes, int in_channels)  VggNet16 (int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  VggNet16 (int num_classes, int in_channels)  VggNet16 (int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  VggNet16 (int num_classes, int in_channels)  VggNet16 (int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  VggNet16 (int num_classes, int in_channels)  VggNet16 (int num_classes, int in_channels, std::vector&lt; int64_t &gt; input_shape)  virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const virtual torch::Tensor forward (torch::Tensor x) override const"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-functions-inherited-from-xtmodelsbasemodel","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-functions-inherited-from-xtmodelsbasemodel_1","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-functions-inherited-from-xtmodelsbasemodel_2","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-functions-inherited-from-xtmodelsbasemodel_3","title":"Public Functions inherited from xt::models::BaseModel","text":"<p>See xt::models::BaseModel</p> Type Name BaseModel ()  virtual torch::Tensor forward (torch::Tensor input) const = 0"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-fc","title":"variable fc","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::fc;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-fc1","title":"variable fc1","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::fc1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-fc2","title":"variable fc2","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::fc2;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer1","title":"variable layer1","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer1;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer10","title":"variable layer10","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer10;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer11","title":"variable layer11","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer11;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer12","title":"variable layer12","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer12;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer13","title":"variable layer13","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer13;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer2","title":"variable layer2","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer2;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer3","title":"variable layer3","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer3;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer4","title":"variable layer4","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer4;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer5","title":"variable layer5","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer5;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer6","title":"variable layer6","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer6;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer7","title":"variable layer7","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer7;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer8","title":"variable layer8","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer8;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#variable-layer9","title":"variable layer9","text":"<pre><code>torch::nn::Sequential xt::models::VggNet16::layer9;\n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-18","title":"function VggNet16 [1/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-28","title":"function VggNet16 [2/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-18_1","title":"function VggNet16 [1/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-28_1","title":"function VggNet16 [2/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-18_2","title":"function VggNet16 [1/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-28_2","title":"function VggNet16 [2/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-18_3","title":"function VggNet16 [1/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-vggnet16-28_3","title":"function VggNet16 [2/8]","text":"<pre><code>xt::models::VggNet16::VggNet16 (\n    int num_classes,\n    int in_channels,\n    std::vector&lt; int64_t &gt; input_shape\n) \n</code></pre>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-forward-14","title":"function forward [1/4]","text":"<pre><code>virtual torch::Tensor xt::models::VggNet16::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-forward-14_1","title":"function forward [1/4]","text":"<pre><code>virtual torch::Tensor xt::models::VggNet16::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-forward-14_2","title":"function forward [1/4]","text":"<pre><code>virtual torch::Tensor xt::models::VggNet16::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p>"},{"location":"xTorch/structxt_1_1models_1_1VggNet16/#function-forward-14_3","title":"function forward [1/4]","text":"<pre><code>virtual torch::Tensor xt::models::VggNet16::forward (\n    torch::Tensor x\n) override const\n</code></pre> <p>Implements xt::models::BaseModel::forward</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/vggnet/vggnet11.h</code></p>"},{"location":"xTorch/namespacext_1_1temp/","title":"Namespace xt::temp","text":"<p>Namespace List &gt; xt &gt; temp</p>"},{"location":"xTorch/namespacext_1_1temp/#classes","title":"Classes","text":"Type Name class TestDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/temp/test-dataset.h</code></p>"},{"location":"xTorch/classxt_1_1temp_1_1TestDataset/","title":"Class xt::temp::TestDataset","text":"<p>ClassList &gt; xt &gt; temp &gt; TestDataset</p>"},{"location":"xTorch/classxt_1_1temp_1_1TestDataset/#public-functions","title":"Public Functions","text":"Type Name TestDataset ()  torch::Tensor forward (torch::Tensor input)"},{"location":"xTorch/classxt_1_1temp_1_1TestDataset/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/classxt_1_1temp_1_1TestDataset/#function-testdataset","title":"function TestDataset","text":"<pre><code>xt::temp::TestDataset::TestDataset () \n</code></pre>"},{"location":"xTorch/classxt_1_1temp_1_1TestDataset/#function-forward","title":"function forward","text":"<pre><code>torch::Tensor xt::temp::TestDataset::forward (\n    torch::Tensor input\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/temp/test-dataset.h</code></p>"},{"location":"xTorch/namespacext_1_1utils/","title":"Namespace xt::utils","text":"<p>Namespace List &gt; xt &gt; utils</p>"},{"location":"xTorch/namespacext_1_1utils/#namespaces","title":"Namespaces","text":"Type Name namespace fs namespace string"},{"location":"xTorch/namespacext_1_1utils/#public-functions","title":"Public Functions","text":"Type Name std::tuple&lt; bool, std::string &gt; download (std::string &amp; url, std::string outPath)  std::tuple&lt; bool, std::string &gt; download_from_gdrive (std::string gid, std::string outPath)  bool extract (const std::string &amp; inFile, const std::string &amp; outFile=\"\")  std::tuple&lt; bool, string &gt; extractGzip (const std::string &amp; inFile, const std::string &amp; outFile=\"\")  bool extractTar (const std::string &amp; tarFile, const std::string &amp; outPath=\"./\")  bool extractTgz (const std::string &amp; inFile, const std::string &amp; outPath=\"./\")  void extractXZ (const std::string &amp; inputFile, const std::string &amp; outputFile)  bool extractZip (const std::string &amp; inFile, const std::string &amp; outPath=\"./\")  std::string get_md5_checksum (const std::string &amp; filename)  std::string rebuild_google_drive_link (std::string gid)"},{"location":"xTorch/namespacext_1_1utils/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext_1_1utils/#function-download","title":"function download","text":"<pre><code>std::tuple&lt; bool, std::string &gt; xt::utils::download (\n    std::string &amp; url,\n    std::string outPath\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-download_from_gdrive","title":"function download_from_gdrive","text":"<pre><code>std::tuple&lt; bool, std::string &gt; xt::utils::download_from_gdrive (\n    std::string gid,\n    std::string outPath\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-extract","title":"function extract","text":"<pre><code>bool xt::utils::extract (\n    const std::string &amp; inFile,\n    const std::string &amp; outFile=\"\"\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-extractgzip","title":"function extractGzip","text":"<pre><code>std::tuple&lt; bool, string &gt; xt::utils::extractGzip (\n    const std::string &amp; inFile,\n    const std::string &amp; outFile=\"\"\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-extracttar","title":"function extractTar","text":"<pre><code>bool xt::utils::extractTar (\n    const std::string &amp; tarFile,\n    const std::string &amp; outPath=\"./\"\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-extracttgz","title":"function extractTgz","text":"<pre><code>bool xt::utils::extractTgz (\n    const std::string &amp; inFile,\n    const std::string &amp; outPath=\"./\"\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-extractxz","title":"function extractXZ","text":"<pre><code>void xt::utils::extractXZ (\n    const std::string &amp; inputFile,\n    const std::string &amp; outputFile\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-extractzip","title":"function extractZip","text":"<pre><code>bool xt::utils::extractZip (\n    const std::string &amp; inFile,\n    const std::string &amp; outPath=\"./\"\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-get_md5_checksum","title":"function get_md5_checksum","text":"<pre><code>std::string xt::utils::get_md5_checksum (\n    const std::string &amp; filename\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils/#function-rebuild_google_drive_link","title":"function rebuild_google_drive_link","text":"<pre><code>std::string xt::utils::rebuild_google_drive_link (\n    std::string gid\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/downloader.h</code></p>"},{"location":"xTorch/namespacext_1_1utils_1_1fs/","title":"Namespace xt::utils::fs","text":"<p>Namespace List &gt; xt &gt; utils &gt; fs</p>"},{"location":"xTorch/namespacext_1_1utils_1_1fs/#public-functions","title":"Public Functions","text":"Type Name std::size_t countFiles (const std::filesystem::path &amp; path, bool recursive=true)"},{"location":"xTorch/namespacext_1_1utils_1_1fs/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext_1_1utils_1_1fs/#function-countfiles","title":"function countFiles","text":"<pre><code>std::size_t xt::utils::fs::countFiles (\n    const std::filesystem::path &amp; path,\n    bool recursive=true\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/filesystem.h</code></p>"},{"location":"xTorch/namespacext_1_1utils_1_1string/","title":"Namespace xt::utils::string","text":"<p>Namespace List &gt; xt &gt; utils &gt; string</p>"},{"location":"xTorch/namespacext_1_1utils_1_1string/#public-functions","title":"Public Functions","text":"Type Name vector&lt; std::string &gt; split (const std::string &amp; str, const std::string &amp; delim)  std::string trim (std::string &amp; str)"},{"location":"xTorch/namespacext_1_1utils_1_1string/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"xTorch/namespacext_1_1utils_1_1string/#function-split","title":"function split","text":"<pre><code>vector&lt; std::string &gt; xt::utils::string::split (\n    const std::string &amp; str,\n    const std::string &amp; delim\n) \n</code></pre>"},{"location":"xTorch/namespacext_1_1utils_1_1string/#function-trim","title":"function trim","text":"<pre><code>std::string xt::utils::string::trim (\n    std::string &amp; str\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/string.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d004076223253223034345146250242170367011070371353/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet50.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d037357166076105226224335212040170170137167303075/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet200.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d047346116371250047366264317312112177031330363156/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet34.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d055232276273157020167115003176162055152061074124/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/res2net.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d061134117267053217040070235306223273214034257352/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet152.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d146130133241212117210302040014146320364244234174/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/wide-resnet.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d147076364111056125143074344367043221273152312152/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet18.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d237207357157206273022110131316032317332370147056/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnext.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d313052300150334303304245201033347263225341022212/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet-v1.5.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d313156072370137220252216224241111010231220305250/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet101.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d316255225002036160226346056300012103064301071303/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet-rs.h</code></p>"},{"location":"xTorch/namespacext_1_1models_1_1_0d354232345332132117104327274336030071164300152203/","title":"Namespace xt::models","text":"<p>Namespace List &gt; models</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet1202.h</code></p>"},{"location":"xTorch/dir_d44c64559bbebec7f509842c48db8b23/","title":"Dir /home/kami/Documents/cpp/models/include","text":"<p>FileList &gt; include</p>"},{"location":"xTorch/dir_d44c64559bbebec7f509842c48db8b23/#files","title":"Files","text":"Type Name file xtorch.h"},{"location":"xTorch/dir_d44c64559bbebec7f509842c48db8b23/#directories","title":"Directories","text":"Type Name dir data-loaders dir datasets dir definitions dir exceptions dir headers dir media dir models dir temp dir trainers dir transforms dir types dir utils <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/</code></p>"},{"location":"xTorch/dir_83fc80326b80dce73692b3bd70d110c8/","title":"Dir /home/kami/Documents/cpp/models/include/data-loaders","text":"<p>FileList &gt; data-loaders</p>"},{"location":"xTorch/dir_83fc80326b80dce73692b3bd70d110c8/#files","title":"Files","text":"Type Name file data-loader.h file data-loaders.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/data-loaders/</code></p>"},{"location":"xTorch/data-loader_8h/","title":"File data-loader.h","text":"<p>FileList &gt; data-loaders &gt; data-loader.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;random&gt;</code></li> <li><code>#include &lt;optional&gt;</code></li> <li><code>#include \"../datasets/base/base.h\"</code></li> <li><code>#include \"data-loader.tpp\"</code></li> </ul>"},{"location":"xTorch/data-loader_8h/#namespaces","title":"Namespaces","text":"Type Name namespace std namespace xt"},{"location":"xTorch/data-loader_8h/#classes","title":"Classes","text":"Type Name class DataLoader &lt;typename Dataset&gt; <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/data-loaders/data-loader.h</code></p>"},{"location":"xTorch/data-loader_8h_source/","title":"File data-loader.h","text":"<p>File List &gt; data-loaders &gt; data-loader.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;filesystem&gt;\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;optional&gt;\n#include \"../datasets/base/base.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt {\n\n    template &lt;typename Dataset&gt;\n    bool is_transformed_dataset(const Dataset&amp; dataset) {\n        if constexpr (std::is_same_v&lt;Dataset, torch::data::datasets::MapDataset&lt;xt::data::datasets::BaseDataset, torch::data::transforms::Stack&lt;&gt;&gt;&gt;) {\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n\ntemplate &lt;typename Dataset&gt;\nclass DataLoader : public torch::data::DataLoaderBase&lt;Dataset, typename Dataset::BatchType, std::vector&lt;size_t&gt;&gt; {\n\npublic:\n    using BatchType        = typename Dataset::BatchType;          // e.g., Example&lt;Tensor, Tensor&gt;\n    using BatchRequestType = std::vector&lt;size_t&gt;;                  // list of indices for one batch\n    using Base = torch::data::DataLoaderBase&lt;Dataset, BatchType, BatchRequestType&gt;;\n    DataLoader(Dataset dataset, const torch::data::DataLoaderOptions&amp; options, bool shuffle = false);\n\n//    // Iterator support for range-for loops\n//    typename Base::iterator begin() {\n//        this-&gt;reset();       // reset (and shuffle if needed) at start of epoch\n//        return Base::begin();\n//    }\n//    typename Base::iterator end() {\n//        return Base::end();\n//    }\n\nprotected:\n    // Provide the next batch of indices to fetch from the dataset\n    std::optional&lt;BatchRequestType&gt; get_batch_request() override ;\n    // Reset and (optionally) shuffle indices for a new epoch\n    void reset_indices();\n    // Override base class reset() to shuffle indices each epoch (if enabled)\n    void reset() override;\nprivate:\n    Dataset* dataset_ptr_;           // raw pointer to the dataset (owned by base class)\n    std::vector&lt;size_t&gt; indices_;    // sequence of indices to iterate over\n    size_t current_index_ = 0;       // current position in indices_ vector\n    size_t batch_size_;\n    bool shuffle_;\n    bool drop_last_;\n};\n\n\n}\n#include \"data-loader.tpp\"\n\n</code></pre>"},{"location":"xTorch/data-loaders_8h/","title":"File data-loaders.h","text":"<p>FileList &gt; data-loaders &gt; data-loaders.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"data-loader.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/data-loaders/data-loaders.h</code></p>"},{"location":"xTorch/data-loaders_8h_source/","title":"File data-loaders.h","text":"<p>File List &gt; data-loaders &gt; data-loaders.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"data-loader.h\"\n</code></pre>"},{"location":"xTorch/dir_29ff4802398ba4a572b958e731c7adb4/","title":"Dir /home/kami/Documents/cpp/models/include/datasets","text":"<p>FileList &gt; datasets</p>"},{"location":"xTorch/dir_29ff4802398ba4a572b958e731c7adb4/#files","title":"Files","text":"Type Name file datasets.h"},{"location":"xTorch/dir_29ff4802398ba4a572b958e731c7adb4/#directories","title":"Directories","text":"Type Name dir audio-speech dir base dir definitions dir face-recognition dir general dir image-classification dir language-modeling dir machine-translation dir natural-language-inference dir object-detection-and-segmentation dir optical-flow dir patch-matching-descriptor-learning dir scene-flow dir sentiment-analysis dir sequence-tagging dir specific dir stereo-matching-depth-estimation dir text-classification dir video <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/</code></p>"},{"location":"xTorch/dir_3f959236e5b642d039994a38a6e55324/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/audio-speech","text":"<p>FileList &gt; audio-speech</p>"},{"location":"xTorch/dir_3f959236e5b642d039994a38a6e55324/#files","title":"Files","text":"Type Name file audio-speech.h file cmu-arctic.h file common-voice.h file crema-d.h file esc.h file gtzan.h file librispeech.h file lj-speech.h file speech-commands.h file tedlium.h file timit.h file urban-sound.h file vctk.h file vox-celeb.h file yes-no.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/</code></p>"},{"location":"xTorch/audio-speech_8h/","title":"File audio-speech.h","text":"<p>FileList &gt; audio-speech &gt; audio-speech.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"cmu-arctic.h\"</code></li> <li><code>#include \"common-voice.h\"</code></li> <li><code>#include \"crema-d.h\"</code></li> <li><code>#include \"esc.h\"</code></li> <li><code>#include \"gtzan.h\"</code></li> <li><code>#include \"librispeech.h\"</code></li> <li><code>#include \"lj-speech.h\"</code></li> <li><code>#include \"speech-commands.h\"</code></li> <li><code>#include \"tedlium.h\"</code></li> <li><code>#include \"timit.h\"</code></li> <li><code>#include \"urban-sound.h\"</code></li> <li><code>#include \"vctk.h\"</code></li> <li><code>#include \"vox-celeb.h\"</code></li> <li><code>#include \"yes-no.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/audio-speech.h</code></p>"},{"location":"xTorch/audio-speech_8h_source/","title":"File audio-speech.h","text":"<p>File List &gt; audio-speech &gt; audio-speech.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"cmu-arctic.h\"\n#include \"common-voice.h\"\n#include \"crema-d.h\"\n#include \"esc.h\"\n#include \"gtzan.h\"\n#include \"librispeech.h\"\n#include \"lj-speech.h\"\n#include \"speech-commands.h\"\n#include \"tedlium.h\"\n#include \"timit.h\"\n#include \"urban-sound.h\"\n#include \"vctk.h\"\n#include \"vox-celeb.h\"\n#include \"yes-no.h\"\n</code></pre>"},{"location":"xTorch/cmu-arctic_8h/","title":"File cmu-arctic.h","text":"<p>FileList &gt; audio-speech &gt; cmu-arctic.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/cmu-arctic_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/cmu-arctic_8h/#classes","title":"Classes","text":"Type Name class CMUArctic <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/cmu-arctic.h</code></p>"},{"location":"xTorch/cmu-arctic_8h_source/","title":"File cmu-arctic.h","text":"<p>File List &gt; audio-speech &gt; cmu-arctic.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class CMUArctic : BaseDataset {\n    public :\n        explicit CMUArctic(const std::string &amp;root);\n        CMUArctic(const std::string &amp;root, DataMode mode);\n        CMUArctic(const std::string &amp;root, DataMode mode , bool download);\n        CMUArctic(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/common-voice_8h/","title":"File common-voice.h","text":"<p>FileList &gt; audio-speech &gt; common-voice.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/common-voice_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/common-voice_8h/#classes","title":"Classes","text":"Type Name class CommonVoice <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/common-voice.h</code></p>"},{"location":"xTorch/common-voice_8h_source/","title":"File common-voice.h","text":"<p>File List &gt; audio-speech &gt; common-voice.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class CommonVoice : BaseDataset {\n    public :\n        explicit CommonVoice(const std::string &amp;root);\n        CommonVoice(const std::string &amp;root, DataMode mode);\n        CommonVoice(const std::string &amp;root, DataMode mode , bool download);\n        CommonVoice(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/crema-d_8h/","title":"File crema-d.h","text":"<p>FileList &gt; audio-speech &gt; crema-d.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/crema-d_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/crema-d_8h/#classes","title":"Classes","text":"Type Name class CremaD <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/crema-d.h</code></p>"},{"location":"xTorch/crema-d_8h_source/","title":"File crema-d.h","text":"<p>File List &gt; audio-speech &gt; crema-d.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class CremaD : BaseDataset {\n    public :\n        explicit CremaD(const std::string &amp;root);\n\n        CremaD(const std::string &amp;root, DataMode mode);\n\n        CremaD(const std::string &amp;root, DataMode mode, bool download);\n\n        CremaD(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/esc_8h/","title":"File esc.h","text":"<p>FileList &gt; audio-speech &gt; esc.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/esc_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/esc_8h/#classes","title":"Classes","text":"Type Name class ESC <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/esc.h</code></p>"},{"location":"xTorch/esc_8h_source/","title":"File esc.h","text":"<p>File List &gt; audio-speech &gt; esc.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class ESC : BaseDataset {\n    public :\n        explicit ESC(const std::string &amp;root);\n\n        ESC(const std::string &amp;root, DataMode mode);\n\n        ESC(const std::string &amp;root, DataMode mode, bool download);\n\n        ESC(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/gtzan_8h/","title":"File gtzan.h","text":"<p>FileList &gt; audio-speech &gt; gtzan.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/gtzan_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/gtzan_8h/#classes","title":"Classes","text":"Type Name class GTZAN <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/gtzan.h</code></p>"},{"location":"xTorch/gtzan_8h_source/","title":"File gtzan.h","text":"<p>File List &gt; audio-speech &gt; gtzan.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class GTZAN : BaseDataset {\n    public :\n        explicit GTZAN(const std::string &amp;root);\n\n        GTZAN(const std::string &amp;root, DataMode mode);\n\n        GTZAN(const std::string &amp;root, DataMode mode, bool download);\n\n        GTZAN(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/librispeech_8h/","title":"File librispeech.h","text":"<p>FileList &gt; audio-speech &gt; librispeech.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/librispeech_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/librispeech_8h/#classes","title":"Classes","text":"Type Name class LibriSpeech <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/librispeech.h</code></p>"},{"location":"xTorch/librispeech_8h_source/","title":"File librispeech.h","text":"<p>File List &gt; audio-speech &gt; librispeech.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class LibriSpeech : BaseDataset {\n    public :\n        explicit LibriSpeech(const std::string &amp;root);\n\n        LibriSpeech(const std::string &amp;root, DataMode mode);\n\n        LibriSpeech(const std::string &amp;root, DataMode mode, bool download);\n\n        LibriSpeech(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/lj-speech_8h/","title":"File lj-speech.h","text":"<p>FileList &gt; audio-speech &gt; lj-speech.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/lj-speech_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/lj-speech_8h/#classes","title":"Classes","text":"Type Name class LjSpeech <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/lj-speech.h</code></p>"},{"location":"xTorch/lj-speech_8h_source/","title":"File lj-speech.h","text":"<p>File List &gt; audio-speech &gt; lj-speech.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class LjSpeech : BaseDataset {\n    public :\n        explicit LjSpeech(const std::string &amp;root);\n\n        LjSpeech(const std::string &amp;root, DataMode mode);\n\n        LjSpeech(const std::string &amp;root, DataMode mode, bool download);\n\n        LjSpeech(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/speech-commands_8h/","title":"File speech-commands.h","text":"<p>FileList &gt; audio-speech &gt; speech-commands.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/speech-commands_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/speech-commands_8h/#classes","title":"Classes","text":"Type Name class SpeechCommands <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/speech-commands.h</code></p>"},{"location":"xTorch/speech-commands_8h_source/","title":"File speech-commands.h","text":"<p>File List &gt; audio-speech &gt; speech-commands.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class SpeechCommands : BaseDataset {\n    public :\n        explicit SpeechCommands(const std::string &amp;root);\n\n        SpeechCommands(const std::string &amp;root, DataMode mode);\n\n        SpeechCommands(const std::string &amp;root, DataMode mode, bool download);\n\n        SpeechCommands(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/tedlium_8h/","title":"File tedlium.h","text":"<p>FileList &gt; audio-speech &gt; tedlium.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/tedlium_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/tedlium_8h/#classes","title":"Classes","text":"Type Name class Tedlium <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/tedlium.h</code></p>"},{"location":"xTorch/tedlium_8h_source/","title":"File tedlium.h","text":"<p>File List &gt; audio-speech &gt; tedlium.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Tedlium : BaseDataset {\n    public :\n        explicit Tedlium(const std::string &amp;root);\n\n        Tedlium(const std::string &amp;root, DataMode mode);\n\n        Tedlium(const std::string &amp;root, DataMode mode, bool download);\n\n        Tedlium(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/timit_8h/","title":"File timit.h","text":"<p>FileList &gt; audio-speech &gt; timit.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/timit_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/timit_8h/#classes","title":"Classes","text":"Type Name class TIMIT <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/timit.h</code></p>"},{"location":"xTorch/timit_8h_source/","title":"File timit.h","text":"<p>File List &gt; audio-speech &gt; timit.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class TIMIT : BaseDataset {\n    public :\n        explicit TIMIT(const std::string &amp;root);\n\n        TIMIT(const std::string &amp;root, DataMode mode);\n\n        TIMIT(const std::string &amp;root, DataMode mode, bool download);\n\n        TIMIT(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/urban-sound_8h/","title":"File urban-sound.h","text":"<p>FileList &gt; audio-speech &gt; urban-sound.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/urban-sound_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/urban-sound_8h/#classes","title":"Classes","text":"Type Name class UrbanSound <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/urban-sound.h</code></p>"},{"location":"xTorch/urban-sound_8h_source/","title":"File urban-sound.h","text":"<p>File List &gt; audio-speech &gt; urban-sound.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class UrbanSound : BaseDataset {\n    public :\n        explicit UrbanSound(const std::string &amp;root);\n\n        UrbanSound(const std::string &amp;root, DataMode mode);\n\n        UrbanSound(const std::string &amp;root, DataMode mode, bool download);\n\n        UrbanSound(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/vctk_8h/","title":"File vctk.h","text":"<p>FileList &gt; audio-speech &gt; vctk.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/vctk_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/vctk_8h/#classes","title":"Classes","text":"Type Name class VCTK <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/vctk.h</code></p>"},{"location":"xTorch/vctk_8h_source/","title":"File vctk.h","text":"<p>File List &gt; audio-speech &gt; vctk.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class VCTK : BaseDataset {\n        public :\n            explicit VCTK(const std::string &amp;root);\n        VCTK(const std::string &amp;root, DataMode mode);\n        VCTK(const std::string &amp;root, DataMode mode , bool download);\n        VCTK(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/vox-celeb_8h/","title":"File vox-celeb.h","text":"<p>FileList &gt; audio-speech &gt; vox-celeb.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/vox-celeb_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/vox-celeb_8h/#classes","title":"Classes","text":"Type Name class VoxCeleb <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/vox-celeb.h</code></p>"},{"location":"xTorch/vox-celeb_8h_source/","title":"File vox-celeb.h","text":"<p>File List &gt; audio-speech &gt; vox-celeb.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class VoxCeleb : BaseDataset {\n        public :\n            explicit VoxCeleb(const std::string &amp;root);\n        VoxCeleb(const std::string &amp;root, DataMode mode);\n        VoxCeleb(const std::string &amp;root, DataMode mode , bool download);\n        VoxCeleb(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/yes-no_8h/","title":"File yes-no.h","text":"<p>FileList &gt; audio-speech &gt; yes-no.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/yes-no_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/yes-no_8h/#classes","title":"Classes","text":"Type Name class YesNo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/audio-speech/yes-no.h</code></p>"},{"location":"xTorch/yes-no_8h_source/","title":"File yes-no.h","text":"<p>File List &gt; audio-speech &gt; yes-no.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class YesNo : BaseDataset {\n        public :\n            explicit YesNo(const std::string &amp;root);\n        YesNo(const std::string &amp;root, DataMode mode);\n        YesNo(const std::string &amp;root, DataMode mode , bool download);\n        YesNo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_9657a40feeddef1c88c156c7806ef467/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/base","text":"<p>FileList &gt; base</p>"},{"location":"xTorch/dir_9657a40feeddef1c88c156c7806ef467/#files","title":"Files","text":"Type Name file base.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/base/</code></p>"},{"location":"xTorch/datasets_2base_2base_8h/","title":"File base.h","text":"<p>FileList &gt; base &gt; base.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/datasets_2base_2base_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/datasets_2base_2base_8h/#classes","title":"Classes","text":"Type Name class BaseDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/base/base.h</code></p>"},{"location":"xTorch/datasets_2base_2base_8h_source/","title":"File base.h","text":"<p>File List &gt; base &gt; base.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class BaseDataset : public torch::data::Dataset&lt;BaseDataset&gt; {\n\n    public:\n        using TransformType = vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt; &gt;;\n\n        BaseDataset(const std::string &amp;root);\n        BaseDataset(const std::string &amp;root, DataMode mode);\n        BaseDataset(const std::string &amp;root, DataMode mode , bool download);\n        BaseDataset(const std::string &amp;root, DataMode mode , bool download , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n\n            // virtual ~BaseDataset() = 0;\n\n        // BaseDataset(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n\n        torch::data::Example&lt;&gt; get(size_t index) override;\n\n        torch::optional&lt;size_t&gt; size() const override;\n\n    public:\n        std::vector&lt;torch::Tensor&gt; data; // Store image data as tensors\n        std::vector&lt;uint8_t&gt; labels; // Store labels\n        DataMode mode = DataMode::TRAIN;\n        bool download = false;\n        fs::path root;\n        fs::path dataset_path;\n        xt::data::transforms::Compose compose;\n        vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms = {};\n\n\n    private:\n        // vector&lt;torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; &gt; transforms = {};\n\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_92610beb03a79c6b2c32aee384ba5d92/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/definitions","text":"<p>FileList &gt; datasets &gt; definitions</p>"},{"location":"xTorch/dir_92610beb03a79c6b2c32aee384ba5d92/#files","title":"Files","text":"Type Name file definitions.h file functions.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/definitions/</code></p>"},{"location":"xTorch/definitions_8h/","title":"File definitions.h","text":"<p>FileList &gt; datasets &gt; definitions &gt; definitions.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"functions.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/definitions/definitions.h</code></p>"},{"location":"xTorch/definitions_8h_source/","title":"File definitions.h","text":"<p>File List &gt; datasets &gt; definitions &gt; definitions.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"functions.h\"\n</code></pre>"},{"location":"xTorch/functions_8h/","title":"File functions.h","text":"<p>FileList &gt; datasets &gt; definitions &gt; functions.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/functions_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/definitions/functions.h</code></p>"},{"location":"xTorch/functions_8h_source/","title":"File functions.h","text":"<p>File List &gt; datasets &gt; definitions &gt; functions.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data {\n    torch::data::datasets::MapDataset&lt;xt::data::datasets::BaseDataset , torch::data::transforms::Stack&lt;&gt;()&gt;\n    transform_dataset(xt::data::datasets::BaseDataset dataset, vector&lt;torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; &gt; transforms);\n}\n</code></pre>"},{"location":"xTorch/dir_510c6254a6be63fdcb0b1e5d731b55b5/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/face-recognition","text":"<p>FileList &gt; datasets &gt; face-recognition</p>"},{"location":"xTorch/dir_510c6254a6be63fdcb0b1e5d731b55b5/#files","title":"Files","text":"Type Name file face-recognition.h file lfw.h file wider-face.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/</code></p>"},{"location":"xTorch/face-recognition_8h/","title":"File face-recognition.h","text":"<p>FileList &gt; datasets &gt; face-recognition &gt; face-recognition.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"lfw.h\"</code></li> <li><code>#include \"wider-face.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/face-recognition.h</code></p>"},{"location":"xTorch/face-recognition_8h_source/","title":"File face-recognition.h","text":"<p>File List &gt; datasets &gt; face-recognition &gt; face-recognition.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n\n#include \"lfw.h\"\n#include \"wider-face.h\"\n</code></pre>"},{"location":"xTorch/lfw_8h/","title":"File lfw.h","text":"<p>FileList &gt; datasets &gt; face-recognition &gt; lfw.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/lfw_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/lfw_8h/#classes","title":"Classes","text":"Type Name class LFW class LFWPairs class LFWPeople <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/lfw.h</code></p>"},{"location":"xTorch/lfw_8h_source/","title":"File lfw.h","text":"<p>File List &gt; datasets &gt; face-recognition &gt; lfw.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::data::datasets {\n    class LFW : public BaseDataset {\n    public :\n        explicit LFW(const std::string &amp;root);\n        LFW(const std::string &amp;root, DataMode mode);\n        LFW(const std::string &amp;root, DataMode mode , bool download);\n        LFW(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        fs::path dataset_folder_name = fs::path(\"lfw-py\");\n        fs::path url = fs::path(\"http://vis-www.cs.umass.edu/lfw/\");\n        std::map&lt;std::string, std::tuple&lt;std::string, fs::path, std::string&gt; &gt; file_dict = {\n            {\"original\", {\"lfw\", fs::path(\"lfw.tgz\"), \"a17d05bd522c52d84eca14327a23d494\"}},\n            {\"funneled\", {\"lfw_funneled\", fs::path(\"lfw-funneled.tgz\"), \"1b42dfed7d15c9b2dd63d5e5840c86ad\"}},\n            {\n                \"deepfunneled\",\n                {\"lfw-deepfunneled\", fs::path(\"lfw-deepfunneled.tgz\"), \"68331da3eb755a505a502b5aacb3c201\"}\n            }\n        };\n\n        std::map&lt;std::string, std::string&gt; checksums = {\n            {\"pairs.txt\", \"9f1ba174e4e1c508ff7cdf10ac338a7d\"},\n            {\"pairsDevTest.txt\", \"5132f7440eb68cf58910c8a45a2ac10b\"},\n            {\"pairsDevTrain.txt\", \"4f27cbf15b2da4a85c1907eb4181ad21\"},\n            {\"people.txt\", \"450f0863dd89e85e73936a6d71a3474b\"},\n            {\"peopleDevTest.txt\", \"e4bf5be0a43b5dcd9dc5ccfcb8fb19c5\"},\n            {\"peopleDevTrain.txt\", \"54eaac34beb6d042ed3a7d883e247a21\"},\n            {\"lfw-names.txt\", \"a6d0a479bd074669f656265a6e693f6d\"}\n        };\n\n        std::map&lt;std::string, std::string&gt; annot_file = {\n            {\"10fold\", \"\"},\n            {\"train\", \"DevTrain\"},\n            {\"test\", \"DevTest\"}\n        };\n        fs::path names = fs::path(\"lfw-names.txt\");\n\n        void load_data();\n\n        void check_resources();\n    };\n\n    class LFWPeople : public LFW {\n        /*\n        \"\"\"`LFW &lt;http://vis-www.cs.umass.edu/lfw/&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where directory\n            ``lfw-py`` exists or will be saved to if download is set to True.\n        split (string, optional): The image split to use. Can be one of ``train``, ``test``,\n            ``10fold`` (default).\n        image_set (str, optional): Type of image funneling to use, ``original``, ``funneled`` or\n            ``deepfunneled``. Defaults to ``funneled``.\n        transform (callable, optional): A function/transform that  takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomRotation``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n         */\n    public :\n        explicit LFWPeople(const std::string &amp;root);\n        LFWPeople(const std::string &amp;root, DataMode mode);\n        LFWPeople(const std::string &amp;root, DataMode mode , bool download);\n        LFWPeople(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n    class LFWPairs : public LFW {\n        /*\n        \"\"\"`LFW &lt;http://vis-www.cs.umass.edu/lfw/&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where directory\n            ``lfw-py`` exists or will be saved to if download is set to True.\n        split (string, optional): The image split to use. Can be one of ``train``, ``test``,\n            ``10fold``. Defaults to ``10fold``.\n        image_set (str, optional): Type of image funneling to use, ``original``, ``funneled`` or\n            ``deepfunneled``. Defaults to ``funneled``.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomRotation``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n\n         */\n    public :\n        explicit  LFWPairs(const std::string &amp;root);\n        LFWPairs(const std::string &amp;root, DataMode mode);\n        LFWPairs(const std::string &amp;root, DataMode mode , bool download);\n        LFWPairs(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/wider-face_8h/","title":"File wider-face.h","text":"<p>FileList &gt; datasets &gt; face-recognition &gt; wider-face.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/wider-face_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/wider-face_8h/#classes","title":"Classes","text":"Type Name class WIDERFace <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/face-recognition/wider-face.h</code></p>"},{"location":"xTorch/wider-face_8h_source/","title":"File wider-face.h","text":"<p>File List &gt; datasets &gt; face-recognition &gt; wider-face.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class WIDERFace : BaseDataset {\n        /*\n        \"\"\"`WIDERFace &lt;http://shuoyang1213.me/WIDERFACE/&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory where images and annotations are downloaded to.\n            Expects the following folder structure if download=False:\n\n            .. code::\n\n                &lt;root&gt;\n                    \u2514\u2500\u2500 widerface\n                        \u251c\u2500\u2500 wider_face_split ('wider_face_split.zip' if compressed)\n                        \u251c\u2500\u2500 WIDER_train ('WIDER_train.zip' if compressed)\n                        \u251c\u2500\u2500 WIDER_val ('WIDER_val.zip' if compressed)\n                        \u2514\u2500\u2500 WIDER_test ('WIDER_test.zip' if compressed)\n        split (string): The dataset split to use. One of {``train``, ``val``, ``test``}.\n            Defaults to ``train``.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n            .. warning::\n\n                To download the dataset `gdown &lt;https://github.com/wkentaro/gdown&gt;`_ is required.\n\n    \"\"\"\n\n         */\n    public :\n        explicit WIDERFace(const std::string &amp;root);\n        WIDERFace(const std::string &amp;root, DataMode mode);\n        WIDERFace(const std::string &amp;root, DataMode mode , bool download);\n        WIDERFace(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private:\n        fs::path dataset_folder_name = fs::path(\"widerface\");\n        std::vector&lt;std::tuple&lt;std::string, std::string, fs::path&gt; &gt; resources = {\n                {\"15hGDLhsx8bLgLcIRD5DhYt5iBxnjNF1M\", \"3fedf70df600953d25982bcd13d91ba2\", fs::path(\"WIDER_train.zip\")},\n                {\"1GUCogbp16PMGa39thoMMeWxp7Rp5oM8Q\", \"dfa7d7e790efa35df3788964cf0bbaea\", fs::path(\"WIDER_val.zip\")},\n                {\"1HIfDbVEWKmsYKJZm4lchTBDLW5N7dY5T\", \"e5d8f4248ed24c334bbd12f49c29dd40\", fs::path(\"WIDER_test.zip\")}\n        };\n        std::tuple&lt;fs::path, std::string, fs::path&gt; ANNOTATIONS_FILE = {\n                fs::path(\"http://shuoyang1213.me/WIDERFACE/support/bbx_annotation/wider_face_split.zip\"),\n                \"0e3767bcf0e326556d407bf5bff5d27c\",\n                fs::path(\"wider_face_split.zip\")\n        };\n        void load_data();\n\n        void check_resources();\n\n\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_3e490c73b2bbc01f3b90ef3b6e284c64/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/general","text":"<p>FileList &gt; datasets &gt; general</p>"},{"location":"xTorch/dir_3e490c73b2bbc01f3b90ef3b6e284c64/#files","title":"Files","text":"Type Name file audio-dataset.h file csv-dataset.h file edf-dataset.h file general.h file image-folder.h file tensor-dataset.h file text-dataset.h file time-series-dataset.h file video-dataset.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/</code></p>"},{"location":"xTorch/audio-dataset_8h/","title":"File audio-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; audio-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;torch/data/datasets.h&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;sndfile.hh&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;sstream&gt;</code></li> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/audio-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/audio-dataset_8h/#classes","title":"Classes","text":"Type Name class AudioDataset class StackedAudioDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/audio-dataset.h</code></p>"},{"location":"xTorch/audio-dataset_8h_source/","title":"File audio-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; audio-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;torch/torch.h&gt;\n#include &lt;torch/data/datasets.h&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\n#include &lt;sndfile.hh&gt;\n#include &lt;fstream&gt;\n#include &lt;sstream&gt;\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n\n\n\n\n    class AudioDataset : public torch::data::datasets::Dataset&lt;AudioDataset&gt; {\n    public:\n        AudioDataset(const std::string&amp; audio_dir, const std::string&amp; label_file) {\n            std::ifstream label_stream(label_file);\n            std::string line;\n            while (std::getline(label_stream, line)) {\n                std::istringstream iss(line);\n                std::string filename, label_str;\n                iss &gt;&gt; filename &gt;&gt; label_str;\n                file_paths.push_back(audio_dir + \"/\" + filename + \".wav\");\n                labels.push_back(std::stoi(label_str));\n            }\n        }\n\n        torch::data::Example&lt;&gt; get(size_t index) override {\n            SndfileHandle file(file_paths[index]);\n            std::vector&lt;float&gt; samples(file.frames());\n            file.read(&amp;samples[0], file.frames());\n            auto options = torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCPU);\n            torch::Tensor waveform = torch::from_blob(samples.data(), {1, (int64_t)samples.size()}, options).clone();\n            torch::Tensor label = torch::full({1}, labels[index], torch::kLong);\n            return {waveform, label};\n        }\n\n        torch::optional&lt;size_t&gt; size() const override {\n            return file_paths.size();\n        }\n\n    private:\n        std::vector&lt;std::string&gt; file_paths;\n        std::vector&lt;int&gt; labels;\n    };\n\n    class StackedAudioDataset : public BaseDataset {\n        public :\n            StackedAudioDataset(const std::string &amp;folder_path);\n\n        StackedAudioDataset(const std::string &amp;folder_path, DataMode mode);\n\n        StackedAudioDataset(const std::string &amp;folder_path, DataMode mode, bool load_sub_folders);\n\n        StackedAudioDataset(const std::string &amp;folder_path, DataMode mode, bool load_sub_folders,\n                          vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt; &gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n\n        void load_data();\n    };\n\n\n}\n</code></pre>"},{"location":"xTorch/csv-dataset_8h/","title":"File csv-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; csv-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> <li><code>#include \"../../../third_party/csv2/reader.hpp\"</code></li> </ul>"},{"location":"xTorch/csv-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/csv-dataset_8h/#classes","title":"Classes","text":"Type Name class CSVDataset class StackedCSVDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/csv-dataset.h</code></p>"},{"location":"xTorch/csv-dataset_8h_source/","title":"File csv-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; csv-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n#include \"../../../third_party/csv2/reader.hpp\"\n\n\n\nnamespace xt::data::datasets {\n    class CSVDataset : public BaseDataset {\n    public :\n        CSVDataset(const std::string &amp;file_path);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;int&gt; x_indices, int y_index);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;int&gt; x_indices, vector&lt;int&gt; y_indices);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;string&gt; x_titles, string y_title);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;string&gt; x_titles, vector&lt;string&gt; y_titles);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, TransformType transforms);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;int&gt; x_indices, int y_index, TransformType transforms);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;int&gt; x_indices, vector&lt;int&gt; y_indices, TransformType transforms);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;string&gt; x_titles, string y_title, TransformType transforms);\n\n        CSVDataset(const std::string &amp;file_path, DataMode mode, vector&lt;string&gt; x_titles, vector&lt;string&gt; y_titles, TransformType transforms);\n\n    private:\n        vector&lt;int&gt; x_indices;\n        vector&lt;int&gt; y_indices;\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n\n        void load_data();\n    };\n\n\n    class StackedCSVDataset : public BaseDataset {\n    public :\n        StackedCSVDataset(const std::string &amp;folder_path);\n\n        StackedCSVDataset(const std::string &amp;folder_path, DataMode mode);\n\n        StackedCSVDataset(const std::string &amp;folder_path, DataMode mode, bool load_sub_folders);\n\n        StackedCSVDataset(const std::string &amp;folder_path, DataMode mode, bool load_sub_folders,\n                          vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt; &gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n\n        void load_data();\n    };\n}\n</code></pre>"},{"location":"xTorch/edf-dataset_8h/","title":"File edf-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; edf-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/edf-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/edf-dataset_8h/#classes","title":"Classes","text":"Type Name class EDFDataset class StackedEDFDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/edf-dataset.h</code></p>"},{"location":"xTorch/edf-dataset_8h_source/","title":"File edf-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; edf-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n\n\n\n    class EDFDataset : public BaseDataset {\n    public :\n        EDFDataset(const std::string &amp;file_path);\n        EDFDataset(const std::string &amp;file_path,DataMode mode);\n        EDFDataset(const std::string &amp;file_path,DataMode mode , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n    class StackedEDFDataset : public BaseDataset {\n    public :\n        StackedEDFDataset(const std::string &amp;folder_path);\n        StackedEDFDataset(const std::string &amp;folder_path,DataMode mode);\n        StackedEDFDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders);\n        StackedEDFDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/general_8h/","title":"File general.h","text":"<p>FileList &gt; datasets &gt; general &gt; general.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"audio-dataset.h\"</code></li> <li><code>#include \"csv-dataset.h\"</code></li> <li><code>#include \"edf-dataset.h\"</code></li> <li><code>#include \"image-folder.h\"</code></li> <li><code>#include \"tensor-dataset.h\"</code></li> <li><code>#include \"text-dataset.h\"</code></li> <li><code>#include \"time-series-dataset.h\"</code></li> <li><code>#include \"video-dataset.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/general.h</code></p>"},{"location":"xTorch/general_8h_source/","title":"File general.h","text":"<p>File List &gt; datasets &gt; general &gt; general.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"audio-dataset.h\"\n#include \"csv-dataset.h\"\n#include \"edf-dataset.h\"\n#include \"image-folder.h\"\n#include \"tensor-dataset.h\"\n#include \"text-dataset.h\"\n#include \"time-series-dataset.h\"\n#include \"video-dataset.h\"\n</code></pre>"},{"location":"xTorch/image-folder_8h/","title":"File image-folder.h","text":"<p>FileList &gt; datasets &gt; general &gt; image-folder.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/image-folder_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/image-folder_8h/#classes","title":"Classes","text":"Type Name class ImageFolder <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/image-folder.h</code></p>"},{"location":"xTorch/image-folder_8h_source/","title":"File image-folder.h","text":"<p>File List &gt; datasets &gt; general &gt; image-folder.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    enum class LabelsType {\n        BY_FOLDER = 0,\n        BY_NAME = 1,\n    };\n\n\n    class ImageFolder : public BaseDataset {\n    public :\n\n        ImageFolder(const std::string &amp;root);\n        ImageFolder(const std::string &amp;root,bool load_sub_folders);\n        ImageFolder(const std::string &amp;root,bool load_sub_folders, DataMode mode);\n        ImageFolder(const std::string &amp;root,bool load_sub_folders, DataMode mode , LabelsType label_type);\n        ImageFolder(const std::string &amp;root,bool load_sub_folders, DataMode mode , LabelsType label_type, vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        LabelsType label_type = LabelsType::BY_FOLDER;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n}\n</code></pre>"},{"location":"xTorch/tensor-dataset_8h/","title":"File tensor-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; tensor-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/tensor-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/tensor-dataset_8h/#classes","title":"Classes","text":"Type Name class TensorDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/tensor-dataset.h</code></p>"},{"location":"xTorch/tensor-dataset_8h_source/","title":"File tensor-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; tensor-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n\n\n\n    class TensorDataset : public BaseDataset {\n    public :\n        TensorDataset(const std::string &amp;file_path);\n        TensorDataset(const std::string &amp;file_path,DataMode mode);\n        TensorDataset(const std::string &amp;file_path,DataMode mode , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n\n\n\n}\n</code></pre>"},{"location":"xTorch/text-dataset_8h/","title":"File text-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; text-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/text-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/text-dataset_8h/#classes","title":"Classes","text":"Type Name class StackedTextDataset class TextDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/text-dataset.h</code></p>"},{"location":"xTorch/text-dataset_8h_source/","title":"File text-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; text-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n\n\n\n    class TextDataset : public BaseDataset {\n    public :\n        TextDataset(const std::string &amp;file_path);\n        TextDataset(const std::string &amp;file_path,DataMode mode);\n        TextDataset(const std::string &amp;file_path,DataMode mode , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n    class StackedTextDataset : public BaseDataset {\n    public :\n        StackedTextDataset(const std::string &amp;folder_path);\n        StackedTextDataset(const std::string &amp;folder_path,DataMode mode);\n        StackedTextDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders);\n        StackedTextDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/time-series-dataset_8h/","title":"File time-series-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; time-series-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/time-series-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/time-series-dataset_8h/#classes","title":"Classes","text":"Type Name class StackedTimeSeriesDataset class TimeSeriesDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/time-series-dataset.h</code></p>"},{"location":"xTorch/time-series-dataset_8h_source/","title":"File time-series-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; time-series-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n\n\n\n    class TimeSeriesDataset : public BaseDataset {\n    public :\n        TimeSeriesDataset(const std::string &amp;file_path);\n        TimeSeriesDataset(const std::string &amp;file_path,DataMode mode);\n        TimeSeriesDataset(const std::string &amp;file_path,DataMode mode , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n    class StackedTimeSeriesDataset : public BaseDataset {\n    public :\n        StackedTimeSeriesDataset(const std::string &amp;folder_path);\n        StackedTimeSeriesDataset(const std::string &amp;folder_path,DataMode mode);\n        StackedTimeSeriesDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders);\n        StackedTimeSeriesDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/video-dataset_8h/","title":"File video-dataset.h","text":"<p>FileList &gt; datasets &gt; general &gt; video-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/video-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/video-dataset_8h/#classes","title":"Classes","text":"Type Name class StackedVideoDataset class VideoDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/general/video-dataset.h</code></p>"},{"location":"xTorch/video-dataset_8h_source/","title":"File video-dataset.h","text":"<p>File List &gt; datasets &gt; general &gt; video-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n\n\n\n    class VideoDataset : public BaseDataset {\n    public :\n        VideoDataset(const std::string &amp;file_path);\n        VideoDataset(const std::string &amp;file_path,DataMode mode);\n        VideoDataset(const std::string &amp;file_path,DataMode mode , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n    class StackedVideoDataset : public BaseDataset {\n    public :\n        StackedVideoDataset(const std::string &amp;folder_path);\n        StackedVideoDataset(const std::string &amp;folder_path,DataMode mode);\n        StackedVideoDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders);\n        StackedVideoDataset(const std::string &amp;folder_path,DataMode mode, bool load_sub_folders , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;string&gt; labels_name;\n        bool load_sub_folders = false;\n        void load_data();\n    };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/dir_9d21d6f83a70094db43fe94b096ae893/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/image-classification","text":"<p>FileList &gt; datasets &gt; image-classification</p>"},{"location":"xTorch/dir_9d21d6f83a70094db43fe94b096ae893/#files","title":"Files","text":"Type Name file caltech.h file celeba.h file cifar.h file country.h file dtd.h file euro-sat.h file fake-data.h file fer.h file fgvc-aircraft.h file flickr.h file flowers.h file food.h file gtsrb.h file image-classification.h file imagenet.h file imagenette.h file inaturalist.h file mnist.h file omniglot.h file pcam.h file places.h file rendered-sst2.h file semeion.h file stanford-cars.h file stl.h file sun.h file svhn.h file usps.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/</code></p>"},{"location":"xTorch/caltech_8h/","title":"File caltech.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; caltech.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/caltech_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/caltech_8h/#classes","title":"Classes","text":"Type Name class Caltech101 class Caltech256 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/caltech.h</code></p>"},{"location":"xTorch/caltech_8h_source/","title":"File caltech.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; caltech.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class Caltech101 : public BaseDataset {\n    public :\n        explicit Caltech101(const std::string &amp;root);\n        Caltech101(const std::string &amp;root, DataMode mode);\n        Caltech101(const std::string &amp;root, DataMode mode , bool download);\n        Caltech101(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private:\n        vector&lt;std::tuple&lt;string, string, string&gt; &gt; resources = {\n            {\n                \"https://drive.google.com/file/d/137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp\", \"101_ObjectCategories.tar.gz\",\n                \"b224c7392d521a49829488ab0f1120d9\"\n            },\n            {\n                \"https://drive.google.com/file/d/175kQy3UsZ0wUEHZjqkUDdNVssr7bgh_m\", \"Annotations.tar\",\n                \"6f83eeb1f24d99cab4eb377263132c91\"\n            }\n        };\n        fs::path dataset_folder_name = \"caltech101\";\n        void load_data();\n\n        void check_resources();\n    };\n\n    class Caltech256 : public BaseDataset {\n    public :\n        explicit  Caltech256(const std::string &amp;root);\n        Caltech256(const std::string &amp;root, DataMode mode);\n        Caltech256(const std::string &amp;root, DataMode mode , bool download);\n        Caltech256(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        vector&lt;std::tuple&lt;string, string, string&gt; &gt; resources = {\n            {\n                \"https://drive.google.com/file/d/1r6o0pSROcV1_VwT4oSjA2FBUSCWGuxLK\", \"256_ObjectCategories.tar\",\n                \"67b4f42ca05d46448c6bb8ecd2220f6d\"\n            },\n        };\n        fs::path dataset_folder_name = \"caltech256\";\n\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/celeba_8h/","title":"File celeba.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; celeba.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/celeba_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/celeba_8h/#classes","title":"Classes","text":"Type Name class CelebA <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/celeba.h</code></p>"},{"location":"xTorch/celeba_8h_source/","title":"File celeba.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; celeba.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::data::datasets {\n    class CelebA : public BaseDataset {\n    public :\n        explicit  CelebA(const std::string &amp;root);\n        CelebA(const std::string &amp;root, DataMode mode);\n        CelebA(const std::string &amp;root, DataMode mode , bool download);\n        CelebA(const std::string &amp;root, DataMode mode , bool download, vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private:\n        vector&lt;std::tuple&lt;string, string, fs::path&gt; &gt; resources = {\n            {\"0B7EVK8r0v71pZjFTYXZWM3FlRnM\", \"00d2c5bc6d35e252742224ab0c1e8fcb\", \"img_align_celeba.zip\"},\n            {\"0B7EVK8r0v71pblRyaVFSWGxPY0U\", \"75e246fa4810816ffd6ee81facbd244c\", \"list_attr_celeba.txt\"},\n            {\"1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\", \"32bd1bd63d3c78cd57e08160ec5ed1e2\", \"identity_CelebA.txt\"},\n            {\"0B7EVK8r0v71pbThiMVRxWXZ4dU0\", \"00566efa6fedff7a56946cd1c10f1c16\", \"list_bbox_celeba.txt\"},\n            {\"0B7EVK8r0v71pd0FJY3Blby1HUTQ\", \"cc24ecafdb5b50baae59b03474781f8c\", \"list_landmarks_align_celeba.txt\"},\n            {\"0B7EVK8r0v71pY0NSMzRuSXJEVkk\", \"d32c9cbf5e040fd4025c592c306e6668\", \"list_eval_partition.txt\"}\n        };\n\n        fs::path dataset_folder_name = \"celeba\";\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/cifar_8h/","title":"File cifar.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; cifar.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/cifar_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/cifar_8h/#classes","title":"Classes","text":"Type Name class CIFAR10 class CIFAR100 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/cifar.h</code></p>"},{"location":"xTorch/cifar_8h_source/","title":"File cifar.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; cifar.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class CIFAR10 : public BaseDataset {\n    public:\n        explicit  CIFAR10(const std::string &amp;root);\n        CIFAR10(const std::string &amp;root, DataMode mode);\n        CIFAR10(const std::string &amp;root, DataMode mode , bool download);\n        CIFAR10(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n        torch::data::Example&lt;&gt; get(size_t index) override;\n\n        torch::optional&lt;size_t&gt; size() const override;\n\n    private:\n        // std::vector&lt;torch::Tensor&gt; data; // Store image data as tensors\n        // std::vector&lt;int64_t&gt; labels; // Store labels\n        std::string url = \"https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\";\n        fs::path archive_file_name = \"cifar-10-binary.tar.gz\";\n        std::string archive_file_md5 = \"c32a1d4ab5d03f1284b67883e8d87530\";\n        // fs::path root;\n        // fs::path dataset_path;\n        fs::path dataset_folder_name = \"cifar-10-batches-bin\";\n        vector&lt;fs::path&gt; train_file_names = {\n            fs::path(\"data_batch_1.bin\"),\n            fs::path(\"data_batch_2.bin\"),\n            fs::path(\"data_batch_3.bin\"),\n            fs::path(\"data_batch_4.bin\"),\n            fs::path(\"data_batch_5.bin\")\n        };\n        fs::path test_file_name = \"test_batch.bin\";\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n    };\n\n\n    class CIFAR100 : public BaseDataset {\n    public:\n        explicit  CIFAR100(const std::string &amp;root);\n        CIFAR100(const std::string &amp;root, DataMode mode);\n        CIFAR100(const std::string &amp;root, DataMode mode , bool download);\n        CIFAR100(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        torch::data::Example&lt;&gt; get(size_t index) override;\n\n        torch::optional&lt;size_t&gt; size() const override;\n\n    private:\n        // std::vector&lt;torch::Tensor&gt; data; // Store image data as tensors\n        // std::vector&lt;int64_t&gt; labels; // Store labels\n        std::string url = \"https://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz\";\n        fs::path archive_file_name = \"cifar-100-binary.tar.gz\";\n        std::string archive_file_md5 = \"03b5dce01913d631647c71ecec9e9cb8\";\n        // fs::path root;\n        // fs::path dataset_path;\n        fs::path dataset_folder_name = \"cifar-100-binary\";\n        fs::path train_file_name = \"train.bin\";\n        fs::path test_file_name = \"test.bin\";\n\n        void load_data( DataMode mode = DataMode::TRAIN);\n    };\n}\n</code></pre>"},{"location":"xTorch/country_8h/","title":"File country.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; country.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/country_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/country_8h/#classes","title":"Classes","text":"Type Name class Country211 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/country.h</code></p>"},{"location":"xTorch/country_8h_source/","title":"File country.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; country.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::data::datasets {\n    class Country211 : public BaseDataset {\n    public:\n        explicit  Country211(const std::string &amp;root);\n        Country211(const std::string &amp;root, DataMode mode);\n        Country211(const std::string &amp;root, DataMode mode , bool download);\n        Country211(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        std::string url = \"https://openaipublic.azureedge.net/clip/data/\";\n        fs::path dataset_file_name = \"country211.tgz\";\n        std::string dataset_file_md5 = \"84988d7644798601126c29e9877aab6a\";\n        fs::path dataset_folder_name = \"country211\";\n\n    };\n}\n</code></pre>"},{"location":"xTorch/dtd_8h/","title":"File dtd.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; dtd.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/dtd_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/dtd_8h/#classes","title":"Classes","text":"Type Name class DTD <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/dtd.h</code></p>"},{"location":"xTorch/dtd_8h_source/","title":"File dtd.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; dtd.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class DTD : public BaseDataset {\n    public :\n        explicit  DTD(const std::string &amp;root);\n        DTD(const std::string &amp;root, DataMode mode);\n        DTD(const std::string &amp;root, DataMode mode , bool download);\n        DTD(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/euro-sat_8h/","title":"File euro-sat.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; euro-sat.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/euro-sat_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/euro-sat_8h/#classes","title":"Classes","text":"Type Name class EuroSAT <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/euro-sat.h</code></p>"},{"location":"xTorch/euro-sat_8h_source/","title":"File euro-sat.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; euro-sat.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class EuroSAT :public BaseDataset {\n    public :\n        explicit EuroSAT(const std::string &amp;root);\n        EuroSAT(const std::string &amp;root, DataMode mode);\n        EuroSAT(const std::string &amp;root, DataMode mode , bool download);\n        EuroSAT(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        std::string url =\n                \"https://huggingface.co/datasets/torchgeo/eurosat/resolve/c877bcd43f099cd0196738f714544e355477f3fd/EuroSAT.zip\";\n        fs::path archive_file_name = \"EuroSAT.zip\";\n        std::string archive_file_md5 = \"c8fa014336c82ac7804f0398fcb19387\";\n        fs::path dataset_folder_name = \"euro-sat\";\n\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/fake-data_8h/","title":"File fake-data.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; fake-data.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/fake-data_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/fake-data_8h/#classes","title":"Classes","text":"Type Name class FakeData <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/fake-data.h</code></p>"},{"location":"xTorch/fake-data_8h_source/","title":"File fake-data.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; fake-data.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class FakeData : public BaseDataset {\n    public :\n        FakeData();\n\n        FakeData(size_t size);\n\n        FakeData( size_t size, vector&lt;int64_t&gt; shape);\n\n        FakeData( size_t size, vector&lt;int64_t&gt; shape, TransformType transforms);\n\n    private :\n        size_t size_;\n        vector&lt;int64_t&gt; shape_ = {3, 24, 24};\n\n        void generate_data();\n    };\n}\n</code></pre>"},{"location":"xTorch/fer_8h/","title":"File fer.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; fer.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/fer_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/fer_8h/#classes","title":"Classes","text":"Type Name class FER2013 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/fer.h</code></p>"},{"location":"xTorch/fer_8h_source/","title":"File fer.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; fer.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class FER2013 : public BaseDataset {\n        /*\n            `FER2013\n            &lt;https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge&gt;`_ Dataset.\n\n            .. note::\n                This dataset can return test labels only if ``fer2013.csv`` OR\n                ``icml_face_data.csv`` are present in ``root/fer2013/``. If only\n                ``train.csv`` and ``test.csv`` are present, the test labels are set to\n                ``None``.\n\n            Args:\n                root (str or ``pathlib.Path``): Root directory of dataset where directory\n                    ``root/fer2013`` exists. This directory may contain either\n                    ``fer2013.csv``, ``icml_face_data.csv``, or both ``train.csv`` and\n                    ``test.csv``. Precendence is given in that order, i.e. if\n                    ``fer2013.csv`` is present then the rest of the files will be\n                    ignored. All these (combinations of) files contain the same data and\n                    are supported for convenience, but only ``fer2013.csv`` and\n                    ``icml_face_data.csv`` are able to return non-None test labels.\n                split (string, optional): The dataset split, supports ``\"train\"`` (default), or ``\"test\"``.\n                transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n                    version. E.g, ``transforms.RandomCrop``\n                target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n        */\n    public :\n        explicit  FER2013(const std::string &amp;root);\n        FER2013(const std::string &amp;root, DataMode mode);\n        FER2013(const std::string &amp;root, DataMode mode , bool download);\n        FER2013(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n\n        // resources = {\n        //     \"train\": (\"train.csv\", \"3f0dfb3d3fd99c811a1299cb947e3131\"),\n        //     \"test\": (\"test.csv\", \"b02c2298636a634e8c2faabbf3ea9a23\"),\n        //     \"fer\": (\"fer2013.csv\", \"f8428a1edbd21e88f42c73edd2a14f95\"),\n        //     \"icml\": (\"icml_face_data.csv\", \"b114b9e04e6949e5fe8b6a98b3892b1d\"),\n        // }\n\n    };\n}\n</code></pre>"},{"location":"xTorch/fgvc-aircraft_8h/","title":"File fgvc-aircraft.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; fgvc-aircraft.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/fgvc-aircraft_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/fgvc-aircraft_8h/#classes","title":"Classes","text":"Type Name class FGVCAircraft <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/fgvc-aircraft.h</code></p>"},{"location":"xTorch/fgvc-aircraft_8h_source/","title":"File fgvc-aircraft.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; fgvc-aircraft.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class FGVCAircraft :public BaseDataset {\n    public :\n        explicit FGVCAircraft(const std::string &amp;root);\n        FGVCAircraft(const std::string &amp;root, DataMode mode);\n        FGVCAircraft(const std::string &amp;root, DataMode mode , bool download);\n        FGVCAircraft(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        fs::path url = \"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\";\n        std::string dataset_file_md5 = \"85eeb15f3717b99a5da872d97d918f87\";\n        std::string dataset_file_name = \"fgvc-aircraft-2013b.tar.gz\";\n        fs::path dataset_folder_name = \"fgvc-aircraft-2013b\";\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n}\n</code></pre>"},{"location":"xTorch/flickr_8h/","title":"File flickr.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; flickr.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/flickr_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/flickr_8h/#classes","title":"Classes","text":"Type Name class Flickr30k class Flickr8k <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/flickr.h</code></p>"},{"location":"xTorch/flickr_8h_source/","title":"File flickr.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; flickr.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    [[deprecated(\"Flickr8k Dataset some files removed and Links are broken\")]]\n    class Flickr8k :public BaseDataset {\n    public :\n        Flickr8k(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n\n        Flickr8k(const fs::path &amp;root, DatasetArguments args);\n\n    private :\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n\n    [[deprecated(\"Flickr30k Dataset some files removed and Links are broken\")]]\n    class Flickr30k :public BaseDataset {\n    public :\n        Flickr30k(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n\n        Flickr30k(const fs::path &amp;root, DatasetArguments args);\n\n    private :\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n}\n</code></pre>"},{"location":"xTorch/flowers_8h/","title":"File flowers.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; flowers.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/flowers_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/flowers_8h/#classes","title":"Classes","text":"Type Name class Flowers102 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/flowers.h</code></p>"},{"location":"xTorch/flowers_8h_source/","title":"File flowers.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; flowers.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Flowers102 : public BaseDataset {\n    public :\n        explicit Flowers102(const std::string &amp;root);\n        Flowers102(const std::string &amp;root, DataMode mode);\n        Flowers102(const std::string &amp;root, DataMode mode , bool download);\n        Flowers102(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n\n        // _download_url_prefix = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/\"\n        // _file_dict = {  # filename, md5\n        // \"image\": (\"102flowers.tgz\", \"52808999861908f626f3c1f4e79d11fa\"),\n        // \"label\": (\"imagelabels.mat\", \"e0620be6f572b9609742df49c70aed4d\"),\n        // \"setid\": (\"setid.mat\", \"a5357ecc9cb78c4bef273ce3793fc85c\"),\n        // }\n        // _splits_map = {\"train\": \"trnid\", \"val\": \"valid\", \"test\": \"tstid\"}\n\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/food_8h/","title":"File food.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; food.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> <li><code>#include \"../../utils/filesystem.h\"</code></li> <li><code>#include \"../../utils/string.h\"</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;map&gt;</code></li> </ul>"},{"location":"xTorch/food_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/food_8h/#classes","title":"Classes","text":"Type Name class Food101 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/food.h</code></p>"},{"location":"xTorch/food_8h_source/","title":"File food.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; food.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n#include  \"../../utils/filesystem.h\"\n#include  \"../../utils/string.h\"\n#include &lt;fstream&gt;\n#include &lt;map&gt;\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::data::datasets {\n    class Food101 : public BaseDataset {\n    public :\n\n        explicit Food101(const std::string &amp;root);\n        Food101(const std::string &amp;root, DataMode mode);\n        Food101(const std::string &amp;root, DataMode mode , bool download);\n        Food101(const std::string &amp;root, DataMode mode , bool download, vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n\n    private :\n        std::string url = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\";\n        fs::path dataset_file_name = \"food-101.tar.gz\";\n        std::string dataset_file_md5 = \"85eeb15f3717b99a5da872d97d918f87\";\n        fs::path dataset_folder_name = \"food-101\";\n        std::size_t images_number = 101'000;\n        std::vector&lt;string&gt; classes_name;\n        std::map&lt;string, int&gt; classes_map;\n\n        void load_data();\n\n        void load_classes();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/gtsrb_8h/","title":"File gtsrb.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; gtsrb.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/gtsrb_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/gtsrb_8h/#classes","title":"Classes","text":"Type Name class GTSRB <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/gtsrb.h</code></p>"},{"location":"xTorch/gtsrb_8h_source/","title":"File gtsrb.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; gtsrb.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class GTSRB : BaseDataset {\n        /*\n        \"\"\"`German Traffic Sign Recognition Benchmark (GTSRB) &lt;https://benchmark.ini.rub.de/&gt;`_ Dataset.\n\n        Args:\n            root (str or ``pathlib.Path``): Root directory of the dataset.\n            split (string, optional): The dataset split, supports ``\"train\"`` (default), or ``\"test\"``.\n            transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n                version. E.g, ``transforms.RandomCrop``.\n            target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n            download (bool, optional): If True, downloads the dataset from the internet and\n                puts it in root directory. If dataset is already downloaded, it is not\n                downloaded again.\n        \"\"\"\n         */\n    public :\n        explicit GTSRB(const std::string &amp;root);\n        GTSRB(const std::string &amp;root, DataMode mode);\n        GTSRB(const std::string &amp;root, DataMode mode , bool download);\n        GTSRB(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        // base_url = \"https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/\"\n        //\n        // if self._split == \"train\":\n        //     download_and_extract_archive(\n        //         f\"{base_url}GTSRB-Training_fixed.zip\",\n        //         download_root=str(self._base_folder),\n        //         md5=\"513f3c79a4c5141765e10e952eaa2478\",\n        //     )\n        // else:\n        //     download_and_extract_archive(\n        //         f\"{base_url}GTSRB_Final_Test_Images.zip\",\n        //         download_root=str(self._base_folder),\n        //         md5=\"c7e4e6327067d32654124b0fe9e82185\",\n        //     )\n        //     download_and_extract_archive(\n        //         f\"{base_url}GTSRB_Final_Test_GT.zip\",\n        //         download_root=str(self._base_folder),\n        //         md5=\"fe31e9c9270bbcd7b84b7f21a9d9d9e5\",\n        //     )\n\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/image-classification_8h/","title":"File image-classification.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; image-classification.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"caltech.h\"</code></li> <li><code>#include \"celeba.h\"</code></li> <li><code>#include \"cifar.h\"</code></li> <li><code>#include \"country.h\"</code></li> <li><code>#include \"dtd.h\"</code></li> <li><code>#include \"euro-sat.h\"</code></li> <li><code>#include \"fake-data.h\"</code></li> <li><code>#include \"fer.h\"</code></li> <li><code>#include \"fgvc-aircraft.h\"</code></li> <li><code>#include \"flickr.h\"</code></li> <li><code>#include \"flowers.h\"</code></li> <li><code>#include \"food.h\"</code></li> <li><code>#include \"gtsrb.h\"</code></li> <li><code>#include \"imagenet.h\"</code></li> <li><code>#include \"imagenette.h\"</code></li> <li><code>#include \"inaturalist.h\"</code></li> <li><code>#include \"mnist.h\"</code></li> <li><code>#include \"omniglot.h\"</code></li> <li><code>#include \"pcam.h\"</code></li> <li><code>#include \"places.h\"</code></li> <li><code>#include \"rendered-sst2.h\"</code></li> <li><code>#include \"semeion.h\"</code></li> <li><code>#include \"stanford-cars.h\"</code></li> <li><code>#include \"stl.h\"</code></li> <li><code>#include \"sun.h\"</code></li> <li><code>#include \"svhn.h\"</code></li> <li><code>#include \"usps.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/image-classification.h</code></p>"},{"location":"xTorch/image-classification_8h_source/","title":"File image-classification.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; image-classification.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"caltech.h\"\n#include \"celeba.h\"\n#include \"cifar.h\"\n#include \"country.h\"\n#include \"dtd.h\"\n#include \"euro-sat.h\"\n#include \"fake-data.h\"\n#include \"fer.h\"\n#include \"fgvc-aircraft.h\"\n#include \"flickr.h\"\n#include \"flowers.h\"\n#include \"food.h\"\n#include \"gtsrb.h\"\n#include \"imagenet.h\"\n#include \"imagenette.h\"\n#include \"inaturalist.h\"\n#include \"mnist.h\"\n#include \"omniglot.h\"\n#include \"pcam.h\"\n#include \"places.h\"\n#include \"rendered-sst2.h\"\n#include \"semeion.h\"\n#include \"stanford-cars.h\"\n#include \"stl.h\"\n#include \"sun.h\"\n#include \"svhn.h\"\n#include \"usps.h\"\n</code></pre>"},{"location":"xTorch/imagenet_8h/","title":"File imagenet.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; imagenet.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/imagenet_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/imagenet_8h/#classes","title":"Classes","text":"Type Name class ImageNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/imagenet.h</code></p>"},{"location":"xTorch/imagenet_8h_source/","title":"File imagenet.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; imagenet.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class ImageNet : BaseDataset {\n    public :\n        explicit  ImageNet(const std::string &amp;root);\n        ImageNet(const std::string &amp;root, DataMode mode);\n        ImageNet(const std::string &amp;root, DataMode mode , bool download);\n        ImageNet(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/imagenette_8h/","title":"File imagenette.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; imagenette.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/imagenette_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/imagenette_8h/#classes","title":"Classes","text":"Type Name class Imagenette <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/imagenette.h</code></p>"},{"location":"xTorch/imagenette_8h_source/","title":"File imagenette.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; imagenette.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::data::datasets {\n    enum class ImageType {\n        FULL = 0,\n        PX320 = 1,\n        PX160 = 2\n    };\n\n    const std::unordered_map&lt;ImageType, std::string&gt; ImageTypeToString = {\n        {ImageType::FULL, \"full\"},\n        {ImageType::PX320, \"320px\"},\n        {ImageType::PX160, \"160px\"}\n    };\n\n    inline std::string getImageTypeValue(ImageType type) {\n        auto it = ImageTypeToString.find(type);\n        if (it != ImageTypeToString.end()) {\n            return it-&gt;second;\n        }\n        return \"unknown\"; // Default value if enum not found\n    }\n\n    class Imagenette : public BaseDataset {\n    public :\n        explicit  Imagenette(const std::string &amp;root);\n        Imagenette(const std::string &amp;root, DataMode mode);\n        Imagenette(const std::string &amp;root, DataMode mode , bool download);\n        Imagenette(const std::string &amp;root, DataMode mode , bool download, ImageType type );\n        Imagenette(const std::string &amp;root, DataMode mode , bool download, ImageType type , TransformType transforms);\n\n    private:\n        std::map&lt;string, std::tuple&lt;fs::path, fs::path, fs::path, std::string&gt; &gt; resources = {\n            {\n                \"full\", {\n                    fs::path(\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\"),\n                    fs::path(\"imagenette2.tgz\"),\n                    fs::path(\"imagenette2\"),\n                    \"fe2fc210e6bb7c5664d602c3cd71e612\"\n                }\n            },\n            {\n                \"320px\", {\n                    fs::path(\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\"),\n                    fs::path(\"imagenette2-320.tgz\"),\n                    fs::path(\"imagenette2-320\"),\n                    \"3df6f0d01a2c9592104656642f5e78a3\"\n                }\n            },\n            {\n                \"160px\", {\n                    fs::path(\"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\"),\n                    fs::path(\"imagenette2-160.tgz\"),\n                    fs::path(\"imagenette2-160\"),\n                    \"e793b78cc4c9e9a4ccc0c1155377a412\"\n                }\n            }\n        };\n        ImageType type = ImageType::PX160;\n        fs::path dataset_folder_name = \"imagenette\";\n        vector&lt;string&gt; labels_name;\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n}\n</code></pre>"},{"location":"xTorch/inaturalist_8h/","title":"File inaturalist.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; inaturalist.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/inaturalist_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/inaturalist_8h/#classes","title":"Classes","text":"Type Name class INaturalist <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/inaturalist.h</code></p>"},{"location":"xTorch/inaturalist_8h_source/","title":"File inaturalist.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; inaturalist.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::data::datasets {\n    class INaturalist : BaseDataset {\n        /*\n        \"\"\"`iNaturalist &lt;https://github.com/visipedia/inat_comp&gt;`_ Dataset.\n        Args:\n            root (str or ``pathlib.Path``): Root directory of dataset where the image files are stored.\n                This class does not require/use annotation files.\n            version (string, optional): Which version of the dataset to download/use. One of\n                '2017', '2018', '2019', '2021_train', '2021_train_mini', '2021_valid'.\n                Default: `2021_train`.\n            target_type (string or list, optional): Type of target to use, for 2021 versions, one of:\n\n                - ``full``: the full category (species)\n                - ``kingdom``: e.g. \"Animalia\"\n                - ``phylum``: e.g. \"Arthropoda\"\n                - ``class``: e.g. \"Insecta\"\n                - ``order``: e.g. \"Coleoptera\"\n                - ``family``: e.g. \"Cleridae\"\n                - ``genus``: e.g. \"Trichodes\"\n\n                for 2017-2019 versions, one of:\n\n                - ``full``: the full (numeric) category\n                - ``super``: the super category, e.g. \"Amphibians\"\n\n                Can also be a list to output a tuple with all specified target types.\n                Defaults to ``full``.\n            transform (callable, optional): A function/transform that takes in a PIL image\n                and returns a transformed version. E.g, ``transforms.RandomCrop``\n            target_transform (callable, optional): A function/transform that takes in the\n                target and transforms it.\n            download (bool, optional): If true, downloads the dataset from the internet and\n                puts it in root directory. If dataset is already downloaded, it is not\n                downloaded again.\n        \"\"\"\n         */\n    public :\n        explicit  INaturalist(const std::string &amp;root);\n        INaturalist(const std::string &amp;root, DataMode mode);\n        INaturalist(const std::string &amp;root, DataMode mode , bool download);\n        INaturalist(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private:\n        std::map&lt;string, std::tuple&lt;fs::path, std::string&gt; &gt; resources = {\n            {\n                \"2017\", {\n                    fs::path(\n                        \"https://ml-inat-competition-datasets.s3.amazonaws.com/2017/train_val_images.tar.gz\"),\n                    \"7c784ea5e424efaec655bd392f87301f\"\n                }\n            },\n            {\n                \"2018\", {\n                    fs::path(\n                        \"https://ml-inat-competition-datasets.s3.amazonaws.com/2018/train_val2018.tar.gz\"),\n                    \"b1c6952ce38f31868cc50ea72d066cc3\"\n                }\n            },\n            {\n                \"2019\", {\n                    fs::path(\n                        \"https://ml-inat-competition-datasets.s3.amazonaws.com/2019/train_val2019.tar.gz\"),\n                    \"c60a6e2962c9b8ccbd458d12c8582644\"\n                }\n            },\n            {\n                \"2021_train\", {\n                    fs::path(\n                        \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train.tar.gz\"),\n                    \"e0526d53c7f7b2e3167b2b43bb2690ed\"\n                }\n            },\n            {\n                \"2021_train_mini\", {\n                    fs::path(\n                        \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/train_mini.tar.gz\"),\n                    \"db6ed8330e634445efc8fec83ae81442\"\n                }\n            },\n            {\n                \"2021_valid\", {\n                    fs::path(\n                        \"https://ml-inat-competition-datasets.s3.amazonaws.com/2021/val.tar.gz\"),\n                    \"f6f6e0e242e3d4c9569ba56400938afc\"\n                }\n            }\n        };\n\n        fs::path dataset_folder_name = \"inaturalist\";\n\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/mnist_8h/","title":"File mnist.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; mnist.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/mnist_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/mnist_8h/#classes","title":"Classes","text":"Type Name class EMNIST class FashionMNIST class KMNIST class MNIST class MNISTBase class QMNIST <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/mnist.h</code></p>"},{"location":"xTorch/mnist_8h_source/","title":"File mnist.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; mnist.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n\n    class MNISTBase : public BaseDataset {\n    public:\n        explicit MNISTBase(const std::string &amp;root);\n        MNISTBase(const std::string &amp;root, DataMode mode);\n        MNISTBase(const std::string &amp;root, DataMode mode , bool download);\n        MNISTBase(const std::string &amp;root, DataMode mode , bool download , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n        // ~MNISTBase() override;\n\n        void read_images(const std::string &amp;file_path, int num_images);\n\n        void read_labels(const std::string &amp;file_path, int num_labels);\n\n        // torch::data::Example&lt;&gt; get(size_t index) override;\n\n        // torch::optional&lt;size_t&gt; size() const override;\n\n    protected:\n        // std::vector&lt;torch::Tensor&gt; data; // Store image data as tensors\n        // std::vector&lt;uint8_t&gt; labels; // Store labels\n        // DataMode mode = DataMode::TRAIN;\n        // bool download = false;\n        // fs::path root;\n        // fs::path dataset_path;\n        // xt::data::transforms::Compose compose;\n\n\n        // void transform_data(std::vector&lt;torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; &gt; transforms);\n\n    private:\n        // vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms = {};\n    };\n\n\n    class MNIST : public MNISTBase {\n    public :\n        explicit MNIST(const std::string &amp;root);\n        MNIST(const std::string &amp;root, DataMode mode);\n        MNIST(const std::string &amp;root, DataMode mode , bool download);\n        MNIST(const std::string &amp;root, DataMode mode , bool download , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n        // // MNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n        // MNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false , std::shared_ptr&lt;xt::data::transforms::Compose&gt; compose= nullptr);\n        // MNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false, vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms= {});\n\n        MNIST(const fs::path &amp;root, DatasetArguments args);\n\n    private :\n        std::string url = \"https://ossci-datasets.s3.amazonaws.com/mnist/\";\n        fs::path dataset_folder_name = \"MNIST/raw\";\n\n        vector&lt;tuple&lt;fs::path, std::string&gt; &gt; resources = {\n            {fs::path(\"train-images-idx3-ubyte.gz\"), \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"},\n            {fs::path(\"train-labels-idx1-ubyte.gz\"), \"d53e105ee54ea40749a09fcbcd1e9432\"},\n            {fs::path(\"t10k-images-idx3-ubyte.gz\"), \"9fb629c4189551a2d022fa330f9573f3\"},\n            {fs::path(\"t10k-labels-idx1-ubyte.gz\"), \"ec29112dd5afa0611ce80d1b7f02629c\"},\n        };\n\n        std::map&lt;std::string, std::tuple&lt;fs::path, fs::path&gt; &gt; files = {\n            {\"train\", {fs::path(\"train-images-idx3-ubyte\"), fs::path(\"train-labels-idx1-ubyte\")}},\n            {\"test\", {fs::path(\"t10k-images-idx3-ubyte\"), fs::path(\"t10k-labels-idx1-ubyte\")}}\n        };\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n        void transform_data();\n    };\n\n\n    class FashionMNIST : public MNISTBase {\n    public:\n\n        explicit FashionMNIST(const std::string &amp;root);\n        FashionMNIST(const std::string &amp;root, DataMode mode);\n        FashionMNIST(const std::string &amp;root, DataMode mode , bool download);\n        FashionMNIST(const std::string &amp;root, DataMode mode , bool download , vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n\n        // FashionMNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n        //\n        // FashionMNIST(const fs::path &amp;root, DatasetArguments args);\n\n    private:\n        std::string url = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\";\n        fs::path dataset_folder_name = \"FashionMNIST/raw\";\n\n        vector&lt;tuple&lt;fs::path, std::string&gt; &gt; resources = {\n            {fs::path(\"train-images-idx3-ubyte.gz\"), \"8d4fb7e6c68d591d4c3dfef9ec88bf0d\"},\n            {fs::path(\"train-labels-idx1-ubyte.gz\"), \"25c81989df183df01b3e8a0aad5dffbe\"},\n            {fs::path(\"t10k-images-idx3-ubyte.gz\"), \"bef4ecab320f06d8554ea6380940ec79\"},\n            {fs::path(\"t10k-labels-idx1-ubyte.gz\"), \"bb300cfdad3c16e7a12a480ee83cd310\"},\n        };\n\n        std::map&lt;std::string, std::tuple&lt;fs::path, fs::path&gt; &gt; files = {\n            {\"train\", {fs::path(\"train-images-idx3-ubyte\"), fs::path(\"train-labels-idx1-ubyte\")}},\n            {\"test\", {fs::path(\"t10k-images-idx3-ubyte\"), fs::path(\"t10k-labels-idx1-ubyte\")}}\n        };\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n\n\n    class KMNIST : public MNISTBase {\n    public :\n        KMNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n\n        KMNIST(const fs::path &amp;root, DatasetArguments args);\n\n    private:\n        std::string url = \"http://codh.rois.ac.jp/kmnist/dataset/kmnist/\";\n        fs::path dataset_folder_name = \"KMNIST/raw\";\n\n        vector&lt;tuple&lt;fs::path, std::string&gt; &gt; resources = {\n            {fs::path(\"train-images-idx3-ubyte.gz\"), \"bdb82020997e1d708af4cf47b453dcf7\"},\n            {fs::path(\"train-labels-idx1-ubyte.gz\"), \"e144d726b3acfaa3e44228e80efcd344\"},\n            {fs::path(\"t10k-images-idx3-ubyte.gz\"), \"5c965bf0a639b31b8f53240b1b52f4d7\"},\n            {fs::path(\"t10k-labels-idx1-ubyte.gz\"), \"7320c461ea6c1c855c0b718fb2a4b134\"},\n        };\n\n        std::map&lt;std::string, std::tuple&lt;fs::path, fs::path&gt; &gt; files = {\n            {\"train\", {fs::path(\"train-images-idx3-ubyte\"), fs::path(\"train-labels-idx1-ubyte\")}},\n            {\"test\", {fs::path(\"t10k-images-idx3-ubyte\"), fs::path(\"t10k-labels-idx1-ubyte\")}}\n        };\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n\n    class EMNIST : public MNISTBase {\n    public :\n        EMNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n\n        EMNIST(const fs::path &amp;root, DatasetArguments args);\n\n    private:\n        std::string url = \"https://biometrics.nist.gov/cs_links/EMNIST/\";\n        fs::path dataset_folder_name = \"EMNIST/raw\";\n        fs::path archive_file_name = \"gzip.zip\";\n        std::string archive_file_md5 = \"58c8d27c78d21e728a6bc7b3cc06412e\";\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n\n    class QMNIST : public MNISTBase {\n    public :\n        QMNIST(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n        QMNIST(const fs::path &amp;root, DatasetArguments args);\n\n    private:\n        std::string url = \"https://raw.githubusercontent.com/facebookresearch/qmnist/master/\";\n        fs::path dataset_path;\n        fs::path dataset_folder_name = \"QMNIST/raw\";\n        std::string archive_file_md5 = \"58c8d27c78d21e728a6bc7b3cc06412e\";\n        std::map&lt;string, std::vector&lt;std::tuple&lt;fs::path, std::string&gt; &gt; &gt; resources = {\n            {\n                \"train\", {\n                    {fs::path(\"qmnist-train-images-idx3-ubyte.gz\"), \"ed72d4157d28c017586c42bc6afe6370\"},\n                    {fs::path(\"qmnist-train-labels-idx2-int.gz\"), \"0058f8dd561b90ffdd0f734c6a30e5e4\"}\n                }\n            },\n            {\n                \"test\", {\n                    {fs::path(\"qmnist-test-images-idx3-ubyte.gz\"), \"1394631089c404de565df7b7aeaf9412\"},\n                    {fs::path(\"qmnist-test-labels-idx2-int.gz\"), \"5b5b05890a5e13444e108efe57b788aa\"}\n                }\n            },\n            {\n                \"nist\", {\n                    {fs::path(\"xnist-images-idx3-ubyte.xz\"), \"7f124b3b8ab81486c9d8c2749c17f834\"},\n                    {fs::path(\"xnist-labels-idx2-int.xz\"), \"5ed0e788978e45d4a8bd4b7caec3d79d\"}\n                }\n            }\n        };\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n\n    };\n}\n</code></pre>"},{"location":"xTorch/omniglot_8h/","title":"File omniglot.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; omniglot.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/omniglot_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/omniglot_8h/#classes","title":"Classes","text":"Type Name class Omniglot <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/omniglot.h</code></p>"},{"location":"xTorch/omniglot_8h_source/","title":"File omniglot.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; omniglot.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Omniglot : BaseDataset {\n        /*\n        https://github.com/brendenlake/omniglot\n        \"\"\"`Omniglot &lt;https://github.com/brendenlake/omniglot&gt;`_ Dataset.\n        Args:\n            root (str or ``pathlib.Path``): Root directory of dataset where directory\n                ``omniglot-py`` exists.\n            background (bool, optional): If True, creates dataset from the \"background\" set, otherwise\n                creates from the \"evaluation\" set. This terminology is defined by the authors.\n            transform (callable, optional): A function/transform that takes in a PIL image\n                and returns a transformed version. E.g, ``transforms.RandomCrop``\n            target_transform (callable, optional): A function/transform that takes in the\n                target and transforms it.\n            download (bool, optional): If true, downloads the dataset zip files from the internet and\n                puts it in root directory. If the zip files are already downloaded, they are not\n                downloaded again.\n        \"\"\"\n         */\n    public :\n        explicit Omniglot(const std::string &amp;root);\n        Omniglot(const std::string &amp;root, DataMode mode);\n        Omniglot(const std::string &amp;root, DataMode mode , bool download);\n        Omniglot(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        // folder = \"omniglot-py\"\n        // download_url_prefix = \"https://raw.githubusercontent.com/brendenlake/omniglot/master/python\"\n        // zips_md5 = {\n        // \"images_background\": \"68d2efa1b9178cc56df9314c21c6e718\",\n        // \"images_evaluation\": \"6b91aef0f799c5bb55b94e3f2daec811\",\n        // }\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n}\n</code></pre>"},{"location":"xTorch/pcam_8h/","title":"File pcam.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; pcam.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/pcam_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/pcam_8h/#classes","title":"Classes","text":"Type Name class PCAM <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/pcam.h</code></p>"},{"location":"xTorch/pcam_8h_source/","title":"File pcam.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; pcam.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\n\nnamespace xt::data::datasets {\n    class PCAM : BaseDataset {\n        /*\n        \"\"\"`PCAM Dataset   &lt;https://github.com/basveeling/pcam&gt;`_.\n\n    The PatchCamelyon dataset is a binary classification dataset with 327,680\n    color images (96px x 96px), extracted from histopathologic scans of lymph node\n    sections. Each image is annotated with a binary label indicating presence of\n    metastatic tissue.\n\n    This dataset requires the ``h5py`` package which you can install with ``pip install h5py``.\n\n    Args:\n         root (str or ``pathlib.Path``): Root directory of the dataset.\n         split (string, optional): The dataset split, supports ``\"train\"`` (default), ``\"test\"`` or ``\"val\"``.\n         transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n             version. E.g, ``transforms.RandomCrop``.\n         target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n         download (bool, optional): If True, downloads the dataset from the internet and puts it into ``root/pcam``. If\n             dataset is already downloaded, it is not downloaded again.\n\n             .. warning::\n\n                To download the dataset `gdown &lt;https://github.com/wkentaro/gdown&gt;`_ is required.\n    \"\"\"\n\n         */\n    public :\n        explicit PCAM(const std::string &amp;root);\n        PCAM(const std::string &amp;root, DataMode mode);\n        PCAM(const std::string &amp;root, DataMode mode , bool download);\n        PCAM(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        std::tuple&lt;fs::path, std::string, std::string&gt;  t = {fs::path(\"camelyonpatch_level_2_split_train_x.h5\"),\"1Ka0XfEMiwgCYPdTI-vv6eUElOBnKFKQ2\",\"1571f514728f59376b705fc836ff4b63\"};\n        std::map&lt;std::string, std::map&lt;std::string, std::tuple&lt;fs::path, std::string, std::string&gt; &gt;&gt; resources = {\n                {\"train\",{\n                    {\"images\", {fs::path(\"camelyonpatch_level_2_split_train_x.h5\"),\"1Ka0XfEMiwgCYPdTI-vv6eUElOBnKFKQ2\",\"1571f514728f59376b705fc836ff4b63\"} },\n                    {\"targets\", {fs::path(\"camelyonpatch_level_2_split_train_y.h5\"),\"1269yhu3pZDP8UYFQs-NYs3FPwuK-nGSG\",\"35c2d7259d906cfc8143347bb8e05be7\"} },\n                }},\n                {\"test\",{\n                    {\"images\", {fs::path(\"camelyonpatch_level_2_split_test_x.h5\"),\"1qV65ZqZvWzuIVthK8eVDhIwrbnsJdbg_\",\"d8c2d60d490dbd479f8199bdfa0cf6ec\"} },\n                    {\"targets\", {fs::path(\"camelyonpatch_level_2_split_test_y.h5\"),\"17BHrSrwWKjYsOgTMmoqrIjDy6Fa2o_gP\",\"60a7035772fbdb7f34eb86d4420cf66a\"} },\n                }},\n                {\"val\",{\n                    {\"images\", {fs::path(\"camelyonpatch_level_2_split_valid_x.h5\"),\"1hgshYGWK8V-eGRy8LToWJJgDU_rXWVJ3\",\"d5b63470df7cfa627aeec8b9dc0c066e\"} },\n                    {\"targets\", {fs::path(\"camelyonpatch_level_2_split_valid_y.h5\"),\"1bH8ZRbhSVAhScTS0p9-ZzGnX91cHT3uO\",\"2b85f58b927af9964a4c15b8f7e8f179\"} },\n                }}\n\n\n        };\n        fs::path dataset_folder_name = \"pcam\";\n        void load_data();\n\n        void check_resources();\n\n\n    };\n}\n</code></pre>"},{"location":"xTorch/places_8h/","title":"File places.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; places.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/places_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/places_8h/#classes","title":"Classes","text":"Type Name class Places365 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/places.h</code></p>"},{"location":"xTorch/places_8h_source/","title":"File places.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; places.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\n\nnamespace xt::data::datasets {\n   class Places365 : BaseDataset {\n       /*\n       \"\"\"`Places365 &lt;http://places2.csail.mit.edu/index.html&gt;`_ classification dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the Places365 dataset.\n        split (string, optional): The dataset split. Can be one of ``train-standard`` (default), ``train-challenge``,\n            ``val``.\n        small (bool, optional): If ``True``, uses the small images, i.e. resized to 256 x 256 pixels, instead of the\n            high resolution ones.\n        download (bool, optional): If ``True``, downloads the dataset components and places them in ``root``. Already\n            downloaded archives are not downloaded again.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        loader (callable, optional): A function to load an image given its path.\n\n     Attributes:\n        classes (list): List of the class names.\n        class_to_idx (dict): Dict with items (class_name, class_index).\n        imgs (list): List of (image path, class_index) tuples\n        targets (list): The class_index value for each image in the dataset\n\n    Raises:\n        RuntimeError: If ``download is False`` and the meta files, i.e. the devkit, are not present or corrupted.\n        RuntimeError: If ``download is True`` and the image archive is already extracted.\n    \"\"\"\n\n        */\n   public :\n       explicit Places365(const std::string &amp;root);\n       Places365(const std::string &amp;root, DataMode mode);\n       Places365(const std::string &amp;root, DataMode mode , bool download);\n       Places365(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n   private :\n\n//        _SPLITS = (\"train-standard\", \"train-challenge\", \"val\")\n//        _BASE_URL = \"http://data.csail.mit.edu/places/places365/\"\n//        # {variant: (archive, md5)}\n//        _DEVKIT_META = {\n//        \"standard\": (\"filelist_places365-standard.tar\", \"35a0585fee1fa656440f3ab298f8479c\"),\n//        \"challenge\": (\"filelist_places365-challenge.tar\", \"70a8307e459c3de41690a7c76c931734\"),\n//    }\n// # (file, md5)\n//        _CATEGORIES_META = (\"categories_places365.txt\", \"06c963b85866bd0649f97cb43dd16673\")\n//        # {split: (file, md5)}\n//        _FILE_LIST_META = {\n//        \"train-standard\": (\"places365_train_standard.txt\", \"30f37515461640559006b8329efbed1a\"),\n//        \"train-challenge\": (\"places365_train_challenge.txt\", \"b2931dc997b8c33c27e7329c073a6b57\"),\n//        \"val\": (\"places365_val.txt\", \"e9f2fd57bfd9d07630173f4e8708e4b1\"),\n//    }\n// # {(split, small): (file, md5)}\n//        _IMAGES_META = {\n//        (\"train-standard\", False): (\"train_large_places365standard.tar\", \"67e186b496a84c929568076ed01a8aa1\"),\n//        (\"train-challenge\", False): (\"train_large_places365challenge.tar\", \"605f18e68e510c82b958664ea134545f\"),\n//        (\"val\", False): (\"val_large.tar\", \"9b71c4993ad89d2d8bcbdc4aef38042f\"),\n//        (\"train-standard\", True): (\"train_256_places365standard.tar\", \"53ca1c756c3d1e7809517cc47c5561c5\"),\n//        (\"train-challenge\", True): (\"train_256_places365challenge.tar\", \"741915038a5e3471ec7332404dfb64ef\"),\n//        (\"val\", True): (\"val_256.tar\", \"e27b17d8d44f4af9a78502beb927f808\"),\n//    }\n\n\n\n       void load_data();\n\n       void check_resources();\n\n   };\n\n}\n</code></pre>"},{"location":"xTorch/rendered-sst2_8h/","title":"File rendered-sst2.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; rendered-sst2.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/rendered-sst2_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/rendered-sst2_8h/#classes","title":"Classes","text":"Type Name class RenderedSST2 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/rendered-sst2.h</code></p>"},{"location":"xTorch/rendered-sst2_8h_source/","title":"File rendered-sst2.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; rendered-sst2.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class RenderedSST2 : BaseDataset {\n        /*\n        \"\"\"`The Rendered SST2 Dataset &lt;https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md&gt;`_.\n\n    Rendered SST2 is an image classification dataset used to evaluate the models capability on optical\n    character recognition. This dataset was generated by rendering sentences in the Standford Sentiment\n    Treebank v2 dataset.\n\n    This dataset contains two classes (positive and negative) and is divided in three splits: a  train\n    split containing 6920 images (3610 positive and 3310 negative), a validation split containing 872 images\n    (444 positive and 428 negative), and a test split containing 1821 images (909 positive and 912 negative).\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the dataset.\n        split (string, optional): The dataset split, supports ``\"train\"`` (default), `\"val\"` and ``\"test\"``.\n        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n            version. E.g, ``transforms.RandomCrop``.\n        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n        download (bool, optional): If True, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again. Default is False.\n    \"\"\"\n\n         */\n    public :\n        explicit RenderedSST2(const std::string &amp;root);\n        RenderedSST2(const std::string &amp;root, DataMode mode);\n        RenderedSST2(const std::string &amp;root, DataMode mode , bool download);\n        RenderedSST2(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        fs::path url = fs::path(\"https://openaipublic.azureedge.net/clip/data/rendered-sst2.tgz\");\n        fs::path dataset_file_name = \"rendered-sst2.tgz\";\n        std::string dataset_file_md5 = \"2384d08e9dcfa4bd55b324e610496ee5\";\n        fs::path dataset_folder_name = \"rendered-sst2\";\n        void load_data();\n\n        void check_resources();\n\n    };\n}\n</code></pre>"},{"location":"xTorch/semeion_8h/","title":"File semeion.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; semeion.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/semeion_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/semeion_8h/#classes","title":"Classes","text":"Type Name class SEMEION <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/semeion.h</code></p>"},{"location":"xTorch/semeion_8h_source/","title":"File semeion.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; semeion.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n   class SEMEION : BaseDataset {\n       /*\n       r\"\"\"`SEMEION &lt;http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where directory\n            ``semeion.py`` exists.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n        */\n   public :\n       explicit SEMEION(const std::string &amp;root);\n       SEMEION(const std::string &amp;root, DataMode mode);\n       SEMEION(const std::string &amp;root, DataMode mode , bool download);\n       SEMEION(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n   private:\n       fs::path url = fs::path(\"http://archive.ics.uci.edu/ml/machine-learning-databases/semeion/semeion.data\");\n       fs::path dataset_file_name = fs::path(\"semeion.data\");\n       std::string dataset_file_md5 = \"cb545d371d2ce14ec121470795a77432\";\n       fs::path dataset_folder_name = \"semeion\";\n\n       void load_data();\n\n       void check_resources();\n\n    };\n}\n</code></pre>"},{"location":"xTorch/stanford-cars_8h/","title":"File stanford-cars.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; stanford-cars.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/stanford-cars_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/stanford-cars_8h/#classes","title":"Classes","text":"Type Name class StanfordCars <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/stanford-cars.h</code></p>"},{"location":"xTorch/stanford-cars_8h_source/","title":"File stanford-cars.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; stanford-cars.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nnamespace xt::data::datasets {\n   class StanfordCars : BaseDataset {\n/*\n       \"\"\"Stanford Cars  Dataset\n\n           The Cars dataset contains 16,185 images of 196 classes of cars. The data is\n           split into 8,144 training images and 8,041 testing images, where each class\n           has been split roughly in a 50-50 split\n\n           The original URL is https://ai.stanford.edu/~jkrause/cars/car_dataset.html, but it is broken.\n           Follow the instructions in ``download`` argument to obtain and use the dataset offline.\n\n           .. note::\n\n               This class needs `scipy &lt;https://docs.scipy.org/doc/&gt;`_ to load target files from `.mat` format.\n\n           Args:\n               root (str or ``pathlib.Path``): Root directory of dataset\n               split (string, optional): The dataset split, supports ``\"train\"`` (default) or ``\"test\"``.\n               transform (callable, optional): A function/transform that takes in a PIL image\n                   and returns a transformed version. E.g, ``transforms.RandomCrop``\n               target_transform (callable, optional): A function/transform that takes in the\n                   target and transforms it.\n               download (bool, optional): This parameter exists for backward compatibility but it does not\n                   download the dataset, since the original URL is not available anymore. The dataset\n                   seems to be available on Kaggle so you can try to manually download and configure it using\n                   `these instructions &lt;https://github.com/pytorch/vision/issues/7545#issuecomment-1631441616&gt;`_,\n                   or use an integrated\n                   `dataset on Kaggle &lt;https://github.com/pytorch/vision/issues/7545#issuecomment-2282674373&gt;`_.\n                   In both cases, first download and configure the dataset locally, and use the dataset with\n                   ``\"download=False\"``.\n           \"\"\"\n\n */\n   public :\n       explicit StanfordCars(const std::string &amp;root);\n       StanfordCars(const std::string &amp;root, DataMode mode);\n       StanfordCars(const std::string &amp;root, DataMode mode , bool download);\n       StanfordCars(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n   private :\n       void load_data();\n\n       void check_resources();\n\n   };\n}\n</code></pre>"},{"location":"xTorch/stl_8h/","title":"File stl.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; stl.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/stl_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/stl_8h/#classes","title":"Classes","text":"Type Name class STL10 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/stl.h</code></p>"},{"location":"xTorch/stl_8h_source/","title":"File stl.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; stl.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class STL10 : BaseDataset {\n        /*\n        \"\"\"`STL10 &lt;https://cs.stanford.edu/~acoates/stl10/&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where directory\n            ``stl10_binary`` exists.\n        split (string): One of {'train', 'test', 'unlabeled', 'train+unlabeled'}.\n            Accordingly, dataset is selected.\n        folds (int, optional): One of {0-9} or None.\n            For training, loads one of the 10 pre-defined folds of 1k samples for the\n            standard evaluation procedure. If no value is passed, loads the 5k samples.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n    \"\"\"\n\n         */\n    public :\n        explicit STL10(const std::string &amp;root);\n        STL10(const std::string &amp;root, DataMode mode);\n        STL10(const std::string &amp;root, DataMode mode , bool download);\n        STL10(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n\n        fs::path dataset_folder_name = fs::path(\"stl10_binary\");\n        fs::path url = fs::path(\"http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz\");\n        fs::path dataset_file_name = fs::path(\"stl10_binary.tar.gz\");\n        std::string dataset_file_md5 = \"91f7769df0f17e558f3565bffb0c7dfb\";\n\n\n        fs::path class_names_file = fs::path(\"class_names.txt\");\n        fs::path folds_list_file = fs::path(\"fold_indices.txt\");\n\n        std::vector&lt;std::tuple&lt;fs::path, std::string &gt;&gt; train_list = {\n                {\"train_X.bin\", \"918c2871b30a85fa023e0c44e0bee87f\"},\n                {\"train_y.bin\", \"5a34089d4802c674881badbb80307741\"},\n                {\"unlabeled_X.bin\", \"5242ba1fed5e4be9e1e742405eb56ca4\"}\n        };\n\n        std::vector&lt;std::tuple&lt;fs::path, std::string &gt;&gt; test_list = {{\"test_X.bin\", \"7f263ba9f9e0b06b93213547f721ac82\"},\n                                                                     {\"test_y.bin\", \"36f9794fa4beb8a2c72628de14fa638e\"}};\n        std::vector&lt;std::string&gt; splits = {\"train\", \"train+unlabeled\", \"unlabeled\", \"test\"};\n        void load_data();\n\n        void check_resources();\n\n\n\n    };\n}\n</code></pre>"},{"location":"xTorch/sun_8h/","title":"File sun.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; sun.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/sun_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/sun_8h/#classes","title":"Classes","text":"Type Name class SUN397 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/sun.h</code></p>"},{"location":"xTorch/sun_8h_source/","title":"File sun.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; sun.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class SUN397 : BaseDataset {\n        /*\n        \"\"\"`The SUN397 Data Set &lt;https://vision.princeton.edu/projects/2010/SUN/&gt;`_.\n\n    The SUN397 or Scene UNderstanding (SUN) is a dataset for scene recognition consisting of\n    397 categories with 108'754 images.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the dataset.\n        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n            version. E.g, ``transforms.RandomCrop``.\n        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n    \"\"\"\n\n         */\n    public :\n        explicit SUN397(const std::string &amp;root);\n        SUN397(const std::string &amp;root, DataMode mode);\n        SUN397(const std::string &amp;root, DataMode mode , bool download);\n        SUN397(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        fs::path url = fs::path(\"http://vision.princeton.edu/projects/2010/SUN/SUN397.tar.gz\");\n        fs::path dataset_file_name = \"SUN397.tar.gz\";\n        std::string dataset_file_md5 = \"8ca2778205c41d23104230ba66911c7a\";\n        fs::path dataset_folder_name = \"sun397\";\n\n        void load_data();\n\n\n        void check_resources();\n\n    };\n}\n</code></pre>"},{"location":"xTorch/svhn_8h/","title":"File svhn.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; svhn.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/svhn_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/svhn_8h/#classes","title":"Classes","text":"Type Name class SVHN <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/svhn.h</code></p>"},{"location":"xTorch/svhn_8h_source/","title":"File svhn.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; svhn.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class SVHN : BaseDataset {\n        /*\n        \"\"\"`SVHN &lt;http://ufldl.stanford.edu/housenumbers/&gt;`_ Dataset.\n    Note: The SVHN dataset assigns the label `10` to the digit `0`. However, in this Dataset,\n    we assign the label `0` to the digit `0` to be compatible with PyTorch loss functions which\n    expect the class labels to be in the range `[0, C-1]`\n\n    .. warning::\n\n        This class needs `scipy &lt;https://docs.scipy.org/doc/&gt;`_ to load data from `.mat` format.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the dataset where the data is stored.\n        split (string): One of {'train', 'test', 'extra'}.\n            Accordingly dataset is selected. 'extra' is Extra training set.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n         */\n    public :\n        explicit SVHN(const std::string &amp;root);\n        SVHN(const std::string &amp;root, DataMode mode);\n        SVHN(const std::string &amp;root, DataMode mode , bool download);\n        SVHN(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        std::map&lt;std::string, std::tuple&lt;fs::path, fs::path, std::string&gt;&gt; resources = {\n                {\"train\", {\n                                  fs::path(\"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\"),\n                                  fs::path(\"train_32x32.mat\"),\n                                  \"e26dedcc434d2e4c54c9b2d4a06d8373\"}\n                },\n                {\"test\",  {\n                                  fs::path(\"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\"),\n                                  fs::path(\"test_32x32.mat\"),\n                                  \"eb5a983be6a315427106f1b164d9cef3\"}\n                },\n                {\"extra\", {\n                                  fs::path(\"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\"),\n                                  fs::path(\"extra_32x32.mat\"),\n                                  \"a93ce644f1a588dc4d68dda5feec44a7\"\n                          }\n                }\n        };\n        void load_data();\n\n        void check_resources();\n\n    };\n}\n</code></pre>"},{"location":"xTorch/usps_8h/","title":"File usps.h","text":"<p>FileList &gt; datasets &gt; image-classification &gt; usps.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/usps_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/usps_8h/#classes","title":"Classes","text":"Type Name class USPS <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/image-classification/usps.h</code></p>"},{"location":"xTorch/usps_8h_source/","title":"File usps.h","text":"<p>File List &gt; datasets &gt; image-classification &gt; usps.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class USPS : BaseDataset {\n        /*\n        \"\"\"`USPS &lt;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#usps&gt;`_ Dataset.\n    The data-format is : [label [index:value ]*256 \\\\n] * num_lines, where ``label`` lies in ``[1, 10]``.\n    The value for each pixel lies in ``[-1, 1]``. Here we transform the ``label`` into ``[0, 9]``\n    and make pixel values in ``[0, 255]``.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset to store``USPS`` data files.\n        train (bool, optional): If True, creates dataset from ``usps.bz2``,\n            otherwise from ``usps.t.bz2``.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n         */\n    public :\n        explicit USPS(const std::string &amp;root);\n        USPS(const std::string &amp;root, DataMode mode);\n        USPS(const std::string &amp;root, DataMode mode , bool download);\n        USPS(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        std::map&lt;std::string, std::tuple&lt;fs::path, fs::path, std::string&gt;&gt; resources = {\n                {\"train\", {\n                                  fs::path(\n                                          \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2\"),\n                                  fs::path(\"usps.bz2\"),\n                                  \"ec16c51db3855ca6c91edd34d0e9b197\"\n                          }\n\n                },\n                {\"test\",  {\n                                  fs::path(\n                                          \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2\"),\n                                  fs::path(\"usps.t.bz2\"),\n                                  \"8ea070ee2aca1ac39742fdd1ef5ed118\"\n                          }\n                }\n        };\n        void load_data();\n\n        void check_resources();\n\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_2ee0048eab60d09605b89e5e753a33b4/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/language-modeling","text":"<p>FileList &gt; datasets &gt; language-modeling</p>"},{"location":"xTorch/dir_2ee0048eab60d09605b89e5e753a33b4/#files","title":"Files","text":"Type Name file en-wik.h file language-modeling.h file penn-treebank.h file wiki-text.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/</code></p>"},{"location":"xTorch/en-wik_8h/","title":"File en-wik.h","text":"<p>FileList &gt; datasets &gt; language-modeling &gt; en-wik.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/en-wik_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/en-wik_8h/#classes","title":"Classes","text":"Type Name class EnWik <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/en-wik.h</code></p>"},{"location":"xTorch/en-wik_8h_source/","title":"File en-wik.h","text":"<p>File List &gt; datasets &gt; language-modeling &gt; en-wik.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class EnWik : BaseDataset {\n        public :\n            explicit EnWik(const std::string &amp;root);\n        EnWik(const std::string &amp;root, DataMode mode);\n        EnWik(const std::string &amp;root, DataMode mode , bool download);\n        EnWik(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/language-modeling_8h/","title":"File language-modeling.h","text":"<p>FileList &gt; datasets &gt; language-modeling &gt; language-modeling.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"en-wik.h\"</code></li> <li><code>#include \"penn-treebank.h\"</code></li> <li><code>#include \"wiki-text.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/language-modeling.h</code></p>"},{"location":"xTorch/language-modeling_8h_source/","title":"File language-modeling.h","text":"<p>File List &gt; datasets &gt; language-modeling &gt; language-modeling.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"en-wik.h\"\n#include \"penn-treebank.h\"\n#include \"wiki-text.h\"\n</code></pre>"},{"location":"xTorch/penn-treebank_8h/","title":"File penn-treebank.h","text":"<p>FileList &gt; datasets &gt; language-modeling &gt; penn-treebank.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/penn-treebank_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/penn-treebank_8h/#classes","title":"Classes","text":"Type Name class PennTreebank <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/penn-treebank.h</code></p>"},{"location":"xTorch/penn-treebank_8h_source/","title":"File penn-treebank.h","text":"<p>File List &gt; datasets &gt; language-modeling &gt; penn-treebank.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class PennTreebank : BaseDataset {\n        public :\n            explicit PennTreebank(const std::string &amp;root);\n        PennTreebank(const std::string &amp;root, DataMode mode);\n        PennTreebank(const std::string &amp;root, DataMode mode , bool download);\n        PennTreebank(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/wiki-text_8h/","title":"File wiki-text.h","text":"<p>FileList &gt; datasets &gt; language-modeling &gt; wiki-text.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/wiki-text_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/wiki-text_8h/#classes","title":"Classes","text":"Type Name class WikiText <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/language-modeling/wiki-text.h</code></p>"},{"location":"xTorch/wiki-text_8h_source/","title":"File wiki-text.h","text":"<p>File List &gt; datasets &gt; language-modeling &gt; wiki-text.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class WikiText : BaseDataset {\n        public :\n            explicit WikiText(const std::string &amp;root);\n        WikiText(const std::string &amp;root, DataMode mode);\n        WikiText(const std::string &amp;root, DataMode mode , bool download);\n        WikiText(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_91ef7b38e4721f67f17b6805785cb95a/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/machine-translation","text":"<p>FileList &gt; datasets &gt; machine-translation</p>"},{"location":"xTorch/dir_91ef7b38e4721f67f17b6805785cb95a/#files","title":"Files","text":"Type Name file iwslt.h file machine-translation.h file multi.h file wmt.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/</code></p>"},{"location":"xTorch/iwslt_8h/","title":"File iwslt.h","text":"<p>FileList &gt; datasets &gt; machine-translation &gt; iwslt.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/iwslt_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/iwslt_8h/#classes","title":"Classes","text":"Type Name class IWSLT <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/iwslt.h</code></p>"},{"location":"xTorch/iwslt_8h_source/","title":"File iwslt.h","text":"<p>File List &gt; datasets &gt; machine-translation &gt; iwslt.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class IWSLT : BaseDataset {\n        public :\n            explicit IWSLT(const std::string &amp;root);\n        IWSLT(const std::string &amp;root, DataMode mode);\n        IWSLT(const std::string &amp;root, DataMode mode , bool download);\n        IWSLT(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/machine-translation_8h/","title":"File machine-translation.h","text":"<p>FileList &gt; datasets &gt; machine-translation &gt; machine-translation.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"iwslt.h\"</code></li> <li><code>#include \"multi.h\"</code></li> <li><code>#include \"wmt.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/machine-translation.h</code></p>"},{"location":"xTorch/machine-translation_8h_source/","title":"File machine-translation.h","text":"<p>File List &gt; datasets &gt; machine-translation &gt; machine-translation.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"iwslt.h\"\n#include \"multi.h\"\n#include \"wmt.h\"\n</code></pre>"},{"location":"xTorch/multi_8h/","title":"File multi.h","text":"<p>FileList &gt; datasets &gt; machine-translation &gt; multi.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/multi_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/multi_8h/#classes","title":"Classes","text":"Type Name class MULTI <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/multi.h</code></p>"},{"location":"xTorch/multi_8h_source/","title":"File multi.h","text":"<p>File List &gt; datasets &gt; machine-translation &gt; multi.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class MULTI : BaseDataset {\n        public :\n            explicit MULTI(const std::string &amp;root);\n        MULTI(const std::string &amp;root, DataMode mode);\n        MULTI(const std::string &amp;root, DataMode mode , bool download);\n        MULTI(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/wmt_8h/","title":"File wmt.h","text":"<p>FileList &gt; datasets &gt; machine-translation &gt; wmt.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/wmt_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/wmt_8h/#classes","title":"Classes","text":"Type Name class WMT <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/machine-translation/wmt.h</code></p>"},{"location":"xTorch/wmt_8h_source/","title":"File wmt.h","text":"<p>File List &gt; datasets &gt; machine-translation &gt; wmt.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class WMT : BaseDataset {\n        public :\n            explicit WMT(const std::string &amp;root);\n        WMT(const std::string &amp;root, DataMode mode);\n        WMT(const std::string &amp;root, DataMode mode , bool download);\n        WMT(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_cecfbd08ba907cb0c98c6ffe5c1549f6/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/natural-language-inference","text":"<p>FileList &gt; datasets &gt; natural-language-inference</p>"},{"location":"xTorch/dir_cecfbd08ba907cb0c98c6ffe5c1549f6/#files","title":"Files","text":"Type Name file cola.h file mnli.h file mrpc.h file natural-language-inference.h file qnli.h file qqp.h file rte.h file snli.h file stsb.h file wnli.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/</code></p>"},{"location":"xTorch/cola_8h/","title":"File cola.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; cola.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/cola_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/cola_8h/#classes","title":"Classes","text":"Type Name class COLA <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/cola.h</code></p>"},{"location":"xTorch/cola_8h_source/","title":"File cola.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; cola.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class COLA : BaseDataset {\n        public :\n            explicit COLA(const std::string &amp;root);\n        COLA(const std::string &amp;root, DataMode mode);\n        COLA(const std::string &amp;root, DataMode mode , bool download);\n        COLA(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/mnli_8h/","title":"File mnli.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; mnli.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/mnli_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/mnli_8h/#classes","title":"Classes","text":"Type Name class MNLI <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/mnli.h</code></p>"},{"location":"xTorch/mnli_8h_source/","title":"File mnli.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; mnli.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class MNLI : BaseDataset {\n        public :\n            explicit MNLI(const std::string &amp;root);\n        MNLI(const std::string &amp;root, DataMode mode);\n        MNLI(const std::string &amp;root, DataMode mode , bool download);\n        MNLI(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/mrpc_8h/","title":"File mrpc.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; mrpc.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/mrpc_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/mrpc_8h/#classes","title":"Classes","text":"Type Name class MRPC <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/mrpc.h</code></p>"},{"location":"xTorch/mrpc_8h_source/","title":"File mrpc.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; mrpc.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class MRPC : BaseDataset {\n        public :\n            explicit MRPC(const std::string &amp;root);\n        MRPC(const std::string &amp;root, DataMode mode);\n        MRPC(const std::string &amp;root, DataMode mode , bool download);\n        MRPC(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/natural-language-inference_8h/","title":"File natural-language-inference.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; natural-language-inference.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"cola.h\"</code></li> <li><code>#include \"mnli.h\"</code></li> <li><code>#include \"mrpc.h\"</code></li> <li><code>#include \"qnli.h\"</code></li> <li><code>#include \"qqp.h\"</code></li> <li><code>#include \"rte.h\"</code></li> <li><code>#include \"snli.h\"</code></li> <li><code>#include \"stsb.h\"</code></li> <li><code>#include \"wnli.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/natural-language-inference.h</code></p>"},{"location":"xTorch/natural-language-inference_8h_source/","title":"File natural-language-inference.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; natural-language-inference.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"cola.h\"\n#include \"mnli.h\"\n#include \"mrpc.h\"\n#include \"qnli.h\"\n#include \"qqp.h\"\n#include \"rte.h\"\n#include \"snli.h\"\n#include \"stsb.h\"\n#include \"wnli.h\"\n</code></pre>"},{"location":"xTorch/qnli_8h/","title":"File qnli.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; qnli.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/qnli_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/qnli_8h/#classes","title":"Classes","text":"Type Name class QNLI <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/qnli.h</code></p>"},{"location":"xTorch/qnli_8h_source/","title":"File qnli.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; qnli.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class QNLI : BaseDataset {\n        public :\n            explicit QNLI(const std::string &amp;root);\n        QNLI(const std::string &amp;root, DataMode mode);\n        QNLI(const std::string &amp;root, DataMode mode , bool download);\n        QNLI(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/qqp_8h/","title":"File qqp.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; qqp.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/qqp_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/qqp_8h/#classes","title":"Classes","text":"Type Name class QQP <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/qqp.h</code></p>"},{"location":"xTorch/qqp_8h_source/","title":"File qqp.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; qqp.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class QQP : BaseDataset {\n        public :\n            explicit QQP(const std::string &amp;root);\n        QQP(const std::string &amp;root, DataMode mode);\n        QQP(const std::string &amp;root, DataMode mode , bool download);\n        QQP(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/rte_8h/","title":"File rte.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; rte.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/rte_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/rte_8h/#classes","title":"Classes","text":"Type Name class RTE <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/rte.h</code></p>"},{"location":"xTorch/rte_8h_source/","title":"File rte.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; rte.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class RTE : BaseDataset {\n        public :\n            explicit RTE(const std::string &amp;root);\n        RTE(const std::string &amp;root, DataMode mode);\n        RTE(const std::string &amp;root, DataMode mode , bool download);\n        RTE(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/snli_8h/","title":"File snli.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; snli.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/snli_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/snli_8h/#classes","title":"Classes","text":"Type Name class SNLI <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/snli.h</code></p>"},{"location":"xTorch/snli_8h_source/","title":"File snli.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; snli.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class SNLI : BaseDataset {\n        public :\n            explicit SNLI(const std::string &amp;root);\n        SNLI(const std::string &amp;root, DataMode mode);\n        SNLI(const std::string &amp;root, DataMode mode , bool download);\n        SNLI(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/stsb_8h/","title":"File stsb.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; stsb.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/stsb_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/stsb_8h/#classes","title":"Classes","text":"Type Name class STSB <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/stsb.h</code></p>"},{"location":"xTorch/stsb_8h_source/","title":"File stsb.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; stsb.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class STSB : BaseDataset {\n        public :\n            explicit STSB(const std::string &amp;root);\n        STSB(const std::string &amp;root, DataMode mode);\n        STSB(const std::string &amp;root, DataMode mode , bool download);\n        STSB(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/wnli_8h/","title":"File wnli.h","text":"<p>FileList &gt; datasets &gt; natural-language-inference &gt; wnli.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/wnli_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/wnli_8h/#classes","title":"Classes","text":"Type Name class WNLI <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/natural-language-inference/wnli.h</code></p>"},{"location":"xTorch/wnli_8h_source/","title":"File wnli.h","text":"<p>File List &gt; datasets &gt; natural-language-inference &gt; wnli.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class WNLI : BaseDataset {\n        public :\n            explicit WNLI(const std::string &amp;root);\n        WNLI(const std::string &amp;root, DataMode mode);\n        WNLI(const std::string &amp;root, DataMode mode , bool download);\n        WNLI(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_6e95aff3cb8ce7a70a5f1e2f7dd69202/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation","text":"<p>FileList &gt; datasets &gt; object-detection-and-segmentation</p>"},{"location":"xTorch/dir_6e95aff3cb8ce7a70a5f1e2f7dd69202/#files","title":"Files","text":"Type Name file cityscapes.h file coco.h file object-detection-and-segmentation.h file oxfordIII-t-pet.h file sb-dataset.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/</code></p>"},{"location":"xTorch/cityscapes_8h/","title":"File cityscapes.h","text":"<p>FileList &gt; datasets &gt; object-detection-and-segmentation &gt; cityscapes.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/cityscapes_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/cityscapes_8h/#classes","title":"Classes","text":"Type Name class Cityscapes <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/cityscapes.h</code></p>"},{"location":"xTorch/cityscapes_8h_source/","title":"File cityscapes.h","text":"<p>File List &gt; datasets &gt; object-detection-and-segmentation &gt; cityscapes.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Cityscapes : public BaseDataset {\n    public :\n        explicit  Cityscapes(const std::string &amp;root);\n        Cityscapes(const std::string &amp;root, DataMode mode);\n        Cityscapes(const std::string &amp;root, DataMode mode , bool download);\n        Cityscapes(const std::string &amp;root, DataMode mode , bool download, vector&lt;std::function&lt;torch::Tensor(torch::Tensor)&gt;&gt; transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/coco_8h/","title":"File coco.h","text":"<p>FileList &gt; datasets &gt; object-detection-and-segmentation &gt; coco.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/coco_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/coco_8h/#classes","title":"Classes","text":"Type Name class CocoCaptions class CocoDetection <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/coco.h</code></p>"},{"location":"xTorch/coco_8h_source/","title":"File coco.h","text":"<p>File List &gt; datasets &gt; object-detection-and-segmentation &gt; coco.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class CocoDetection : public BaseDataset {\n    public :\n        explicit  CocoDetection(const std::string &amp;root);\n        CocoDetection(const std::string &amp;root, DataMode mode);\n        CocoDetection(const std::string &amp;root, DataMode mode , bool download);\n        CocoDetection(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n    class CocoCaptions : public BaseDataset {\n    public :\n        explicit  CocoCaptions(const std::string &amp;root);\n        CocoCaptions(const std::string &amp;root, DataMode mode);\n        CocoCaptions(const std::string &amp;root, DataMode mode , bool download);\n        CocoCaptions(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/object-detection-and-segmentation_8h/","title":"File object-detection-and-segmentation.h","text":"<p>FileList &gt; datasets &gt; object-detection-and-segmentation &gt; object-detection-and-segmentation.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"cityscapes.h\"</code></li> <li><code>#include \"coco.h\"</code></li> <li><code>#include \"oxfordIII-t-pet.h\"</code></li> <li><code>#include \"sb-dataset.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/object-detection-and-segmentation.h</code></p>"},{"location":"xTorch/object-detection-and-segmentation_8h_source/","title":"File object-detection-and-segmentation.h","text":"<p>File List &gt; datasets &gt; object-detection-and-segmentation &gt; object-detection-and-segmentation.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"cityscapes.h\"\n#include \"coco.h\"\n#include \"oxfordIII-t-pet.h\"\n#include \"sb-dataset.h\"\n</code></pre>"},{"location":"xTorch/oxfordIII-t-pet_8h/","title":"File oxfordIII-t-pet.h","text":"<p>FileList &gt; datasets &gt; object-detection-and-segmentation &gt; oxfordIII-t-pet.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/oxfordIII-t-pet_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/oxfordIII-t-pet_8h/#classes","title":"Classes","text":"Type Name class OxfordIIITPet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/oxfordIII-t-pet.h</code></p>"},{"location":"xTorch/oxfordIII-t-pet_8h_source/","title":"File oxfordIII-t-pet.h","text":"<p>File List &gt; datasets &gt; object-detection-and-segmentation &gt; oxfordIII-t-pet.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class OxfordIIITPet : BaseDataset {\n        /*\n        \"\"\"`Oxford-IIIT Pet Dataset   &lt;https://www.robots.ox.ac.uk/~vgg/data/pets/&gt;`_.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the dataset.\n        split (string, optional): The dataset split, supports ``\"trainval\"`` (default) or ``\"test\"``.\n        target_types (string, sequence of strings, optional): Types of target to use. Can be ``category`` (default) or\n            ``segmentation``. Can also be a list to output a tuple with all specified target types. The types represent:\n\n                - ``category`` (int): Label for one of the 37 pet categories.\n                - ``binary-category`` (int): Binary label for cat or dog.\n                - ``segmentation`` (PIL image): Segmentation trimap of the image.\n\n            If empty, ``None`` will be returned as target.\n\n        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed\n            version. E.g, ``transforms.RandomCrop``.\n        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n        download (bool, optional): If True, downloads the dataset from the internet and puts it into\n            ``root/oxford-iiit-pet``. If dataset is already downloaded, it is not downloaded again.\n    \"\"\"\n\n         */\n    public :\n        explicit OxfordIIITPet(const std::string &amp;root);\n        OxfordIIITPet(const std::string &amp;root, DataMode mode);\n        OxfordIIITPet(const std::string &amp;root, DataMode mode , bool download);\n        OxfordIIITPet(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        vector&lt;std::tuple&lt;fs::path, std::string&gt; &gt; resources = {\n            {\n                fs::path(\"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"),\n                \"5c4f3ee8e5d25df40f4fd59a7f44e54c\"\n            },\n            {\n                fs::path(\"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\"),\n                \"95a8c909bbe2e81eed6a22bccdf3f68f\"\n            }\n        };\n        vector&lt;std::string&gt; _VALID_TARGET_TYPES = {\"category\", \"binary-category\", \"segmentation\"};\n        fs::path dataset_folder_name = \"oxford-iii-pets\";\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/sb-dataset_8h/","title":"File sb-dataset.h","text":"<p>FileList &gt; datasets &gt; object-detection-and-segmentation &gt; sb-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/sb-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/sb-dataset_8h/#classes","title":"Classes","text":"Type Name class SBDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/object-detection-and-segmentation/sb-dataset.h</code></p>"},{"location":"xTorch/sb-dataset_8h_source/","title":"File sb-dataset.h","text":"<p>File List &gt; datasets &gt; object-detection-and-segmentation &gt; sb-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class SBDataset : BaseDataset {\n        /*\n        \"\"\"`Semantic Boundaries Dataset &lt;http://home.bharathh.info/pubs/codes/SBD/download.html&gt;`_\n\n    The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.\n\n    .. note ::\n\n        Please note that the train and val splits included with this dataset are different from\n        the splits in the PASCAL VOC dataset. In particular some \"train\" images might be part of\n        VOC2012 val.\n        If you are interested in testing on VOC 2012 val, then use `image_set='train_noval'`,\n        which excludes all val images.\n\n    .. warning::\n\n        This class needs `scipy &lt;https://docs.scipy.org/doc/&gt;`_ to load target files from `.mat` format.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the Semantic Boundaries Dataset\n        image_set (string, optional): Select the image_set to use, ``train``, ``val`` or ``train_noval``.\n            Image set ``train_noval`` excludes VOC 2012 val images.\n        mode (string, optional): Select target type. Possible values 'boundaries' or 'segmentation'.\n            In case of 'boundaries', the target is an array of shape `[num_classes, H, W]`,\n            where `num_classes=20`.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n        transforms (callable, optional): A function/transform that takes input sample and its target as entry\n            and returns a transformed version. Input sample is PIL image and target is a numpy array\n            if `mode='boundaries'` or PIL image if `mode='segmentation'`.\n    \"\"\"\n\n         */\n    public :\n        explicit SBDataset(const std::string &amp;root);\n        SBDataset(const std::string &amp;root, DataMode mode);\n        SBDataset(const std::string &amp;root, DataMode mode , bool download);\n        SBDataset(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        fs::path url = fs::path(\"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz\");\n        std::string md5 = \"82b4d87ceb2ed10f6038a1cba92111cb\";\n        fs::path filename = fs::path(\"benchmark.tgz\");\n\n        fs::path voc_train_url = fs::path(\"https://www.cs.cornell.edu/~bharathh/train_noval.txt\");\n        fs::path voc_split_filename = fs::path(\"train_noval.txt\");\n        std::string voc_split_md5 = \"79bff800c5f0b1ec6b21080a3c066722\";\n        void load_data();\n\n        void check_resources();\n\n\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_c5272f5a689662c2c5c28882f7ac0097/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/optical-flow","text":"<p>FileList &gt; datasets &gt; optical-flow</p>"},{"location":"xTorch/dir_c5272f5a689662c2c5c28882f7ac0097/#files","title":"Files","text":"Type Name file flying-chairs.h file hd1k.h file optical-flow.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/optical-flow/</code></p>"},{"location":"xTorch/flying-chairs_8h/","title":"File flying-chairs.h","text":"<p>FileList &gt; datasets &gt; optical-flow &gt; flying-chairs.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/flying-chairs_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/flying-chairs_8h/#classes","title":"Classes","text":"Type Name class FlyingChairs <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/optical-flow/flying-chairs.h</code></p>"},{"location":"xTorch/flying-chairs_8h_source/","title":"File flying-chairs.h","text":"<p>File List &gt; datasets &gt; optical-flow &gt; flying-chairs.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class FlyingChairs : public BaseDataset {\n        /*\n        \"\"\"`FlyingChairs &lt;https://lmb.informatik.uni-freiburg.de/resources/datasets/FlyingChairs.en.html#flyingchairs&gt;`_ Dataset for optical flow.\n        You will also need to download the FlyingChairs_train_val.txt file from the dataset page.\n        The dataset is expected to have the following structure: ::\n\n            root\n                FlyingChairs\n                    data\n                        00001_flow.flo\n                        00001_img1.ppm\n                        00001_img2.ppm\n                        ...\n                    FlyingChairs_train_val.txt\n        Args:\n            root (str or ``pathlib.Path``): Root directory of the FlyingChairs Dataset.\n            split (string, optional): The dataset split, either \"train\" (default) or \"val\"\n            transforms (callable, optional): A function/transform that takes in\n                ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n                ``valid_flow_mask`` is expected for consistency with other datasets which\n                return a built-in valid mask, such as :class:`~torchvision.datasets.KittiFlow`.\n        \"\"\"\n        */\n    public :\n        explicit FlyingChairs(const std::string &amp;root);\n        FlyingChairs(const std::string &amp;root, DataMode mode);\n        FlyingChairs(const std::string &amp;root, DataMode mode , bool download);\n        FlyingChairs(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n}\n</code></pre>"},{"location":"xTorch/hd1k_8h/","title":"File hd1k.h","text":"<p>FileList &gt; datasets &gt; optical-flow &gt; hd1k.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/hd1k_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/hd1k_8h/#classes","title":"Classes","text":"Type Name class HD1K <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/optical-flow/hd1k.h</code></p>"},{"location":"xTorch/hd1k_8h_source/","title":"File hd1k.h","text":"<p>File List &gt; datasets &gt; optical-flow &gt; hd1k.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class HD1K : BaseDataset {\n        /*\n        Hello,\n\n        Thanks for your interest in our dataset.\n        You may download our packages using the following links:\n\n        Complete package with all available data (ca. 8 GB):\n        http://hci-benchmark.iwr.uni-heidelberg.de/media/downloads/hd1k_full_package.zip\n\n        Individual packages:\n\n        Benchmark package with input images of the test frames:\n        http://hci-benchmark.iwr.uni-heidelberg.de/media/downloads/hd1k_challenge.zip\n\n        Input images for optical flow:\n        http://hci-benchmark.iwr.uni-heidelberg.de/media/downloads/hd1k_input.zip\n\n        Ground truth for optical flow:\n        http://hci-benchmark.iwr.uni-heidelberg.de/media/downloads/hd1k_flow_gt.zip\n\n        Ground truth uncertainty maps for optical flow:\n        http://hci-benchmark.iwr.uni-heidelberg.de/media/downloads/hd1k_flow_uncertainty.zip\n\n\n        For more information, visit www.hci-benchmark.org or contact us via email.\n        We are happy to hear about your feedback, wishes, and bug reports.\n\n        Yours,\n        The HD1K Benchmark Team\n\n        ----------------------------------------------------------------------------------------------------------------\n        \"\"\"`HD1K &lt;http://hci-benchmark.iwr.uni-heidelberg.de/&gt;`__ dataset for optical flow.\n        The dataset is expected to have the following structure: ::\n\n            root\n                hd1k\n                    hd1k_challenge\n                        image_2\n                    hd1k_flow_gt\n                        flow_occ\n                    hd1k_input\n                        image_2\n        Args:\n            root (str or ``pathlib.Path``): Root directory of the HD1K Dataset.\n            split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n            transforms (callable, optional): A function/transform that takes in\n                ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n        \"\"\"\n\n\n        */\n    public :\n        explicit HD1K(const std::string &amp;root);\n        HD1K(const std::string &amp;root, DataMode mode);\n        HD1K(const std::string &amp;root, DataMode mode , bool download);\n        HD1K(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/optical-flow_8h/","title":"File optical-flow.h","text":"<p>FileList &gt; datasets &gt; optical-flow &gt; optical-flow.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"flying-chairs.h\"</code></li> <li><code>#include \"hd1k.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/optical-flow/optical-flow.h</code></p>"},{"location":"xTorch/optical-flow_8h_source/","title":"File optical-flow.h","text":"<p>File List &gt; datasets &gt; optical-flow &gt; optical-flow.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"flying-chairs.h\"\n#include \"hd1k.h\"\n</code></pre>"},{"location":"xTorch/dir_16503b39329efc9391e88fd543051250/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/patch-matching-descriptor-learning","text":"<p>FileList &gt; datasets &gt; patch-matching-descriptor-learning</p>"},{"location":"xTorch/dir_16503b39329efc9391e88fd543051250/#files","title":"Files","text":"Type Name file patch-matching-descriptor-learning.h file photo-tour.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/patch-matching-descriptor-learning/</code></p>"},{"location":"xTorch/patch-matching-descriptor-learning_8h/","title":"File patch-matching-descriptor-learning.h","text":"<p>FileList &gt; datasets &gt; patch-matching-descriptor-learning &gt; patch-matching-descriptor-learning.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"photo-tour.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/patch-matching-descriptor-learning/patch-matching-descriptor-learning.h</code></p>"},{"location":"xTorch/patch-matching-descriptor-learning_8h_source/","title":"File patch-matching-descriptor-learning.h","text":"<p>File List &gt; datasets &gt; patch-matching-descriptor-learning &gt; patch-matching-descriptor-learning.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"photo-tour.h\"\n</code></pre>"},{"location":"xTorch/photo-tour_8h/","title":"File photo-tour.h","text":"<p>FileList &gt; datasets &gt; patch-matching-descriptor-learning &gt; photo-tour.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/photo-tour_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/photo-tour_8h/#classes","title":"Classes","text":"Type Name class PhotoTour <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/patch-matching-descriptor-learning/photo-tour.h</code></p>"},{"location":"xTorch/photo-tour_8h_source/","title":"File photo-tour.h","text":"<p>File List &gt; datasets &gt; patch-matching-descriptor-learning &gt; photo-tour.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class PhotoTour : BaseDataset {\n        /*\n        \"\"\"`Multi-view Stereo Correspondence &lt;http://matthewalunbrown.com/patchdata/patchdata.html&gt;`_ Dataset.\n\n    .. note::\n\n        We only provide the newer version of the dataset, since the authors state that it\n\n            is more suitable for training descriptors based on difference of Gaussian, or Harris corners, as the\n            patches are centred on real interest point detections, rather than being projections of 3D points as is the\n            case in the old dataset.\n\n        The original dataset is available under http://phototour.cs.washington.edu/patches/default.htm.\n\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory where images are.\n        name (string): Name of the dataset to load.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n         */\n    public :\n        explicit PhotoTour(const std::string &amp;root);\n        PhotoTour(const std::string &amp;root, DataMode mode);\n        PhotoTour(const std::string &amp;root, DataMode mode , bool download);\n        PhotoTour(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        std::map&lt;std::string, std::tuple&lt;fs::path, fs::path, std::string&gt; &gt; resources = {\n            {\n                \"notredame_harris\", {\n                    fs::path(\"http://matthewalunbrown.com/patchdata/notredame_harris.zip\"), fs::path(\n                        \"notredame_harris.zip\"),\n                    \"69f8c90f78e171349abdf0307afefe4d\"\n                }\n            },\n            {\n                \"yosemite_harris\", {\n                    fs::path(\"http://matthewalunbrown.com/patchdata/yosemite_harris.zip\"), fs::path(\n                        \"yosemite_harris.zip\"),\n                    \"a73253d1c6fbd3ba2613c45065c00d46\"\n                }\n            },\n            {\n                \"liberty_harris\", {\n                    fs::path(\"http://matthewalunbrown.com/patchdata/liberty_harris.zip\"), fs::path(\n                        \"liberty_harris.zip\"),\n                    \"c731fcfb3abb4091110d0ae8c7ba182c\"\n                }\n            },\n            {\n                \"notredame\", {\n                    fs::path(\"http://icvl.ee.ic.ac.uk/vbalnt/notredame.zip\"), fs::path(\n                        \"notredame.zip\"),\n                    \"509eda8535847b8c0a90bbb210c83484\"\n                }\n            },\n            {\n                \"yosemite\", {\n                    fs::path(\"http://icvl.ee.ic.ac.uk/vbalnt/yosemite.zip\"), fs::path(\n                        \"yosemite.zip\"),\n                    \"533b2e8eb7ede31be40abc317b2fd4f0\"\n                }\n            },\n            {\n                \"liberty\", {\n                    fs::path(\"http://icvl.ee.ic.ac.uk/vbalnt/liberty.zip\"), fs::path(\n                        \"liberty.zip\"),\n                    \"fdd9152f138ea5ef2091746689176414\"\n                }\n            },\n\n\n        };\n\n        fs::path dataset_folder_name = \"photo-tour\";\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_991b5a5a02a118bdd45c478eaaf6557d/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/scene-flow","text":"<p>FileList &gt; datasets &gt; scene-flow</p>"},{"location":"xTorch/dir_991b5a5a02a118bdd45c478eaaf6557d/#files","title":"Files","text":"Type Name file flying-things-3d.h file scene-flow.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/scene-flow/</code></p>"},{"location":"xTorch/flying-things-3d_8h/","title":"File flying-things-3d.h","text":"<p>FileList &gt; datasets &gt; scene-flow &gt; flying-things-3d.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/flying-things-3d_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/flying-things-3d_8h/#classes","title":"Classes","text":"Type Name class FlyingThings3D <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/scene-flow/flying-things-3d.h</code></p>"},{"location":"xTorch/flying-things-3d_8h_source/","title":"File flying-things-3d.h","text":"<p>File List &gt; datasets &gt; scene-flow &gt; flying-things-3d.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class FlyingThings3D : public BaseDataset {\n        /*\n        \"\"\"`FlyingThings3D &lt;https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html&gt;`_ dataset for optical flow.\n       The dataset is expected to have the following structure: ::\n            root\n                FlyingThings3D\n                    frames_cleanpass\n                        TEST\n                        TRAIN\n                    frames_finalpass\n                        TEST\n                        TRAIN\n                    optical_flow\n                        TEST\n                        TRAIN\n\n        Args:\n            root (str or ``pathlib.Path``): Root directory of the intel FlyingThings3D Dataset.\n            split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n            pass_name (string, optional): The pass to use, either \"clean\" (default) or \"final\" or \"both\". See link above for\n                details on the different passes.\n            camera (string, optional): Which camera to return images from. Can be either \"left\" (default) or \"right\" or \"both\".\n            transforms (callable, optional): A function/transform that takes in\n                ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n                ``valid_flow_mask`` is expected for consistency with other datasets which\n                return a built-in valid mask, such as :class:`~torchvision.datasets.KittiFlow`.\n        \"\"\"\n    */\n    public :\n        explicit FlyingThings3D(const std::string &amp;root);\n        FlyingThings3D(const std::string &amp;root, DataMode mode);\n        FlyingThings3D(const std::string &amp;root, DataMode mode , bool download);\n        FlyingThings3D(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/scene-flow_8h/","title":"File scene-flow.h","text":"<p>FileList &gt; datasets &gt; scene-flow &gt; scene-flow.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"flying-things-3d.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/scene-flow/scene-flow.h</code></p>"},{"location":"xTorch/scene-flow_8h_source/","title":"File scene-flow.h","text":"<p>File List &gt; datasets &gt; scene-flow &gt; scene-flow.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"flying-things-3d.h\"\n</code></pre>"},{"location":"xTorch/dir_2c5adc0a1688a9a1937194391138274f/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/sentiment-analysis","text":"<p>FileList &gt; datasets &gt; sentiment-analysis</p>"},{"location":"xTorch/dir_2c5adc0a1688a9a1937194391138274f/#files","title":"Files","text":"Type Name file imdb.h file sentiment-analysis.h file sst.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sentiment-analysis/</code></p>"},{"location":"xTorch/imdb_8h/","title":"File imdb.h","text":"<p>FileList &gt; datasets &gt; sentiment-analysis &gt; imdb.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/imdb_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/imdb_8h/#classes","title":"Classes","text":"Type Name class IMDB <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sentiment-analysis/imdb.h</code></p>"},{"location":"xTorch/imdb_8h_source/","title":"File imdb.h","text":"<p>File List &gt; datasets &gt; sentiment-analysis &gt; imdb.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class IMDB : BaseDataset {\n        public :\n            explicit IMDB(const std::string &amp;root);\n        IMDB(const std::string &amp;root, DataMode mode);\n        IMDB(const std::string &amp;root, DataMode mode , bool download);\n        IMDB(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/sentiment-analysis_8h/","title":"File sentiment-analysis.h","text":"<p>FileList &gt; datasets &gt; sentiment-analysis &gt; sentiment-analysis.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"imdb.h\"</code></li> <li><code>#include \"sst.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sentiment-analysis/sentiment-analysis.h</code></p>"},{"location":"xTorch/sentiment-analysis_8h_source/","title":"File sentiment-analysis.h","text":"<p>File List &gt; datasets &gt; sentiment-analysis &gt; sentiment-analysis.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"imdb.h\"\n#include \"sst.h\"\n</code></pre>"},{"location":"xTorch/sst_8h/","title":"File sst.h","text":"<p>FileList &gt; datasets &gt; sentiment-analysis &gt; sst.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/sst_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/sst_8h/#classes","title":"Classes","text":"Type Name class SST <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sentiment-analysis/sst.h</code></p>"},{"location":"xTorch/sst_8h_source/","title":"File sst.h","text":"<p>File List &gt; datasets &gt; sentiment-analysis &gt; sst.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class SST : BaseDataset {\n        public :\n            explicit SST(const std::string &amp;root);\n        SST(const std::string &amp;root, DataMode mode);\n        SST(const std::string &amp;root, DataMode mode , bool download);\n        SST(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_c4dca688f613c914aa3d806c1f628e0e/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/sequence-tagging","text":"<p>FileList &gt; datasets &gt; sequence-tagging</p>"},{"location":"xTorch/dir_c4dca688f613c914aa3d806c1f628e0e/#files","title":"Files","text":"Type Name file con-ll-2000-chunking.h file sequence-tagging.h file udpos.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sequence-tagging/</code></p>"},{"location":"xTorch/con-ll-2000-chunking_8h/","title":"File con-ll-2000-chunking.h","text":"<p>FileList &gt; datasets &gt; sequence-tagging &gt; con-ll-2000-chunking.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/con-ll-2000-chunking_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/con-ll-2000-chunking_8h/#classes","title":"Classes","text":"Type Name class CoNLL2000Chunking <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sequence-tagging/con-ll-2000-chunking.h</code></p>"},{"location":"xTorch/con-ll-2000-chunking_8h_source/","title":"File con-ll-2000-chunking.h","text":"<p>File List &gt; datasets &gt; sequence-tagging &gt; con-ll-2000-chunking.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class CoNLL2000Chunking : BaseDataset {\n        public :\n            explicit CoNLL2000Chunking(const std::string &amp;root);\n        CoNLL2000Chunking(const std::string &amp;root, DataMode mode);\n        CoNLL2000Chunking(const std::string &amp;root, DataMode mode , bool download);\n        CoNLL2000Chunking(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/sequence-tagging_8h/","title":"File sequence-tagging.h","text":"<p>FileList &gt; datasets &gt; sequence-tagging &gt; sequence-tagging.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"Co-ll-2000-chunking.h\"</code></li> <li><code>#include \"udpos.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sequence-tagging/sequence-tagging.h</code></p>"},{"location":"xTorch/sequence-tagging_8h_source/","title":"File sequence-tagging.h","text":"<p>File List &gt; datasets &gt; sequence-tagging &gt; sequence-tagging.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"Co-ll-2000-chunking.h\"\n#include \"udpos.h\"\n</code></pre>"},{"location":"xTorch/udpos_8h/","title":"File udpos.h","text":"<p>FileList &gt; datasets &gt; sequence-tagging &gt; udpos.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/udpos_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/udpos_8h/#classes","title":"Classes","text":"Type Name class UDPOS <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/sequence-tagging/udpos.h</code></p>"},{"location":"xTorch/udpos_8h_source/","title":"File udpos.h","text":"<p>File List &gt; datasets &gt; sequence-tagging &gt; udpos.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class UDPOS : BaseDataset {\n        public :\n            explicit UDPOS(const std::string &amp;root);\n        UDPOS(const std::string &amp;root, DataMode mode);\n        UDPOS(const std::string &amp;root, DataMode mode , bool download);\n        UDPOS(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_e5ef08163bed877f164b8cca216875b1/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/specific","text":"<p>FileList &gt; datasets &gt; specific</p>"},{"location":"xTorch/dir_e5ef08163bed877f164b8cca216875b1/#files","title":"Files","text":"Type Name file kitti.h file lsun.h file sbu.h file sintel.h file specific.h file voc.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/</code></p>"},{"location":"xTorch/kitti_8h/","title":"File kitti.h","text":"<p>FileList &gt; datasets &gt; specific &gt; kitti.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/kitti_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/kitti_8h/#classes","title":"Classes","text":"Type Name class Kitti class Kitti2012Stereo class Kitti2015Stereo class KittiFlow <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/kitti.h</code></p>"},{"location":"xTorch/kitti_8h_source/","title":"File kitti.h","text":"<p>File List &gt; datasets &gt; specific &gt; kitti.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Kitti : BaseDataset {\n        /*\n        \"\"\"`KITTI &lt;http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark&gt;`_ Dataset.\n\n    It corresponds to the \"left color images of object\" dataset, for object detection.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory where images are downloaded to.\n            Expects the following folder structure if download=False:\n\n            .. code::\n\n                &lt;root&gt;\n                    \u2514\u2500\u2500 Kitti\n                        \u2514\u2500 raw\n                            \u251c\u2500\u2500 training\n                            |   \u251c\u2500\u2500 image_2\n                            |   \u2514\u2500\u2500 label_2\n                            \u2514\u2500\u2500 testing\n                                \u2514\u2500\u2500 image_2\n        train (bool, optional): Use ``train`` split if true, else ``test`` split.\n            Defaults to ``train``.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.PILToTensor``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        transforms (callable, optional): A function/transform that takes input sample\n            and its target as entry and returns a transformed version.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n         */\n    public :\n        explicit Kitti(const std::string &amp;root);\n        Kitti(const std::string &amp;root, DataMode mode);\n        Kitti(const std::string &amp;root, DataMode mode , bool download);\n        Kitti(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private:\n        fs::path url = fs::path(\"https://s3.eu-central-1.amazonaws.com/avg-kitti/\");\n        vector&lt;std::string&gt; resources = {\n            \"data_object_image_2.zip\",\n            \"data_object_label_2.zip\"\n        };\n        fs::path image_dir_name = fs::path(\"image_2\");\n        fs::path labels_dir_name = fs::path(\"label_2\");\n        fs::path dataset_folder_name = \"kitti\";\n\n        void load_data();\n\n        void check_resources();\n    };\n\n    class KittiFlow : BaseDataset {\n        /*\n        \"\"\"`KITTI &lt;http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=flow&gt;`__ dataset for optical flow (2015).\n\n    The dataset is expected to have the following structure: ::\n\n        root\n            KittiFlow\n                testing\n                    image_2\n                training\n                    image_2\n                    flow_occ\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the KittiFlow Dataset.\n        split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n        transforms (callable, optional): A function/transform that takes in\n            ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n    \"\"\"\n\n         */\n    public :\n        explicit  KittiFlow(const std::string &amp;root);\n        KittiFlow(const std::string &amp;root, DataMode mode);\n        KittiFlow(const std::string &amp;root, DataMode mode , bool download);\n        KittiFlow(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n    class Kitti2012Stereo : BaseDataset {\n        /*\n        \"\"\"\n    KITTI dataset from the `2012 stereo evaluation benchmark &lt;http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php&gt;`_.\n    Uses the RGB images for consistency with KITTI 2015.\n\n    The dataset is expected to have the following structure: ::\n\n        root\n            Kitti2012\n                testing\n                    colored_0\n                        1_10.png\n                        2_10.png\n                        ...\n                    colored_1\n                        1_10.png\n                        2_10.png\n                        ...\n                training\n                    colored_0\n                        1_10.png\n                        2_10.png\n                        ...\n                    colored_1\n                        1_10.png\n                        2_10.png\n                        ...\n                    disp_noc\n                        1.png\n                        2.png\n                        ...\n                    calib\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory where `Kitti2012` is located.\n        split (string, optional): The dataset split of scenes, either \"train\" (default) or \"test\".\n        transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n    \"\"\"\n\n         */\n    public :\n        explicit  Kitti2012Stereo(const std::string &amp;root);\n        Kitti2012Stereo(const std::string &amp;root, DataMode mode);\n        Kitti2012Stereo(const std::string &amp;root, DataMode mode , bool download);\n        Kitti2012Stereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n    class Kitti2015Stereo : BaseDataset {\n        /*\n        \"\"\"\n    KITTI dataset from the `2015 stereo evaluation benchmark &lt;http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php&gt;`_.\n\n    The dataset is expected to have the following structure: ::\n\n        root\n            Kitti2015\n                testing\n                    image_2\n                        img1.png\n                        img2.png\n                        ...\n                    image_3\n                        img1.png\n                        img2.png\n                        ...\n                training\n                    image_2\n                        img1.png\n                        img2.png\n                        ...\n                    image_3\n                        img1.png\n                        img2.png\n                        ...\n                    disp_occ_0\n                        img1.png\n                        img2.png\n                        ...\n                    disp_occ_1\n                        img1.png\n                        img2.png\n                        ...\n                    calib\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory where `Kitti2015` is located.\n        split (string, optional): The dataset split of scenes, either \"train\" (default) or \"test\".\n        transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n    \"\"\"\n\n         */\n    public :\n        explicit Kitti2015Stereo(const std::string &amp;root);\n        Kitti2015Stereo(const std::string &amp;root, DataMode mode);\n        Kitti2015Stereo(const std::string &amp;root, DataMode mode , bool download);\n        Kitti2015Stereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/lsun_8h/","title":"File lsun.h","text":"<p>FileList &gt; datasets &gt; specific &gt; lsun.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/lsun_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/lsun_8h/#classes","title":"Classes","text":"Type Name class LSUN <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/lsun.h</code></p>"},{"location":"xTorch/lsun_8h_source/","title":"File lsun.h","text":"<p>File List &gt; datasets &gt; specific &gt; lsun.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    [[deprecated(\"LSUN Dataset files removed and Links are broken\")]]\n    class LSUN  : BaseDataset  {\n    public :\n        LSUN(const std::string &amp;root, DataMode mode = DataMode::TRAIN, bool download = false);\n\n        LSUN(const fs::path &amp;root, DatasetArguments args);\n\n    private :\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n}\n</code></pre>"},{"location":"xTorch/sbu_8h/","title":"File sbu.h","text":"<p>FileList &gt; datasets &gt; specific &gt; sbu.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/sbu_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/sbu_8h/#classes","title":"Classes","text":"Type Name class SBU <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/sbu.h</code></p>"},{"location":"xTorch/sbu_8h_source/","title":"File sbu.h","text":"<p>File List &gt; datasets &gt; specific &gt; sbu.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\n\nnamespace xt::data::datasets {\n    class SBU : BaseDataset {\n        /*\n        \"\"\"`SBU Captioned Photo &lt;http://www.cs.virginia.edu/~vicente/sbucaptions/&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where tarball\n            ``SBUCaptionedPhotoDataset.tar.gz`` exists.\n        transform (callable, optional): A function/transform that takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If True, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n    \"\"\"\n\n         */\n    public :\n        explicit SBU(const std::string &amp;root);\n        SBU(const std::string &amp;root, DataMode mode);\n        SBU(const std::string &amp;root, DataMode mode , bool download);\n        SBU(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        fs::path url = fs::path(\"https://www.cs.rice.edu/~vo9/sbucaptions/SBUCaptionedPhotoDataset.tar.gz\");\n        fs::path dataset_file_name = fs::path(\"SBUCaptionedPhotoDataset.tar.gz\");\n        std::string dataset_file_md5 = \"9aec147b3488753cf758b4d493422285\";\n        fs::path dataset_folder_name = \"sbu\";\n        void load_data();\n\n        void check_resources();\n\n\n    };\n}\n</code></pre>"},{"location":"xTorch/sintel_8h/","title":"File sintel.h","text":"<p>FileList &gt; datasets &gt; specific &gt; sintel.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/sintel_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/sintel_8h/#classes","title":"Classes","text":"Type Name class Sintel class SintelStereo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/sintel.h</code></p>"},{"location":"xTorch/sintel_8h_source/","title":"File sintel.h","text":"<p>File List &gt; datasets &gt; specific &gt; sintel.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n   class Sintel : BaseDataset {\n/*\n       \"\"\"`Sintel &lt;http://sintel.is.tue.mpg.de/&gt;`_ Dataset for optical flow.\n\n           The dataset is expected to have the following structure: ::\n\n               root\n                   Sintel\n                       testing\n                           clean\n                               scene_1\n                               scene_2\n                               ...\n                           final\n                               scene_1\n                               scene_2\n                               ...\n                       training\n                           clean\n                               scene_1\n                               scene_2\n                               ...\n                           final\n                               scene_1\n                               scene_2\n                               ...\n                           flow\n                               scene_1\n                               scene_2\n                               ...\n\n           Args:\n               root (str or ``pathlib.Path``): Root directory of the Sintel Dataset.\n               split (string, optional): The dataset split, either \"train\" (default) or \"test\"\n               pass_name (string, optional): The pass to use, either \"clean\" (default), \"final\", or \"both\". See link above for\n                   details on the different passes.\n               transforms (callable, optional): A function/transform that takes in\n                   ``img1, img2, flow, valid_flow_mask`` and returns a transformed version.\n                   ``valid_flow_mask`` is expected for consistency with other datasets which\n                   return a built-in valid mask, such as :class:`~torchvision.datasets.KittiFlow`.\n           \"\"\"\n\n */\n   public :\n       explicit Sintel(const std::string &amp;root);\n       Sintel(const std::string &amp;root, DataMode mode);\n       Sintel(const std::string &amp;root, DataMode mode , bool download);\n       Sintel(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n   private :\n       void load_data();\n\n       void check_resources();\n\n   };\n   class SintelStereo : BaseDataset {\n/*\n       \"\"\"Sintel `Stereo Dataset &lt;http://sintel.is.tue.mpg.de/stereo&gt;`_.\n\n           The dataset is expected to have the following structure: ::\n\n               root\n                   Sintel\n                       training\n                           final_left\n                               scene1\n                                   img1.png\n                                   img2.png\n                                   ...\n                               ...\n                           final_right\n                               scene2\n                                   img1.png\n                                   img2.png\n                                   ...\n                               ...\n                           disparities\n                               scene1\n                                   img1.png\n                                   img2.png\n                                   ...\n                               ...\n                           occlusions\n                               scene1\n                                   img1.png\n                                   img2.png\n                                   ...\n                               ...\n                           outofframe\n                               scene1\n                                   img1.png\n                                   img2.png\n                                   ...\n                               ...\n\n           Args:\n               root (str or ``pathlib.Path``): Root directory where Sintel Stereo is located.\n               pass_name (string): The name of the pass to use, either \"final\", \"clean\" or \"both\".\n               transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n           \"\"\"\n\n */\n   public :\n       SintelStereo(const std::string &amp;root);\n       SintelStereo(const std::string &amp;root, DataMode mode);\n       SintelStereo(const std::string &amp;root, DataMode mode , bool download);\n       SintelStereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n   private :\n       void load_data();\n\n       void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/specific_8h/","title":"File specific.h","text":"<p>FileList &gt; datasets &gt; specific &gt; specific.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"kitti.h\"</code></li> <li><code>#include \"lsun.h\"</code></li> <li><code>#include \"sbu.h\"</code></li> <li><code>#include \"sintel.h\"</code></li> <li><code>#include \"voc.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/specific.h</code></p>"},{"location":"xTorch/specific_8h_source/","title":"File specific.h","text":"<p>File List &gt; datasets &gt; specific &gt; specific.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"kitti.h\"\n#include \"lsun.h\"\n#include \"sbu.h\"\n#include \"sintel.h\"\n#include \"voc.h\"\n</code></pre>"},{"location":"xTorch/voc_8h/","title":"File voc.h","text":"<p>FileList &gt; datasets &gt; specific &gt; voc.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/voc_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/voc_8h/#classes","title":"Classes","text":"Type Name class VOCDetection class VOCSegmentation <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/specific/voc.h</code></p>"},{"location":"xTorch/voc_8h_source/","title":"File voc.h","text":"<p>File List &gt; datasets &gt; specific &gt; voc.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class VOCDetection : BaseDataset {\n        /*\n        \"\"\"`Pascal VOC &lt;http://host.robots.ox.ac.uk/pascal/VOC/&gt;`_ Detection Dataset.\n\n     Args:\n         root (str or ``pathlib.Path``): Root directory of the VOC Dataset.\n         year (string, optional): The dataset year, supports years ``\"2007\"`` to ``\"2012\"``.\n         image_set (string, optional): Select the image_set to use, ``\"train\"``, ``\"trainval\"`` or ``\"val\"``. If\n             ``year==\"2007\"``, can also be ``\"test\"``.\n         download (bool, optional): If true, downloads the dataset from the internet and\n             puts it in root directory. If dataset is already downloaded, it is not\n             downloaded again.\n             (default: alphabetic indexing of VOC's 20 classes).\n         transform (callable, optional): A function/transform that takes in a PIL image\n             and returns a transformed version. E.g, ``transforms.RandomCrop``\n         target_transform (callable, required): A function/transform that takes in the\n             target and transforms it.\n         transforms (callable, optional): A function/transform that takes input sample and its target as entry\n             and returns a transformed version.\n     \"\"\"\n\n         */\n\n    public :\n        explicit VOCDetection(const std::string &amp;root);\n\n        VOCDetection(const std::string &amp;root, DataMode mode);\n\n        VOCDetection(const std::string &amp;root, DataMode mode, bool download);\n\n        VOCDetection(const std::string &amp;root, DataMode mode, bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n    class VOCSegmentation : BaseDataset {\n        /*\n        \"\"\"`Pascal VOC &lt;http://host.robots.ox.ac.uk/pascal/VOC/&gt;`_ Segmentation Dataset.\n\n     Args:\n         root (str or ``pathlib.Path``): Root directory of the VOC Dataset.\n         year (string, optional): The dataset year, supports years ``\"2007\"`` to ``\"2012\"``.\n         image_set (string, optional): Select the image_set to use, ``\"train\"``, ``\"trainval\"`` or ``\"val\"``. If\n             ``year==\"2007\"``, can also be ``\"test\"``.\n         download (bool, optional): If true, downloads the dataset from the internet and\n             puts it in root directory. If dataset is already downloaded, it is not\n             downloaded again.\n         transform (callable, optional): A function/transform that  takes in a PIL image\n             and returns a transformed version. E.g, ``transforms.RandomCrop``\n         target_transform (callable, optional): A function/transform that takes in the\n             target and transforms it.\n         transforms (callable, optional): A function/transform that takes input sample and its target as entry\n             and returns a transformed version.\n     \"\"\"\n\n         */\n\n    public :\n        explicit VOCSegmentation(const std::string &amp;root);\n        VOCSegmentation(const std::string &amp;root, DataMode mode);\n        VOCSegmentation(const std::string &amp;root, DataMode mode , bool download);\n        VOCSegmentation(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_e353cfd6010331702b3559c9641f7f23/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation</p>"},{"location":"xTorch/dir_e353cfd6010331702b3559c9641f7f23/#files","title":"Files","text":"Type Name file cre-stereo.h file eth-3d-stereo.h file falling-things-stereo.h file in-stereo.h file middlebury.h file scene-flow-stereo.h file stereo-matching-depth-estimation.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/</code></p>"},{"location":"xTorch/cre-stereo_8h/","title":"File cre-stereo.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; cre-stereo.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/cre-stereo_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/cre-stereo_8h/#classes","title":"Classes","text":"Type Name class CREStereo class CarlaStereo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/cre-stereo.h</code></p>"},{"location":"xTorch/cre-stereo_8h_source/","title":"File cre-stereo.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; cre-stereo.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class CarlaStereo : public  BaseDataset {\n    public :\n        explicit  CarlaStereo(const std::string &amp;root);\n        CarlaStereo(const std::string &amp;root, DataMode mode);\n        CarlaStereo(const std::string &amp;root, DataMode mode , bool download);\n        CarlaStereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n\n\n    class CREStereo : public BaseDataset {\n    public :\n        explicit  CREStereo(const std::string &amp;root);\n        CREStereo(const std::string &amp;root, DataMode mode);\n        CREStereo(const std::string &amp;root, DataMode mode , bool download);\n        CREStereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/eth-3d-stereo_8h/","title":"File eth-3d-stereo.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; eth-3d-stereo.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/eth-3d-stereo_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/eth-3d-stereo_8h/#classes","title":"Classes","text":"Type Name class ETH3DStereo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/eth-3d-stereo.h</code></p>"},{"location":"xTorch/eth-3d-stereo_8h_source/","title":"File eth-3d-stereo.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; eth-3d-stereo.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class ETH3DStereo : public BaseDataset {\n    public:\n        explicit ETH3DStereo(const std::string &amp;root);\n        ETH3DStereo(const std::string &amp;root, DataMode mode);\n        ETH3DStereo(const std::string &amp;root, DataMode mode , bool download);\n        ETH3DStereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/falling-things-stereo_8h/","title":"File falling-things-stereo.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; falling-things-stereo.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/falling-things-stereo_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/falling-things-stereo_8h/#classes","title":"Classes","text":"Type Name class FallingThingsStereo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/falling-things-stereo.h</code></p>"},{"location":"xTorch/falling-things-stereo_8h_source/","title":"File falling-things-stereo.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; falling-things-stereo.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class FallingThingsStereo : public BaseDataset {\n        /*\n        `FallingThings &lt;https://research.nvidia.com/publication/2018-06_falling-things-synthetic-dataset-3d-object-detection-and-pose-estimation&gt;`_ dataset.\n        The dataset is expected to have the following structure: ::\n        root\n            FallingThings\n                single\n                    dir1\n                        scene1\n                            _object_settings.json\n                            _camera_settings.json\n                            image1.left.depth.png\n                            image1.right.depth.png\n                            image1.left.jpg\n                            image1.right.jpg\n                            image2.left.depth.png\n                            image2.right.depth.png\n                            image2.left.jpg\n                            image2.right\n                            ...\n                        scene2\n                    ...\n                mixed\n                    scene1\n                        _object_settings.json\n                        _camera_settings.json\n                        image1.left.depth.png\n                        image1.right.depth.png\n                        image1.left.jpg\n                        image1.right.jpg\n                        image2.left.depth.png\n                        image2.right.depth.png\n                        image2.left.jpg\n                        image2.right\n                        ...\n                    scene2\n                    ...\n         */\n    public :\n        explicit  FallingThingsStereo(const std::string &amp;root);\n        FallingThingsStereo(const std::string &amp;root, DataMode mode);\n        FallingThingsStereo(const std::string &amp;root, DataMode mode , bool download);\n        FallingThingsStereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        fs::path  url =\"https://drive.google.com/open?id=1y4h9T6D9rf6dAmsRwEtfzJdcghCnI_01\";\n        fs::path dataset_file_name = \"fat.zip\";\n        std::string dataset_file_md5 = \"????????????????????????????????\";\n        fs::path dataset_folder_name = \"FallingThings\";\n        void load_data();\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/in-stereo_8h/","title":"File in-stereo.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; in-stereo.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/in-stereo_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/in-stereo_8h/#classes","title":"Classes","text":"Type Name class InStereo2k <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/in-stereo.h</code></p>"},{"location":"xTorch/in-stereo_8h_source/","title":"File in-stereo.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; in-stereo.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class InStereo2k : BaseDataset {\n        /*\n        \"\"\"`InStereo2k &lt;https://github.com/YuhuaXu/StereoDataset&gt;`_ dataset.\n\n        The dataset is expected to have the following structure: ::\n\n            root\n                InStereo2k\n                    train\n                        scene1\n                            left.png\n                            right.png\n                            left_disp.png\n                            right_disp.png\n                            ...\n                        scene2\n                        ...\n                    test\n                        scene1\n                            left.png\n                            right.png\n                            left_disp.png\n                            right_disp.png\n                            ...\n                        scene2\n                        ...\n\n        Args:\n            root (str or ``pathlib.Path``): Root directory where InStereo2k is located.\n            split (string): Either \"train\" or \"test\".\n            transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n        \"\"\"\n         */\n    public :\n        explicit  InStereo2k(const std::string &amp;root);\n        InStereo2k(const std::string &amp;root, DataMode mode);\n        InStereo2k(const std::string &amp;root, DataMode mode , bool download);\n        InStereo2k(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        void load_data();\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/middlebury_8h/","title":"File middlebury.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; middlebury.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/middlebury_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/middlebury_8h/#classes","title":"Classes","text":"Type Name class Middlebury2014Stereo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/middlebury.h</code></p>"},{"location":"xTorch/middlebury_8h_source/","title":"File middlebury.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; middlebury.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Middlebury2014Stereo : BaseDataset {\n        /*\n             \"\"\"Publicly available scenes from the Middlebury dataset `2014 version &lt;https://vision.middlebury.edu/stereo/data/scenes2014/&gt;`.\n\n    The dataset mostly follows the original format, without containing the ambient subdirectories.  : ::\n\n        root\n            Middlebury2014\n                train\n                    scene1-{perfect,imperfect}\n                        calib.txt\n                        im{0,1}.png\n                        im1E.png\n                        im1L.png\n                        disp{0,1}.pfm\n                        disp{0,1}-n.png\n                        disp{0,1}-sd.pfm\n                        disp{0,1}y.pfm\n                    scene2-{perfect,imperfect}\n                        calib.txt\n                        im{0,1}.png\n                        im1E.png\n                        im1L.png\n                        disp{0,1}.pfm\n                        disp{0,1}-n.png\n                        disp{0,1}-sd.pfm\n                        disp{0,1}y.pfm\n                    ...\n                additional\n                    scene1-{perfect,imperfect}\n                        calib.txt\n                        im{0,1}.png\n                        im1E.png\n                        im1L.png\n                        disp{0,1}.pfm\n                        disp{0,1}-n.png\n                        disp{0,1}-sd.pfm\n                        disp{0,1}y.pfm\n                    ...\n                test\n                    scene1\n                        calib.txt\n                        im{0,1}.png\n                    scene2\n                        calib.txt\n                        im{0,1}.png\n                    ...\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the Middleburry 2014 Dataset.\n        split (string, optional): The dataset split of scenes, either \"train\" (default), \"test\", or \"additional\"\n        use_ambient_views (boolean, optional): Whether to use different expose or lightning views when possible.\n            The dataset samples with equal probability between ``[im1.png, im1E.png, im1L.png]``.\n        calibration (string, optional): Whether or not to use the calibrated (default) or uncalibrated scenes.\n        transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n        download (boolean, optional): Whether or not to download the dataset in the ``root`` directory.\n    \"\"\"\n\n         */\n    public :\n        explicit Middlebury2014Stereo(const std::string &amp;root);\n        Middlebury2014Stereo(const std::string &amp;root, DataMode mode);\n        Middlebury2014Stereo(const std::string &amp;root, DataMode mode , bool download);\n        Middlebury2014Stereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        fs::path dataset_folder_name = fs::path(\"Middlebury2014\");\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/scene-flow-stereo_8h/","title":"File scene-flow-stereo.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; scene-flow-stereo.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/scene-flow-stereo_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/scene-flow-stereo_8h/#classes","title":"Classes","text":"Type Name class SceneFlowStereo <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/scene-flow-stereo.h</code></p>"},{"location":"xTorch/scene-flow-stereo_8h_source/","title":"File scene-flow-stereo.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; scene-flow-stereo.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n   class SceneFlowStereo : BaseDataset {\n       /*\n            \"\"\"Dataset interface for `Scene Flow &lt;https://lmb.informatik.uni-freiburg.de/resources/datasets/SceneFlowDatasets.en.html&gt;`_ datasets.\n    This interface provides access to the `FlyingThings3D, `Monkaa` and `Driving` datasets.\n\n    The dataset is expected to have the following structure: ::\n\n        root\n            SceneFlow\n                Monkaa\n                    frames_cleanpass\n                        scene1\n                            left\n                                img1.png\n                                img2.png\n                            right\n                                img1.png\n                                img2.png\n                        scene2\n                            left\n                                img1.png\n                                img2.png\n                            right\n                                img1.png\n                                img2.png\n                    frames_finalpass\n                        scene1\n                            left\n                                img1.png\n                                img2.png\n                            right\n                                img1.png\n                                img2.png\n                        ...\n                        ...\n                    disparity\n                        scene1\n                            left\n                                img1.pfm\n                                img2.pfm\n                            right\n                                img1.pfm\n                                img2.pfm\n                FlyingThings3D\n                    ...\n                    ...\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory where SceneFlow is located.\n        variant (string): Which dataset variant to user, \"FlyingThings3D\" (default), \"Monkaa\" or \"Driving\".\n        pass_name (string): Which pass to use, \"clean\" (default), \"final\" or \"both\".\n        transforms (callable, optional): A function/transform that takes in a sample and returns a transformed version.\n\n    \"\"\"\n\n        */\n\n   public :\n       explicit SceneFlowStereo(const std::string &amp;root);\n       SceneFlowStereo(const std::string &amp;root, DataMode mode);\n       SceneFlowStereo(const std::string &amp;root, DataMode mode , bool download);\n       SceneFlowStereo(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n   private :\n       fs::path dataset_folder_name = fs::path(\"SceneFlow\") ;\n       void load_data();\n\n       void check_resources();\n\n   };\n}\n</code></pre>"},{"location":"xTorch/stereo-matching-depth-estimation_8h/","title":"File stereo-matching-depth-estimation.h","text":"<p>FileList &gt; datasets &gt; stereo-matching-depth-estimation &gt; stereo-matching-depth-estimation.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"cre-stereo.h\"</code></li> <li><code>#include \"eth-3d-stereo.h\"</code></li> <li><code>#include \"falling-things-stereo.h\"</code></li> <li><code>#include \"in-stereo.h\"</code></li> <li><code>#include \"middlebury.h\"</code></li> <li><code>#include \"scene-flow-stereo.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/stereo-matching-depth-estimation/stereo-matching-depth-estimation.h</code></p>"},{"location":"xTorch/stereo-matching-depth-estimation_8h_source/","title":"File stereo-matching-depth-estimation.h","text":"<p>File List &gt; datasets &gt; stereo-matching-depth-estimation &gt; stereo-matching-depth-estimation.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"cre-stereo.h\"\n#include \"eth-3d-stereo.h\"\n#include \"falling-things-stereo.h\"\n#include \"in-stereo.h\"\n#include \"middlebury.h\"\n#include \"scene-flow-stereo.h\"\n</code></pre>"},{"location":"xTorch/dir_50f41150f848aea77b9741968a6098a5/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/text-classification","text":"<p>FileList &gt; datasets &gt; text-classification</p>"},{"location":"xTorch/dir_50f41150f848aea77b9741968a6098a5/#files","title":"Files","text":"Type Name file ag-news.h file amazon-review.h file db-pedia.h file sogou-news.h file text-classification.h file yahoo-answers.h file yelp-review.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/</code></p>"},{"location":"xTorch/ag-news_8h/","title":"File ag-news.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; ag-news.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/ag-news_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/ag-news_8h/#classes","title":"Classes","text":"Type Name class AgNews <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/ag-news.h</code></p>"},{"location":"xTorch/ag-news_8h_source/","title":"File ag-news.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; ag-news.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class AgNews : BaseDataset {\n        public :\n            explicit AgNews(const std::string &amp;root);\n        AgNews(const std::string &amp;root, DataMode mode);\n        AgNews(const std::string &amp;root, DataMode mode , bool download);\n        AgNews(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/amazon-review_8h/","title":"File amazon-review.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; amazon-review.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/amazon-review_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/amazon-review_8h/#classes","title":"Classes","text":"Type Name class AmazonReview <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/amazon-review.h</code></p>"},{"location":"xTorch/amazon-review_8h_source/","title":"File amazon-review.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; amazon-review.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class AmazonReview : BaseDataset {\n        public :\n            explicit AmazonReview(const std::string &amp;root);\n        AmazonReview(const std::string &amp;root, DataMode mode);\n        AmazonReview(const std::string &amp;root, DataMode mode , bool download);\n        AmazonReview(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/db-pedia_8h/","title":"File db-pedia.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; db-pedia.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/db-pedia_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/db-pedia_8h/#classes","title":"Classes","text":"Type Name class DBPedia <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/db-pedia.h</code></p>"},{"location":"xTorch/db-pedia_8h_source/","title":"File db-pedia.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; db-pedia.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class DBPedia : BaseDataset {\n        public :\n            explicit DBPedia(const std::string &amp;root);\n        DBPedia(const std::string &amp;root, DataMode mode);\n        DBPedia(const std::string &amp;root, DataMode mode , bool download);\n        DBPedia(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/sogou-news_8h/","title":"File sogou-news.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; sogou-news.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/sogou-news_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/sogou-news_8h/#classes","title":"Classes","text":"Type Name class SogouNews <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/sogou-news.h</code></p>"},{"location":"xTorch/sogou-news_8h_source/","title":"File sogou-news.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; sogou-news.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class SogouNews : BaseDataset {\n        public :\n            explicit SogouNews(const std::string &amp;root);\n        SogouNews(const std::string &amp;root, DataMode mode);\n        SogouNews(const std::string &amp;root, DataMode mode , bool download);\n        SogouNews(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/text-classification_8h/","title":"File text-classification.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; text-classification.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"ag-news.h\"</code></li> <li><code>#include \"amazon-review.h\"</code></li> <li><code>#include \"db-pedia.h\"</code></li> <li><code>#include \"sogou-news.h\"</code></li> <li><code>#include \"yahoo-answers.h\"</code></li> <li><code>#include \"yelp-review.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/text-classification.h</code></p>"},{"location":"xTorch/text-classification_8h_source/","title":"File text-classification.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; text-classification.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"ag-news.h\"\n#include \"amazon-review.h\"\n#include \"db-pedia.h\"\n#include \"sogou-news.h\"\n#include \"yahoo-answers.h\"\n#include \"yelp-review.h\"\n</code></pre>"},{"location":"xTorch/yahoo-answers_8h/","title":"File yahoo-answers.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; yahoo-answers.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/yahoo-answers_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/yahoo-answers_8h/#classes","title":"Classes","text":"Type Name class YahooAnswers <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/yahoo-answers.h</code></p>"},{"location":"xTorch/yahoo-answers_8h_source/","title":"File yahoo-answers.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; yahoo-answers.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class YahooAnswers : BaseDataset {\n        public :\n            explicit YahooAnswers(const std::string &amp;root);\n        YahooAnswers(const std::string &amp;root, DataMode mode);\n        YahooAnswers(const std::string &amp;root, DataMode mode , bool download);\n        YahooAnswers(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/yelp-review_8h/","title":"File yelp-review.h","text":"<p>FileList &gt; datasets &gt; text-classification &gt; yelp-review.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/yelp-review_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/yelp-review_8h/#classes","title":"Classes","text":"Type Name class YelpReview <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/text-classification/yelp-review.h</code></p>"},{"location":"xTorch/yelp-review_8h_source/","title":"File yelp-review.h","text":"<p>File List &gt; datasets &gt; text-classification &gt; yelp-review.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class YelpReview : BaseDataset {\n        public :\n            explicit YelpReview(const std::string &amp;root);\n        YelpReview(const std::string &amp;root, DataMode mode);\n        YelpReview(const std::string &amp;root, DataMode mode , bool download);\n        YelpReview(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n        private :\n            void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_424049e583f42f721b040286e87ec464/","title":"Dir /home/kami/Documents/cpp/models/include/datasets/video","text":"<p>FileList &gt; datasets &gt; video</p>"},{"location":"xTorch/dir_424049e583f42f721b040286e87ec464/#files","title":"Files","text":"Type Name file hmdb.h file kinetics.h file moving-mnist.h file ucf.h file video.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/</code></p>"},{"location":"xTorch/hmdb_8h/","title":"File hmdb.h","text":"<p>FileList &gt; datasets &gt; video &gt; hmdb.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/hmdb_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/hmdb_8h/#classes","title":"Classes","text":"Type Name class HMDB51 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/hmdb.h</code></p>"},{"location":"xTorch/hmdb_8h_source/","title":"File hmdb.h","text":"<p>File List &gt; datasets &gt; video &gt; hmdb.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class HMDB51 : BaseDataset {\n        /*\n        \"\"\"\n            `HMDB51 &lt;https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/&gt;`_\n            dataset.\n\n            HMDB51 is an action recognition video dataset.\n            This dataset consider every video as a collection of video clips of fixed size, specified\n            by ``frames_per_clip``, where the step in frames between each clip is given by\n            ``step_between_clips``.\n\n            To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n            and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n            elements will come from video 1, and the next three elements from video 2.\n            Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n            frames in a video might be present.\n\n            Internally, it uses a VideoClips object to handle clip creation.\n\n            Args:\n                root (str or ``pathlib.Path``): Root directory of the HMDB51 Dataset.\n                annotation_path (str): Path to the folder containing the split files.\n                frames_per_clip (int): Number of frames in a clip.\n                step_between_clips (int): Number of frames between each clip.\n                fold (int, optional): Which fold to use. Should be between 1 and 3.\n                train (bool, optional): If ``True``, creates a dataset from the train split,\n                    otherwise from the ``test`` split.\n                transform (callable, optional): A function/transform that takes in a TxHxWxC video\n                    and returns a transformed version.\n                output_format (str, optional): The format of the output video tensors (before transforms).\n                    Can be either \"THWC\" (default) or \"TCHW\".\n\n            Returns:\n                tuple: A 3-tuple with the following entries:\n\n                    - video (Tensor[T, H, W, C] or Tensor[T, C, H, W]): The `T` video frames\n                    - audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n                      and `L` is the number of points\n                    - label (int): class of the video clip\n            \"\"\"\n         */\n    public :\n        explicit  HMDB51(const std::string &amp;root);\n        HMDB51(const std::string &amp;root, DataMode mode);\n        HMDB51(const std::string &amp;root, DataMode mode , bool download);\n        HMDB51(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n    private :\n        // data_url = \"https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\"\n        // splits = {\n        //         \"url\": \"https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\",\n        //         \"md5\": \"15e67781e70dcfbdce2d7dbb9b3344b5\",\n        // }\n\n        void load_data(DataMode mode = DataMode::TRAIN);\n\n        void check_resources(const std::string &amp;root, bool download = false);\n    };\n}\n</code></pre>"},{"location":"xTorch/kinetics_8h/","title":"File kinetics.h","text":"<p>FileList &gt; datasets &gt; video &gt; kinetics.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/kinetics_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/kinetics_8h/#classes","title":"Classes","text":"Type Name class Kinetics <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/kinetics.h</code></p>"},{"location":"xTorch/kinetics_8h_source/","title":"File kinetics.h","text":"<p>File List &gt; datasets &gt; video &gt; kinetics.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class Kinetics : BaseDataset {\n        /*\n        https://s3.amazonaws.com/kinetics\n            \"\"\"`Generic Kinetics &lt;https://www.deepmind.com/open-source/kinetics&gt;`_\n    dataset.\n\n    Kinetics-400/600/700 are action recognition video datasets.\n    This dataset consider every video as a collection of video clips of fixed size, specified\n    by ``frames_per_clip``, where the step in frames between each clip is given by\n    ``step_between_clips``.\n\n    To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n    and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n    elements will come from video 1, and the next three elements from video 2.\n    Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n    frames in a video might be present.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the Kinetics Dataset.\n            Directory should be structured as follows:\n            .. code::\n\n                root/\n                \u251c\u2500\u2500 split\n                \u2502   \u251c\u2500\u2500  class1\n                \u2502   \u2502   \u251c\u2500\u2500  vid1.mp4\n                \u2502   \u2502   \u251c\u2500\u2500  vid2.mp4\n                \u2502   \u2502   \u251c\u2500\u2500  vid3.mp4\n                \u2502   \u2502   \u251c\u2500\u2500  ...\n                \u2502   \u251c\u2500\u2500  class2\n                \u2502   \u2502   \u251c\u2500\u2500   vidx.mp4\n                \u2502   \u2502    \u2514\u2500\u2500 ...\n\n            Note: split is appended automatically using the split argument.\n        frames_per_clip (int): number of frames in a clip\n        num_classes (int): select between Kinetics-400 (default), Kinetics-600, and Kinetics-700\n        split (str): split of the dataset to consider; supports ``\"train\"`` (default) ``\"val\"`` ``\"test\"``\n        frame_rate (float): If omitted, interpolate different frame rate for each clip.\n        step_between_clips (int): number of frames between each clip\n        transform (callable, optional): A function/transform that takes in a TxHxWxC video\n            and returns a transformed version.\n        download (bool): Download the official version of the dataset to root folder.\n        num_workers (int): Use multiple workers for VideoClips creation\n        num_download_workers (int): Use multiprocessing in order to speed up download.\n        output_format (str, optional): The format of the output video tensors (before transforms).\n            Can be either \"THWC\" or \"TCHW\" (default).\n            Note that in most other utils and datasets, the default is actually \"THWC\".\n\n    Returns:\n        tuple: A 3-tuple with the following entries:\n\n            - video (Tensor[T, C, H, W] or Tensor[T, H, W, C]): the `T` video frames in torch.uint8 tensor\n            - audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n              and `L` is the number of points in torch.float tensor\n            - label (int): class of the video clip\n\n    Raises:\n        RuntimeError: If ``download is True`` and the video archives are already extracted.\n    \"\"\"\n\n\n         */\n    public :\n        explicit Kinetics(const std::string &amp;root);\n        Kinetics(const std::string &amp;root, DataMode mode);\n        Kinetics(const std::string &amp;root, DataMode mode , bool download);\n        Kinetics(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n    //     _TAR_URLS = {\n    //     \"400\": \"https://s3.amazonaws.com/kinetics/400/{split}/k400_{split}_path.txt\",\n    //     \"600\": \"https://s3.amazonaws.com/kinetics/600/{split}/k600_{split}_path.txt\",\n    //     \"700\": \"https://s3.amazonaws.com/kinetics/700_2020/{split}/k700_2020_{split}_path.txt\",\n    // }\n    //     _ANNOTATION_URLS = {\n    //     \"400\": \"https://s3.amazonaws.com/kinetics/400/annotations/{split}.csv\",\n    //     \"600\": \"https://s3.amazonaws.com/kinetics/600/annotations/{split}.csv\",\n    //     \"700\": \"https://s3.amazonaws.com/kinetics/700_2020/annotations/{split}.csv\",\n    // }\n\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/moving-mnist_8h/","title":"File moving-mnist.h","text":"<p>FileList &gt; datasets &gt; video &gt; moving-mnist.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/moving-mnist_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/moving-mnist_8h/#classes","title":"Classes","text":"Type Name class MovingMNIST <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/moving-mnist.h</code></p>"},{"location":"xTorch/moving-mnist_8h_source/","title":"File moving-mnist.h","text":"<p>File List &gt; datasets &gt; video &gt; moving-mnist.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n    class MovingMNIST : BaseDataset {\n        /*\n        \"\"\"`MovingMNIST &lt;http://www.cs.toronto.edu/~nitish/unsupervised_video/&gt;`_ Dataset.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of dataset where ``MovingMNIST/mnist_test_seq.npy`` exists.\n        split (string, optional): The dataset split, supports ``None`` (default), ``\"train\"`` and ``\"test\"``.\n            If ``split=None``, the full data is returned.\n        split_ratio (int, optional): The split ratio of number of frames. If ``split=\"train\"``, the first split\n            frames ``data[:, :split_ratio]`` is returned. If ``split=\"test\"``, the last split frames ``data[:, split_ratio:]``\n            is returned. If ``split=None``, this parameter is ignored and the all frames data is returned.\n        transform (callable, optional): A function/transform that takes in a torch Tensor\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n    \"\"\"\n\n         */\n    public :\n        explicit MovingMNIST(const std::string &amp;root);\n        MovingMNIST(const std::string &amp;root, DataMode mode);\n        MovingMNIST(const std::string &amp;root, DataMode mode , bool download);\n        MovingMNIST(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n\n    private :\n        fs::path url = fs::path(\"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\");\n        fs::path dataset_file_name = fs::path(\"mnist_test_seq.npy\");\n        string dataset_file_md5 = \"be083ec986bfe91a449d63653c411eb2\";\n        void load_data();\n\n        void check_resources();\n    };\n}\n</code></pre>"},{"location":"xTorch/ucf_8h/","title":"File ucf.h","text":"<p>FileList &gt; datasets &gt; video &gt; ucf.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../base/base.h\"</code></li> <li><code>#include \"../../headers/datasets.h\"</code></li> </ul>"},{"location":"xTorch/ucf_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace datasets"},{"location":"xTorch/ucf_8h/#classes","title":"Classes","text":"Type Name class UCF101 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/ucf.h</code></p>"},{"location":"xTorch/ucf_8h_source/","title":"File ucf.h","text":"<p>File List &gt; datasets &gt; video &gt; ucf.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"../base/base.h\"\n#include \"../../headers/datasets.h\"\n\n\nnamespace xt::data::datasets {\n   class UCF101 : public BaseDataset {\n       /*\n            \"\"\"\n    `UCF101 &lt;https://www.crcv.ucf.edu/data/UCF101.php&gt;`_ dataset.\n\n    UCF101 is an action recognition video dataset.\n    This dataset consider every video as a collection of video clips of fixed size, specified\n    by ``frames_per_clip``, where the step in frames between each clip is given by\n    ``step_between_clips``. The dataset itself can be downloaded from the dataset website;\n    annotations that ``annotation_path`` should be pointing to can be downloaded from `here\n    &lt;https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip&gt;`_.\n\n    To give an example, for 2 videos with 10 and 15 frames respectively, if ``frames_per_clip=5``\n    and ``step_between_clips=5``, the dataset size will be (2 + 3) = 5, where the first two\n    elements will come from video 1, and the next three elements from video 2.\n    Note that we drop clips which do not have exactly ``frames_per_clip`` elements, so not all\n    frames in a video might be present.\n\n    Internally, it uses a VideoClips object to handle clip creation.\n\n    Args:\n        root (str or ``pathlib.Path``): Root directory of the UCF101 Dataset.\n        annotation_path (str): path to the folder containing the split files;\n            see docstring above for download instructions of these files\n        frames_per_clip (int): number of frames in a clip.\n        step_between_clips (int, optional): number of frames between each clip.\n        fold (int, optional): which fold to use. Should be between 1 and 3.\n        train (bool, optional): if ``True``, creates a dataset from the train split,\n            otherwise from the ``test`` split.\n        transform (callable, optional): A function/transform that takes in a TxHxWxC video\n            and returns a transformed version.\n        output_format (str, optional): The format of the output video tensors (before transforms).\n            Can be either \"THWC\" (default) or \"TCHW\".\n\n    Returns:\n        tuple: A 3-tuple with the following entries:\n\n            - video (Tensor[T, H, W, C] or Tensor[T, C, H, W]): The `T` video frames\n            -  audio(Tensor[K, L]): the audio frames, where `K` is the number of channels\n               and `L` is the number of points\n            - label (int): class of the video clip\n    \"\"\"\n\n\n        */\n   public :\n       explicit UCF101(const std::string &amp;root);\n       UCF101(const std::string &amp;root, DataMode mode);\n       UCF101(const std::string &amp;root, DataMode mode , bool download);\n       UCF101(const std::string &amp;root, DataMode mode , bool download, TransformType transforms);\n\n   private :\n       void load_data();\n\n       void check_resources();\n\n\n    };\n}\n</code></pre>"},{"location":"xTorch/datasets_2video_2video_8h/","title":"File video.h","text":"<p>FileList &gt; datasets &gt; video &gt; video.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"hmdb.h\"</code></li> <li><code>#include \"kinetics.h\"</code></li> <li><code>#include \"moving-mnist.h\"</code></li> <li><code>#include \"ucf.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/video/video.h</code></p>"},{"location":"xTorch/datasets_2video_2video_8h_source/","title":"File video.h","text":"<p>File List &gt; datasets &gt; video &gt; video.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"hmdb.h\"\n#include \"kinetics.h\"\n#include \"moving-mnist.h\"\n#include \"ucf.h\"\n</code></pre>"},{"location":"xTorch/datasets_2datasets_8h/","title":"File datasets.h","text":"<p>FileList &gt; datasets &gt; datasets.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"audio-speech/audio-speech.h\"</code></li> <li><code>#include \"base/base.h\"</code></li> <li><code>#include \"definitions/definitions.h\"</code></li> <li><code>#include \"face-recognition/face-recognition.h\"</code></li> <li><code>#include \"general/general.h\"</code></li> <li><code>#include \"image-classification/image-classification.h\"</code></li> <li><code>#include \"language-modeling/language-modeling.h\"</code></li> <li><code>#include \"machine-translation/machine-translation.h\"</code></li> <li><code>#include \"natural-language-inference/natural-language-inference.h\"</code></li> <li><code>#include \"object-detection-and-segmentation/object-detection-and-segmentation.h\"</code></li> <li><code>#include \"optical-flow/optical-flow.h\"</code></li> <li><code>#include \"patch-matching-descriptor-learning/patch-matching-descriptor-learning.h\"</code></li> <li><code>#include \"scene-flow/scene-flow.h\"</code></li> <li><code>#include \"sentiment-analysis/sentiment-analysis.h\"</code></li> <li><code>#include \"sequence-tagging/sequence-tagging.h\"</code></li> <li><code>#include \"specific/specific.h\"</code></li> <li><code>#include \"stereo-matching-depth-estimation/stereo-matching-depth-estimation.h\"</code></li> <li><code>#include \"text-classification/text-classification.h\"</code></li> <li><code>#include \"video/video.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/datasets/datasets.h</code></p>"},{"location":"xTorch/datasets_2datasets_8h_source/","title":"File datasets.h","text":"<p>File List &gt; datasets &gt; datasets.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"audio-speech/audio-speech.h\"\n#include \"base/base.h\"\n#include \"definitions/definitions.h\"\n#include \"face-recognition/face-recognition.h\"\n#include \"general/general.h\"\n#include \"image-classification/image-classification.h\"\n#include \"language-modeling/language-modeling.h\"\n#include \"machine-translation/machine-translation.h\"\n#include \"natural-language-inference/natural-language-inference.h\"\n#include \"object-detection-and-segmentation/object-detection-and-segmentation.h\"\n#include \"optical-flow/optical-flow.h\"\n#include \"patch-matching-descriptor-learning/patch-matching-descriptor-learning.h\"\n#include \"scene-flow/scene-flow.h\"\n#include \"sentiment-analysis/sentiment-analysis.h\"\n#include \"sequence-tagging/sequence-tagging.h\"\n#include \"specific/specific.h\"\n#include \"stereo-matching-depth-estimation/stereo-matching-depth-estimation.h\"\n#include \"text-classification/text-classification.h\"\n#include \"video/video.h\"\n</code></pre>"},{"location":"xTorch/dir_11d78a78cbacc94abc067fbb8f3d9498/","title":"Dir /home/kami/Documents/cpp/models/include/definitions","text":"<p>FileList &gt; definitions</p>"},{"location":"xTorch/dir_11d78a78cbacc94abc067fbb8f3d9498/#files","title":"Files","text":"Type Name file transforms.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/definitions/</code></p>"},{"location":"xTorch/definitions_2transforms_8h/","title":"File transforms.h","text":"<p>FileList &gt; definitions &gt; transforms.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/definitions_2transforms_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/definitions/transforms.h</code></p>"},{"location":"xTorch/definitions_2transforms_8h_source/","title":"File transforms.h","text":"<p>File List &gt; definitions &gt; transforms.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../headers/transforms.h\"\n\n\nnamespace xt::data::transforms {\n    std::function&lt;torch::Tensor(torch::Tensor input)&gt; create_resize_transform(std::vector&lt;int64_t&gt; size);\n\n    torch::Tensor resize_tensor(const torch::Tensor &amp;tensor, const std::vector&lt;int64_t&gt; &amp;size);\n\n    torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; resize(std::vector&lt;int64_t&gt; size);\n\n    torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; normalize(double mean, double stddev);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n}\n</code></pre>"},{"location":"xTorch/dir_06ec884a0825782b323e4577406ae7aa/","title":"Dir /home/kami/Documents/cpp/models/include/exceptions","text":"<p>FileList &gt; exceptions</p>"},{"location":"xTorch/dir_06ec884a0825782b323e4577406ae7aa/#files","title":"Files","text":"Type Name file implementation.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/exceptions/</code></p>"},{"location":"xTorch/implementation_8h/","title":"File implementation.h","text":"<p>FileList &gt; exceptions &gt; implementation.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> </ul>"},{"location":"xTorch/implementation_8h/#classes","title":"Classes","text":"Type Name class NotImplementedException <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/exceptions/implementation.h</code></p>"},{"location":"xTorch/implementation_8h_source/","title":"File implementation.h","text":"<p>File List &gt; exceptions &gt; implementation.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;iostream&gt;\n\n\nclass NotImplementedException : public std::logic_error {\npublic:\n    NotImplementedException() : std::logic_error(\"Function not yet implemented\") {};\n};\n</code></pre>"},{"location":"xTorch/dir_8e6593a601935323ccb6c1a5a439ec0c/","title":"Dir /home/kami/Documents/cpp/models/include/headers","text":"<p>FileList &gt; headers</p>"},{"location":"xTorch/dir_8e6593a601935323ccb6c1a5a439ec0c/#files","title":"Files","text":"Type Name file datasets.h file transforms.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/headers/</code></p>"},{"location":"xTorch/headers_2datasets_8h/","title":"File datasets.h","text":"<p>FileList &gt; headers &gt; datasets.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;tuple&gt;</code></li> <li><code>#include &lt;map&gt;</code></li> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include \"../utils/downloader.h\"</code></li> <li><code>#include \"../utils/extract.h\"</code></li> <li><code>#include \"../utils/md5.h\"</code></li> <li><code>#include \"../exceptions/implementation.h\"</code></li> <li><code>#include \"../definitions/transforms.h\"</code></li> <li><code>#include \"../types/arguments.h\"</code></li> <li><code>#include \"../types/enums.h\"</code></li> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include \"../media/opencv/images.h\"</code></li> <li><code>#include \"../transforms/base/base.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/headers/datasets.h</code></p>"},{"location":"xTorch/headers_2datasets_8h_source/","title":"File datasets.h","text":"<p>File List &gt; headers &gt; datasets.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;fstream&gt;\n#include &lt;filesystem&gt;\n#include &lt;vector&gt;\n#include &lt;tuple&gt;\n#include &lt;map&gt;\n#include &lt;torch/torch.h&gt;\n#include \"../utils/downloader.h\"\n#include \"../utils/extract.h\"\n#include \"../utils/md5.h\"\n#include \"../exceptions/implementation.h\"\n#include \"../definitions/transforms.h\"\n#include \"../types/arguments.h\"\n#include \"../types/enums.h\"\n#include &lt;opencv2/opencv.hpp&gt;\n#include \"../media/opencv/images.h\"\n#include \"../transforms/base/base.h\"\n\n\n</code></pre>"},{"location":"xTorch/headers_2transforms_8h/","title":"File transforms.h","text":"<p>FileList &gt; headers &gt; transforms.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;torch/data/datasets/mnist.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;torch/data/transforms/base.h&gt;</code></li> <li><code>#include &lt;functional&gt;</code></li> <li><code>#include &lt;stdexcept&gt;</code></li> <li><code>#include &lt;cmath&gt;</code></li> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;random&gt;</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/headers/transforms.h</code></p>"},{"location":"xTorch/headers_2transforms_8h_source/","title":"File transforms.h","text":"<p>File List &gt; headers &gt; transforms.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;torch/torch.h&gt;\n#include &lt;torch/data/datasets/mnist.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;torch/data/transforms/base.h&gt;\n#include &lt;functional&gt;\n#include &lt;stdexcept&gt;\n#include &lt;cmath&gt;\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;random&gt;\n</code></pre>"},{"location":"xTorch/dir_aa03a1d12037901d4378cbd73498762d/","title":"Dir /home/kami/Documents/cpp/models/include/media","text":"<p>FileList &gt; include &gt; media</p>"},{"location":"xTorch/dir_aa03a1d12037901d4378cbd73498762d/#files","title":"Files","text":"Type Name file media.h"},{"location":"xTorch/dir_aa03a1d12037901d4378cbd73498762d/#directories","title":"Directories","text":"Type Name dir image dir opencv dir video <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/</code></p>"},{"location":"xTorch/dir_b86c9d22e47aa9431a2bbc5d6808d12b/","title":"Dir /home/kami/Documents/cpp/models/include/media/image","text":"<p>FileList &gt; image</p>"},{"location":"xTorch/dir_b86c9d22e47aa9431a2bbc5d6808d12b/#files","title":"Files","text":"Type Name file image.h file processing.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/</code></p>"},{"location":"xTorch/image_8h/","title":"File image.h","text":"<p>FileList &gt; image &gt; image.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"processing.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/image.h</code></p>"},{"location":"xTorch/image_8h_source/","title":"File image.h","text":"<p>File List &gt; image &gt; image.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include \"processing.h\"\n</code></pre>"},{"location":"xTorch/image_2processing_8h/","title":"File processing.h","text":"<p>FileList &gt; image &gt; processing.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;torch/torch.h&gt;</code></li> </ul>"},{"location":"xTorch/image_2processing_8h/#namespaces","title":"Namespaces","text":"Type Name namespace torch namespace ext namespace media namespace image <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/image/processing.h</code></p>"},{"location":"xTorch/image_2processing_8h_source/","title":"File processing.h","text":"<p>File List &gt; image &gt; processing.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;iostream&gt;\n#include &lt;torch/torch.h&gt;\n\n\nnamespace torch::ext::media::image {\n    torch::Tensor resize(const torch::Tensor &amp;tensor, const std::vector&lt;int64_t&gt; &amp;size);\n}\n</code></pre>"},{"location":"xTorch/dir_2b794fa5f0369c1c80752771b4d33858/","title":"Dir /home/kami/Documents/cpp/models/include/media/opencv","text":"<p>FileList &gt; include &gt; media &gt; opencv</p>"},{"location":"xTorch/dir_2b794fa5f0369c1c80752771b4d33858/#files","title":"Files","text":"Type Name file images.h file opencv.h file videos.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/opencv/</code></p>"},{"location":"xTorch/images_8h/","title":"File images.h","text":"<p>FileList &gt; include &gt; media &gt; opencv &gt; images.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;torch/torch.h&gt;</code></li> </ul>"},{"location":"xTorch/images_8h/#namespaces","title":"Namespaces","text":"Type Name namespace torch namespace ext namespace media namespace opencv <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/opencv/images.h</code></p>"},{"location":"xTorch/images_8h_source/","title":"File images.h","text":"<p>File List &gt; include &gt; media &gt; opencv &gt; images.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;iostream&gt;\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;filesystem&gt;\n#include &lt;torch/torch.h&gt;\nusing namespace std;\n\nnamespace fs = std::filesystem;\n\nnamespace torch::ext::media::opencv {\n\n    torch::Tensor convertImageToTensor(fs::path image ,vector&lt;int&gt; size = {0,0});\n\n\n\n}\n\n\n</code></pre>"},{"location":"xTorch/opencv_8h/","title":"File opencv.h","text":"<p>FileList &gt; include &gt; media &gt; opencv &gt; opencv.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"images.h\"</code></li> <li><code>#include \"videos.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/opencv/opencv.h</code></p>"},{"location":"xTorch/opencv_8h_source/","title":"File opencv.h","text":"<p>File List &gt; include &gt; media &gt; opencv &gt; opencv.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"images.h\"\n#include \"videos.h\"\n</code></pre>"},{"location":"xTorch/videos_8h/","title":"File videos.h","text":"<p>FileList &gt; include &gt; media &gt; opencv &gt; videos.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;opencv2/opencv.hpp&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> </ul>"},{"location":"xTorch/videos_8h/#namespaces","title":"Namespaces","text":"Type Name namespace torch namespace ext namespace media namespace opencv namespace videos <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/opencv/videos.h</code></p>"},{"location":"xTorch/videos_8h_source/","title":"File videos.h","text":"<p>File List &gt; include &gt; media &gt; opencv &gt; videos.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;iostream&gt;\n#include &lt;opencv2/opencv.hpp&gt;\n#include &lt;filesystem&gt;\n#include &lt;torch/torch.h&gt;\n#include &lt;string&gt;\n#include &lt;vector&gt;\n\nusing namespace std;\n\nnamespace fs = std::filesystem;\n\nnamespace torch::ext::media::opencv::videos {\n    std::vector&lt;cv::Mat&gt;  extractFrames(const std::string&amp; videoFilePath);\n    std::vector&lt;torch::Tensor&gt; extractVideoFramesAsTensor(fs::path videoFilePath);\n}\n</code></pre>"},{"location":"xTorch/dir_107604769d8a5525c826381ab1dce444/","title":"Dir /home/kami/Documents/cpp/models/include/media/video","text":"<p>FileList &gt; include &gt; media &gt; video</p>"},{"location":"xTorch/dir_107604769d8a5525c826381ab1dce444/#files","title":"Files","text":"Type Name file processing.h file video.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/video/</code></p>"},{"location":"xTorch/video_2processing_8h/","title":"File processing.h","text":"<p>FileList &gt; include &gt; media &gt; video &gt; processing.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/video/processing.h</code></p>"},{"location":"xTorch/video_2processing_8h_source/","title":"File processing.h","text":"<p>File List &gt; include &gt; media &gt; video &gt; processing.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n</code></pre>"},{"location":"xTorch/media_2video_2video_8h/","title":"File video.h","text":"<p>FileList &gt; include &gt; media &gt; video &gt; video.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"processing.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/video/video.h</code></p>"},{"location":"xTorch/media_2video_2video_8h_source/","title":"File video.h","text":"<p>File List &gt; include &gt; media &gt; video &gt; video.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"processing.h\"\n</code></pre>"},{"location":"xTorch/media_8h/","title":"File media.h","text":"<p>FileList &gt; include &gt; media &gt; media.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"image/image.h\"</code></li> <li><code>#include \"opencv/opencv.h\"</code></li> <li><code>#include \"video/video.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/media/media.h</code></p>"},{"location":"xTorch/media_8h_source/","title":"File media.h","text":"<p>File List &gt; include &gt; media &gt; media.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"image/image.h\"\n#include \"opencv/opencv.h\"\n#include \"video/video.h\"\n</code></pre>"},{"location":"xTorch/dir_828b612f8450ccb3091aade92090c8e3/","title":"Dir /home/kami/Documents/cpp/models/include/models","text":"<p>FileList &gt; include &gt; models</p>"},{"location":"xTorch/dir_828b612f8450ccb3091aade92090c8e3/#files","title":"Files","text":"Type Name file base.h file models.h"},{"location":"xTorch/dir_828b612f8450ccb3091aade92090c8e3/#directories","title":"Directories","text":"Type Name dir cnn <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/</code></p>"},{"location":"xTorch/dir_40be95ab8912b8deac694fbe2f8f2654/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn","text":"<p>FileList &gt; cnn</p>"},{"location":"xTorch/dir_40be95ab8912b8deac694fbe2f8f2654/#files","title":"Files","text":"Type Name file cnn.h"},{"location":"xTorch/dir_40be95ab8912b8deac694fbe2f8f2654/#directories","title":"Directories","text":"Type Name dir alexnet dir dense-net dir efficient-net dir inception dir lenet dir mobilenet dir nas-net dir reg-net dir resnet dir shuffle-net dir squeeze-net dir unet dir vggnet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/</code></p>"},{"location":"xTorch/dir_3b7157f900ab20c97880c9a0f5c25c82/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/alexnet","text":"<p>FileList &gt; alexnet</p>"},{"location":"xTorch/dir_3b7157f900ab20c97880c9a0f5c25c82/#files","title":"Files","text":"Type Name file alexnet.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/alexnet/</code></p>"},{"location":"xTorch/alexnet_8h/","title":"File alexnet.h","text":"<p>FileList &gt; alexnet &gt; alexnet.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/alexnet_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/alexnet_8h/#classes","title":"Classes","text":"Type Name struct AlexNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/alexnet/alexnet.h</code></p>"},{"location":"xTorch/alexnet_8h_source/","title":"File alexnet.h","text":"<p>File List &gt; alexnet &gt; alexnet.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\n\nnamespace xt::models {\n    struct AlexNet : BaseModel {\n        mutable torch::nn::Sequential layer1 = nullptr, layer2 = nullptr, layer3 = nullptr, layer4 = nullptr, layer5 =\n                        nullptr;\n        mutable torch::nn::Sequential fc = nullptr, fc1 = nullptr, fc2 = nullptr;\n\n    public:\n        AlexNet(int num_classes /* classes */, int in_channels = 3/* input channels */);\n\n        AlexNet(int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_45ae9a97fc80830746290ec1b5654b3d/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/dense-net","text":"<p>FileList &gt; cnn &gt; dense-net</p>"},{"location":"xTorch/dir_45ae9a97fc80830746290ec1b5654b3d/#files","title":"Files","text":"Type Name file dense-net-121.h file dense-net-169.h file dense-net-201.h file dense-net-264.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/dense-net/</code></p>"},{"location":"xTorch/dense-net-121_8h/","title":"File dense-net-121.h","text":"<p>FileList &gt; cnn &gt; dense-net &gt; dense-net-121.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/dense-net/dense-net-121.h</code></p>"},{"location":"xTorch/dense-net-121_8h_source/","title":"File dense-net-121.h","text":"<p>File List &gt; cnn &gt; dense-net &gt; dense-net-121.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef DENSE_NET_121_H\n#define DENSE_NET_121_H\n\n#endif //DENSE_NET_121_H\n</code></pre>"},{"location":"xTorch/dense-net-169_8h/","title":"File dense-net-169.h","text":"<p>FileList &gt; cnn &gt; dense-net &gt; dense-net-169.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/dense-net/dense-net-169.h</code></p>"},{"location":"xTorch/dense-net-169_8h_source/","title":"File dense-net-169.h","text":"<p>File List &gt; cnn &gt; dense-net &gt; dense-net-169.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef DENSE_NET_169_H\n#define DENSE_NET_169_H\n\n#endif //DENSE_NET_169_H\n</code></pre>"},{"location":"xTorch/dense-net-201_8h/","title":"File dense-net-201.h","text":"<p>FileList &gt; cnn &gt; dense-net &gt; dense-net-201.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/dense-net/dense-net-201.h</code></p>"},{"location":"xTorch/dense-net-201_8h_source/","title":"File dense-net-201.h","text":"<p>File List &gt; cnn &gt; dense-net &gt; dense-net-201.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef DENSE_NET_201_H\n#define DENSE_NET_201_H\n\n#endif //DENSE_NET_201_H\n</code></pre>"},{"location":"xTorch/dense-net-264_8h/","title":"File dense-net-264.h","text":"<p>FileList &gt; cnn &gt; dense-net &gt; dense-net-264.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/dense-net/dense-net-264.h</code></p>"},{"location":"xTorch/dense-net-264_8h_source/","title":"File dense-net-264.h","text":"<p>File List &gt; cnn &gt; dense-net &gt; dense-net-264.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef DENSE_NET_264_H\n#define DENSE_NET_264_H\n\n#endif //DENSE_NET_264_H\n</code></pre>"},{"location":"xTorch/dir_430257895ecd3668c9128fdd3dfcb853/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/efficient-net","text":"<p>FileList &gt; cnn &gt; efficient-net</p>"},{"location":"xTorch/dir_430257895ecd3668c9128fdd3dfcb853/#files","title":"Files","text":"Type Name file efficient-net-b0.h file efficient-net-b1.h file efficient-net-b2.h file efficient-net-b3.h file efficient-net-b4.h file efficient-net-b5.h file efficient-net-b6.h file efficient-net-b7.h file efficient-net-v2.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/</code></p>"},{"location":"xTorch/efficient-net-b0_8h/","title":"File efficient-net-b0.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b0.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b0.h</code></p>"},{"location":"xTorch/efficient-net-b0_8h_source/","title":"File efficient-net-b0.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b0.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B0_H\n#define EFFICIENT_NET_B0_H\n\n#endif //EFFICIENT_NET_B0_H\n</code></pre>"},{"location":"xTorch/efficient-net-b1_8h/","title":"File efficient-net-b1.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b1.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b1.h</code></p>"},{"location":"xTorch/efficient-net-b1_8h_source/","title":"File efficient-net-b1.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b1.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B1_H\n#define EFFICIENT_NET_B1_H\n\n#endif //EFFICIENT_NET_B1_H\n</code></pre>"},{"location":"xTorch/efficient-net-b2_8h/","title":"File efficient-net-b2.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b2.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b2.h</code></p>"},{"location":"xTorch/efficient-net-b2_8h_source/","title":"File efficient-net-b2.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b2.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B2_H\n#define EFFICIENT_NET_B2_H\n\n#endif //EFFICIENT_NET_B2_H\n</code></pre>"},{"location":"xTorch/efficient-net-b3_8h/","title":"File efficient-net-b3.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b3.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b3.h</code></p>"},{"location":"xTorch/efficient-net-b3_8h_source/","title":"File efficient-net-b3.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b3.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B3_H\n#define EFFICIENT_NET_B3_H\n\n#endif //EFFICIENT_NET_B3_H\n</code></pre>"},{"location":"xTorch/efficient-net-b4_8h/","title":"File efficient-net-b4.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b4.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b4.h</code></p>"},{"location":"xTorch/efficient-net-b4_8h_source/","title":"File efficient-net-b4.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b4.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B4_H\n#define EFFICIENT_NET_B4_H\n\n#endif //EFFICIENT_NET_B4_H\n</code></pre>"},{"location":"xTorch/efficient-net-b5_8h/","title":"File efficient-net-b5.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b5.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b5.h</code></p>"},{"location":"xTorch/efficient-net-b5_8h_source/","title":"File efficient-net-b5.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b5.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B5_H\n#define EFFICIENT_NET_B5_H\n\n#endif //EFFICIENT_NET_B5_H\n</code></pre>"},{"location":"xTorch/efficient-net-b6_8h/","title":"File efficient-net-b6.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b6.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b6.h</code></p>"},{"location":"xTorch/efficient-net-b6_8h_source/","title":"File efficient-net-b6.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b6.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B6_H\n#define EFFICIENT_NET_B6_H\n\n#endif //EFFICIENT_NET_B6_H\n</code></pre>"},{"location":"xTorch/efficient-net-b7_8h/","title":"File efficient-net-b7.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-b7.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-b7.h</code></p>"},{"location":"xTorch/efficient-net-b7_8h_source/","title":"File efficient-net-b7.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-b7.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_B7_H\n#define EFFICIENT_NET_B7_H\n\n#endif //EFFICIENT_NET_B7_H\n</code></pre>"},{"location":"xTorch/efficient-net-v2_8h/","title":"File efficient-net-v2.h","text":"<p>FileList &gt; cnn &gt; efficient-net &gt; efficient-net-v2.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/efficient-net/efficient-net-v2.h</code></p>"},{"location":"xTorch/efficient-net-v2_8h_source/","title":"File efficient-net-v2.h","text":"<p>File List &gt; cnn &gt; efficient-net &gt; efficient-net-v2.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef EFFICIENT_NET_V2_H\n#define EFFICIENT_NET_V2_H\n\n#endif //EFFICIENT_NET_V2_H\n</code></pre>"},{"location":"xTorch/dir_b2aa8ff22ef72860ed32a476dd9404fe/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/inception","text":"<p>FileList &gt; cnn &gt; inception</p>"},{"location":"xTorch/dir_b2aa8ff22ef72860ed32a476dd9404fe/#files","title":"Files","text":"Type Name file inception-rsnet.h file inception-v1.h file inception-v2.h file inception-v3.h file inception-v4.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/inception/</code></p>"},{"location":"xTorch/inception-rsnet_8h/","title":"File inception-rsnet.h","text":"<p>FileList &gt; cnn &gt; inception &gt; inception-rsnet.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/inception/inception-rsnet.h</code></p>"},{"location":"xTorch/inception-rsnet_8h_source/","title":"File inception-rsnet.h","text":"<p>File List &gt; cnn &gt; inception &gt; inception-rsnet.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef INCEPTION_V1_H\n#define INCEPTION_V1_H\n\n#endif //INCEPTION_V1_H\n</code></pre>"},{"location":"xTorch/inception-v1_8h/","title":"File inception-v1.h","text":"<p>FileList &gt; cnn &gt; inception &gt; inception-v1.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/inception/inception-v1.h</code></p>"},{"location":"xTorch/inception-v1_8h_source/","title":"File inception-v1.h","text":"<p>File List &gt; cnn &gt; inception &gt; inception-v1.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef INCEPTION_V1_H\n#define INCEPTION_V1_H\n\n#endif //INCEPTION_V1_H\n</code></pre>"},{"location":"xTorch/inception-v2_8h/","title":"File inception-v2.h","text":"<p>FileList &gt; cnn &gt; inception &gt; inception-v2.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/inception/inception-v2.h</code></p>"},{"location":"xTorch/inception-v2_8h_source/","title":"File inception-v2.h","text":"<p>File List &gt; cnn &gt; inception &gt; inception-v2.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef INCEPTION_V1_H\n#define INCEPTION_V1_H\n\n#endif //INCEPTION_V1_H\n</code></pre>"},{"location":"xTorch/inception-v3_8h/","title":"File inception-v3.h","text":"<p>FileList &gt; cnn &gt; inception &gt; inception-v3.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/inception/inception-v3.h</code></p>"},{"location":"xTorch/inception-v3_8h_source/","title":"File inception-v3.h","text":"<p>File List &gt; cnn &gt; inception &gt; inception-v3.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef INCEPTION_V1_H\n#define INCEPTION_V1_H\n\n#endif //INCEPTION_V1_H\n</code></pre>"},{"location":"xTorch/inception-v4_8h/","title":"File inception-v4.h","text":"<p>FileList &gt; cnn &gt; inception &gt; inception-v4.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/inception/inception-v4.h</code></p>"},{"location":"xTorch/inception-v4_8h_source/","title":"File inception-v4.h","text":"<p>File List &gt; cnn &gt; inception &gt; inception-v4.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef INCEPTION_V1_H\n#define INCEPTION_V1_H\n\n#endif //INCEPTION_V1_H\n</code></pre>"},{"location":"xTorch/dir_7143ffcf272660e648740977d1bb606b/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/lenet","text":"<p>FileList &gt; cnn &gt; lenet</p>"},{"location":"xTorch/dir_7143ffcf272660e648740977d1bb606b/#files","title":"Files","text":"Type Name file lenet5.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/lenet/</code></p>"},{"location":"xTorch/lenet5_8h/","title":"File lenet5.h","text":"<p>FileList &gt; cnn &gt; lenet &gt; lenet5.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> </ul>"},{"location":"xTorch/lenet5_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/lenet5_8h/#classes","title":"Classes","text":"Type Name struct LeNet5 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/lenet/lenet5.h</code></p>"},{"location":"xTorch/lenet5_8h_source/","title":"File lenet5.h","text":"<p>File List &gt; cnn &gt; lenet &gt; lenet5.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include \"../../base.h\"\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\n\nusing namespace std;\n\nnamespace xt::models {\n    struct LeNet5 : BaseModel {\n    protected:\n        mutable  torch::nn::Sequential layer1 = nullptr, layer2 = nullptr;\n        mutable  torch::nn::Linear fc1 = nullptr, fc2 = nullptr, fc3 = nullptr;\n\n    public:\n        LeNet5(int num_classes/* classes */, int in_channels = 1/*  input channels */);\n        LeNet5(int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_a57691a5251d223bcea69c863aa2200a/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/mobilenet","text":"<p>FileList &gt; cnn &gt; mobilenet</p>"},{"location":"xTorch/dir_a57691a5251d223bcea69c863aa2200a/#files","title":"Files","text":"Type Name file mobilenet-v1.h file mobilenet-v2.h file mobilenet-v3.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/</code></p>"},{"location":"xTorch/mobilenet-v1_8h/","title":"File mobilenet-v1.h","text":"<p>FileList &gt; cnn &gt; mobilenet &gt; mobilenet-v1.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/mobilenet-v1_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/mobilenet-v1_8h/#classes","title":"Classes","text":"Type Name struct Bottleneck struct HSigmoid struct HSwish struct MobileNetV3 struct SqueezeExcite <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v1.h</code></p>"},{"location":"xTorch/mobilenet-v1_8h_source/","title":"File mobilenet-v1.h","text":"<p>File List &gt; cnn &gt; mobilenet &gt; mobilenet-v1.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nnamespace xt::models {\n    //class HSigmoid(nn.Module):\n    //    def __init__(self):\n    //        \"\"\"Hard Sigmoid activation function.\"\"\"\n    //        super().__init__()\n    //        self.relu6 = nn.ReLU6(inplace=True)\n    //\n    //    def forward(self, x):\n    //        x = self.relu6(x + 3) / 6\n    //        return x\n    struct HSigmoid : torch::nn::Module {\n    public:\n        HSigmoid();\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::ReLU6 relu6;\n    };\n\n    //---------------------------------------------------------------------------\n\n    //class HSwish(nn.Module):\n    //    def __init__(self):\n    //        \"\"\"Hard Swish activation function.\"\"\"\n    //        super().__init__()\n    //        self.relu6 = nn.ReLU6(inplace=True)\n    //\n    //    def forward(self, x):\n    //        x = x * self.relu6(x + 3) / 6\n    //        return x\n    //\n    //\n    struct HSwish : torch::nn::Module {\n    public:\n        HSwish();\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::ReLU6 relu6;\n    };\n\n    //---------------------------------------------------------------------------\n\n    //class SqueezeExcite(nn.Module):\n    //    def __init__(self,input_channels: int,squeeze: int = 4,) -&gt; None:\n    //        \"\"\"\n    //        Squeeze-and-Excitation block.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        squeeze (`int`, optional): Squeeze ratio. Defaults to 4.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.SE = nn.Sequential(\n    //                nn.AdaptiveAvgPool2d(output_size=1),\n    //                nn.Conv2d(input_channels, out_channels=input_channels//squeeze, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(input_channels//squeeze),\n    //        nn.ReLU(inplace=True),\n    //        nn.Conv2d(input_channels//squeeze, input_channels, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(input_channels),\n    //                HSigmoid(),\n    //        )\n    //\n    //    def forward(self, x):\n    //        x = x * self.SE(x)\n    //        return x\n\n    struct SqueezeExcite : torch::nn::Module {\n    public:\n        SqueezeExcite(int input_channels, int squeeze = 4);\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential SE = nullptr;\n    };\n\n\n    //---------------------------------------------------------------------------\n\n    //class Bottleneck(nn.Module):\n    //    def __init__(self,input_channels: int,kernel: int,stride: int,expansion: int,output_channels: int,activation: nn.Module,se: bool = False,) -&gt; None:\n    //        \"\"\"\n    //        MobileNetV3 bottleneck block.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        kernel (`int`): Convolution kernel size.\n    //        stride (`int`): Convolution stride.\n    //        expansion (`int`): Expansion size, indicating the middle layer's output channels.\n    //        output_channels (`int`): Number of final output channels.\n    //        activation (`nn.Module`): Activation function.\n    //        se (`bool`, optional): Whether to use Squeeze-and-Excitation. Defaults to False.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.bottleneck = nn.Sequential(\n    //        # expansion\n    //                nn.Conv2d(input_channels, expansion, kernel_size=1, stride=1, bias=False),\n    //                nn.BatchNorm2d(expansion),\n    //                activation,\n    //\n    //        # depth-wise convolution\n    //                nn.Conv2d(expansion, expansion, kernel_size=kernel, stride=stride, padding=kernel//2, groups=expansion, bias=False),\n    //        nn.BatchNorm2d(expansion),\n    //                activation,\n    //\n    //        # squeeze-and-excite\n    //                SqueezeExcite(expansion) if se else nn.Identity(),\n    //\n    //        # point-wise convolution\n    //                nn.Conv2d(expansion, output_channels, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(output_channels),\n    //                activation,\n    //        )\n    //\n    //        # for residual skip connecting when the input size is different from output size\n    //        self.downsample = None if input_channels == output_channels and stride == 1 else nn.Sequential(\n    //                nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=stride, bias=False),\n    //        nn.BatchNorm2d(output_channels),\n    //        )\n    //\n    //\n    //    def forward(self, x):\n    //        residual = x\n    //        output = self.bottleneck(x)\n    //\n    //        if self.downsample:\n    //        residual = self.downsample(x)\n    //\n    //        output = output + residual\n    //\n    //        return output\n\n    struct Bottleneck : torch::nn::Module {\n    public:\n        Bottleneck(int input_channels, int kernel, int stride, int expansion, int output_channels,\n                   torch::nn::Module activation, bool se = false);\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential bottleneck;\n        torch::nn::Sequential downsample;\n    };\n\n\n    //---------------------------------------------------------------------------\n\n\n    //class MobileNetV3(nn.Module):\n    //    def __init__(self,input_channels: int,num_classes: int,dropout_prob: float = 0.5,) -&gt; None:\n    //        \"\"\"\n    //        MobileNetV3 (Large) model.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        num_classes (`int`): Number of classes.\n    //        dropout_prob (`float`, optional): Dropout probability. Defaults to 0.5.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.initial_conv = nn.Sequential(\n    //                nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3, stride=2),\n    //                nn.BatchNorm2d(16),\n    //                HSwish(),\n    //        )\n    //\n    //        self.bottlenecks = nn.Sequential(\n    //                Bottleneck(input_channels=16, kernel=3, stride=1, expansion=16, output_channels=16, activation=nn.ReLU(inplace=True)),\n    //                Bottleneck(input_channels=16, kernel=3, stride=2, expansion=64, output_channels=24, activation=nn.ReLU(inplace=True)),\n    //                Bottleneck(input_channels=24, kernel=3, stride=1, expansion=72, output_channels=24, activation=nn.ReLU(inplace=True)),\n\n    //                Bottleneck(input_channels=24, kernel=5, stride=2, expansion=72, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n    //                Bottleneck(input_channels=40, kernel=5, stride=1, expansion=120, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n    //                Bottleneck(input_channels=40, kernel=5, stride=1, expansion=120, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n\n\n    //                Bottleneck(input_channels=40, kernel=3, stride=2, expansion=240, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=200, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=184, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=184, output_channels=80, activation=HSwish()),\n\n\n\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=480, output_channels=112, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=112, kernel=3, stride=1, expansion=672, output_channels=112, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=112, kernel=5, stride=2, expansion=672, output_channels=160, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=160, kernel=5, stride=1, expansion=960, output_channels=160, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=160, kernel=5, stride=1, expansion=960, output_channels=160, activation=HSwish(), se=True),\n    //        )\n    //\n    //        self.final_conv = nn.Sequential(\n    //                nn.Conv2d(in_channels=160, out_channels=960, kernel_size=1, stride=1, bias=False),\n    //                nn.BatchNorm2d(960),\n    //                HSwish(),\n    //        )\n    //\n    //        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n    //\n    //        self.classifier = nn.Sequential(\n    //                nn.Linear(960, 1280),\n    //                HSwish(),\n    //                nn.Dropout(p=dropout_prob, inplace=True),\n    //                nn.Linear(1280, num_classes),\n    //        )\n    //\n    //    def forward(self, x):\n    //        x = self.initial_conv(x)\n    //        x = self.bottlenecks(x)\n    //        x = self.final_conv(x)\n    //        x = self.pool(x)\n    //        x = torch.flatten(x, 1)\n    //        x = self.classifier(x)\n    //        return x\n\n    struct MobileNetV3 : BaseModel {\n    public:\n        MobileNetV3(int input_channels, int num_classes, float dropout_prob = 0.5);\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential initial_conv;\n        torch::nn::Sequential bottlenecks;\n        torch::nn::Sequential final_conv;\n        torch::nn::AdaptiveAvgPool2d pool;\n        torch::nn::Sequential classifier;\n    };\n}\n</code></pre>"},{"location":"xTorch/mobilenet-v2_8h/","title":"File mobilenet-v2.h","text":"<p>FileList &gt; cnn &gt; mobilenet &gt; mobilenet-v2.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/mobilenet-v2_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/mobilenet-v2_8h/#classes","title":"Classes","text":"Type Name struct Bottleneck struct HSigmoid struct HSwish struct MobileNetV3 struct SqueezeExcite <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v2.h</code></p>"},{"location":"xTorch/mobilenet-v2_8h_source/","title":"File mobilenet-v2.h","text":"<p>File List &gt; cnn &gt; mobilenet &gt; mobilenet-v2.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nnamespace xt::models {\n    //class HSigmoid(nn.Module):\n    //    def __init__(self):\n    //        \"\"\"Hard Sigmoid activation function.\"\"\"\n    //        super().__init__()\n    //        self.relu6 = nn.ReLU6(inplace=True)\n    //\n    //    def forward(self, x):\n    //        x = self.relu6(x + 3) / 6\n    //        return x\n    struct HSigmoid : torch::nn::Module {\n    public:\n        HSigmoid();\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::ReLU6 relu6;\n    };\n\n    //---------------------------------------------------------------------------\n\n    //class HSwish(nn.Module):\n    //    def __init__(self):\n    //        \"\"\"Hard Swish activation function.\"\"\"\n    //        super().__init__()\n    //        self.relu6 = nn.ReLU6(inplace=True)\n    //\n    //    def forward(self, x):\n    //        x = x * self.relu6(x + 3) / 6\n    //        return x\n    //\n    //\n    struct HSwish : torch::nn::Module {\n    public:\n        HSwish();\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::ReLU6 relu6;\n    };\n\n    //---------------------------------------------------------------------------\n\n    //class SqueezeExcite(nn.Module):\n    //    def __init__(self,input_channels: int,squeeze: int = 4,) -&gt; None:\n    //        \"\"\"\n    //        Squeeze-and-Excitation block.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        squeeze (`int`, optional): Squeeze ratio. Defaults to 4.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.SE = nn.Sequential(\n    //                nn.AdaptiveAvgPool2d(output_size=1),\n    //                nn.Conv2d(input_channels, out_channels=input_channels//squeeze, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(input_channels//squeeze),\n    //        nn.ReLU(inplace=True),\n    //        nn.Conv2d(input_channels//squeeze, input_channels, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(input_channels),\n    //                HSigmoid(),\n    //        )\n    //\n    //    def forward(self, x):\n    //        x = x * self.SE(x)\n    //        return x\n\n    struct SqueezeExcite : torch::nn::Module {\n    public:\n        SqueezeExcite(int input_channels, int squeeze = 4);\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential SE = nullptr;\n    };\n\n\n    //---------------------------------------------------------------------------\n\n    //class Bottleneck(nn.Module):\n    //    def __init__(self,input_channels: int,kernel: int,stride: int,expansion: int,output_channels: int,activation: nn.Module,se: bool = False,) -&gt; None:\n    //        \"\"\"\n    //        MobileNetV3 bottleneck block.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        kernel (`int`): Convolution kernel size.\n    //        stride (`int`): Convolution stride.\n    //        expansion (`int`): Expansion size, indicating the middle layer's output channels.\n    //        output_channels (`int`): Number of final output channels.\n    //        activation (`nn.Module`): Activation function.\n    //        se (`bool`, optional): Whether to use Squeeze-and-Excitation. Defaults to False.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.bottleneck = nn.Sequential(\n    //        # expansion\n    //                nn.Conv2d(input_channels, expansion, kernel_size=1, stride=1, bias=False),\n    //                nn.BatchNorm2d(expansion),\n    //                activation,\n    //\n    //        # depth-wise convolution\n    //                nn.Conv2d(expansion, expansion, kernel_size=kernel, stride=stride, padding=kernel//2, groups=expansion, bias=False),\n    //        nn.BatchNorm2d(expansion),\n    //                activation,\n    //\n    //        # squeeze-and-excite\n    //                SqueezeExcite(expansion) if se else nn.Identity(),\n    //\n    //        # point-wise convolution\n    //                nn.Conv2d(expansion, output_channels, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(output_channels),\n    //                activation,\n    //        )\n    //\n    //        # for residual skip connecting when the input size is different from output size\n    //        self.downsample = None if input_channels == output_channels and stride == 1 else nn.Sequential(\n    //                nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=stride, bias=False),\n    //        nn.BatchNorm2d(output_channels),\n    //        )\n    //\n    //\n    //    def forward(self, x):\n    //        residual = x\n    //        output = self.bottleneck(x)\n    //\n    //        if self.downsample:\n    //        residual = self.downsample(x)\n    //\n    //        output = output + residual\n    //\n    //        return output\n\n    struct Bottleneck : torch::nn::Module {\n    public:\n        Bottleneck(int input_channels, int kernel, int stride, int expansion, int output_channels,\n                   torch::nn::Module activation, bool se = false);\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential bottleneck;\n        torch::nn::Sequential downsample;\n    };\n\n\n    //---------------------------------------------------------------------------\n\n\n    //class MobileNetV3(nn.Module):\n    //    def __init__(self,input_channels: int,num_classes: int,dropout_prob: float = 0.5,) -&gt; None:\n    //        \"\"\"\n    //        MobileNetV3 (Large) model.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        num_classes (`int`): Number of classes.\n    //        dropout_prob (`float`, optional): Dropout probability. Defaults to 0.5.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.initial_conv = nn.Sequential(\n    //                nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3, stride=2),\n    //                nn.BatchNorm2d(16),\n    //                HSwish(),\n    //        )\n    //\n    //        self.bottlenecks = nn.Sequential(\n    //                Bottleneck(input_channels=16, kernel=3, stride=1, expansion=16, output_channels=16, activation=nn.ReLU(inplace=True)),\n    //                Bottleneck(input_channels=16, kernel=3, stride=2, expansion=64, output_channels=24, activation=nn.ReLU(inplace=True)),\n    //                Bottleneck(input_channels=24, kernel=3, stride=1, expansion=72, output_channels=24, activation=nn.ReLU(inplace=True)),\n\n    //                Bottleneck(input_channels=24, kernel=5, stride=2, expansion=72, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n    //                Bottleneck(input_channels=40, kernel=5, stride=1, expansion=120, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n    //                Bottleneck(input_channels=40, kernel=5, stride=1, expansion=120, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n\n\n    //                Bottleneck(input_channels=40, kernel=3, stride=2, expansion=240, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=200, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=184, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=184, output_channels=80, activation=HSwish()),\n\n\n\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=480, output_channels=112, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=112, kernel=3, stride=1, expansion=672, output_channels=112, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=112, kernel=5, stride=2, expansion=672, output_channels=160, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=160, kernel=5, stride=1, expansion=960, output_channels=160, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=160, kernel=5, stride=1, expansion=960, output_channels=160, activation=HSwish(), se=True),\n    //        )\n    //\n    //        self.final_conv = nn.Sequential(\n    //                nn.Conv2d(in_channels=160, out_channels=960, kernel_size=1, stride=1, bias=False),\n    //                nn.BatchNorm2d(960),\n    //                HSwish(),\n    //        )\n    //\n    //        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n    //\n    //        self.classifier = nn.Sequential(\n    //                nn.Linear(960, 1280),\n    //                HSwish(),\n    //                nn.Dropout(p=dropout_prob, inplace=True),\n    //                nn.Linear(1280, num_classes),\n    //        )\n    //\n    //    def forward(self, x):\n    //        x = self.initial_conv(x)\n    //        x = self.bottlenecks(x)\n    //        x = self.final_conv(x)\n    //        x = self.pool(x)\n    //        x = torch.flatten(x, 1)\n    //        x = self.classifier(x)\n    //        return x\n\n    struct MobileNetV3 : BaseModel {\n    public:\n        MobileNetV3(int input_channels, int num_classes, float dropout_prob = 0.5);\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential initial_conv;\n        torch::nn::Sequential bottlenecks;\n        torch::nn::Sequential final_conv;\n        torch::nn::AdaptiveAvgPool2d pool;\n        torch::nn::Sequential classifier;\n    };\n}\n</code></pre>"},{"location":"xTorch/mobilenet-v3_8h/","title":"File mobilenet-v3.h","text":"<p>FileList &gt; cnn &gt; mobilenet &gt; mobilenet-v3.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/mobilenet-v3_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/mobilenet-v3_8h/#classes","title":"Classes","text":"Type Name struct Bottleneck struct HSigmoid struct HSwish struct MobileNetV3 struct SqueezeExcite <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/mobilenet/mobilenet-v3.h</code></p>"},{"location":"xTorch/mobilenet-v3_8h_source/","title":"File mobilenet-v3.h","text":"<p>File List &gt; cnn &gt; mobilenet &gt; mobilenet-v3.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nnamespace xt::models {\n    //class HSigmoid(nn.Module):\n    //    def __init__(self):\n    //        \"\"\"Hard Sigmoid activation function.\"\"\"\n    //        super().__init__()\n    //        self.relu6 = nn.ReLU6(inplace=True)\n    //\n    //    def forward(self, x):\n    //        x = self.relu6(x + 3) / 6\n    //        return x\n    struct HSigmoid : torch::nn::Module {\n    public:\n        HSigmoid();\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::ReLU6 relu6;\n    };\n\n    //---------------------------------------------------------------------------\n\n    //class HSwish(nn.Module):\n    //    def __init__(self):\n    //        \"\"\"Hard Swish activation function.\"\"\"\n    //        super().__init__()\n    //        self.relu6 = nn.ReLU6(inplace=True)\n    //\n    //    def forward(self, x):\n    //        x = x * self.relu6(x + 3) / 6\n    //        return x\n    //\n    //\n    struct HSwish : torch::nn::Module {\n    public:\n        HSwish();\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::ReLU6 relu6;\n    };\n\n    //---------------------------------------------------------------------------\n\n    //class SqueezeExcite(nn.Module):\n    //    def __init__(self,input_channels: int,squeeze: int = 4,) -&gt; None:\n    //        \"\"\"\n    //        Squeeze-and-Excitation block.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        squeeze (`int`, optional): Squeeze ratio. Defaults to 4.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.SE = nn.Sequential(\n    //                nn.AdaptiveAvgPool2d(output_size=1),\n    //                nn.Conv2d(input_channels, out_channels=input_channels//squeeze, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(input_channels//squeeze),\n    //        nn.ReLU(inplace=True),\n    //        nn.Conv2d(input_channels//squeeze, input_channels, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(input_channels),\n    //                HSigmoid(),\n    //        )\n    //\n    //    def forward(self, x):\n    //        x = x * self.SE(x)\n    //        return x\n\n    struct SqueezeExcite : torch::nn::Module {\n    public:\n        SqueezeExcite(int input_channels, int squeeze = 4);\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential SE = nullptr;\n    };\n\n\n    //---------------------------------------------------------------------------\n\n    //class Bottleneck(nn.Module):\n    //    def __init__(self,input_channels: int,kernel: int,stride: int,expansion: int,output_channels: int,activation: nn.Module,se: bool = False,) -&gt; None:\n    //        \"\"\"\n    //        MobileNetV3 bottleneck block.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        kernel (`int`): Convolution kernel size.\n    //        stride (`int`): Convolution stride.\n    //        expansion (`int`): Expansion size, indicating the middle layer's output channels.\n    //        output_channels (`int`): Number of final output channels.\n    //        activation (`nn.Module`): Activation function.\n    //        se (`bool`, optional): Whether to use Squeeze-and-Excitation. Defaults to False.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.bottleneck = nn.Sequential(\n    //        # expansion\n    //                nn.Conv2d(input_channels, expansion, kernel_size=1, stride=1, bias=False),\n    //                nn.BatchNorm2d(expansion),\n    //                activation,\n    //\n    //        # depth-wise convolution\n    //                nn.Conv2d(expansion, expansion, kernel_size=kernel, stride=stride, padding=kernel//2, groups=expansion, bias=False),\n    //        nn.BatchNorm2d(expansion),\n    //                activation,\n    //\n    //        # squeeze-and-excite\n    //                SqueezeExcite(expansion) if se else nn.Identity(),\n    //\n    //        # point-wise convolution\n    //                nn.Conv2d(expansion, output_channels, kernel_size=1, stride=1, bias=False),\n    //        nn.BatchNorm2d(output_channels),\n    //                activation,\n    //        )\n    //\n    //        # for residual skip connecting when the input size is different from output size\n    //        self.downsample = None if input_channels == output_channels and stride == 1 else nn.Sequential(\n    //                nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=stride, bias=False),\n    //        nn.BatchNorm2d(output_channels),\n    //        )\n    //\n    //\n    //    def forward(self, x):\n    //        residual = x\n    //        output = self.bottleneck(x)\n    //\n    //        if self.downsample:\n    //        residual = self.downsample(x)\n    //\n    //        output = output + residual\n    //\n    //        return output\n\n    struct Bottleneck : torch::nn::Module {\n    public:\n        Bottleneck(int input_channels, int kernel, int stride, int expansion, int output_channels,\n                   torch::nn::Module activation, bool se = false);\n\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential bottleneck;\n        torch::nn::Sequential downsample;\n    };\n\n\n    //---------------------------------------------------------------------------\n\n\n    //class MobileNetV3(nn.Module):\n    //    def __init__(self,input_channels: int,num_classes: int,dropout_prob: float = 0.5,) -&gt; None:\n    //        \"\"\"\n    //        MobileNetV3 (Large) model.\n    //\n    //        Args:\n    //        input_channels (`int`): Number of input channels.\n    //        num_classes (`int`): Number of classes.\n    //        dropout_prob (`float`, optional): Dropout probability. Defaults to 0.5.\n    //        \"\"\"\n    //        super().__init__()\n    //\n    //        self.initial_conv = nn.Sequential(\n    //                nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3, stride=2),\n    //                nn.BatchNorm2d(16),\n    //                HSwish(),\n    //        )\n    //\n    //        self.bottlenecks = nn.Sequential(\n    //                Bottleneck(input_channels=16, kernel=3, stride=1, expansion=16, output_channels=16, activation=nn.ReLU(inplace=True)),\n    //                Bottleneck(input_channels=16, kernel=3, stride=2, expansion=64, output_channels=24, activation=nn.ReLU(inplace=True)),\n    //                Bottleneck(input_channels=24, kernel=3, stride=1, expansion=72, output_channels=24, activation=nn.ReLU(inplace=True)),\n\n    //                Bottleneck(input_channels=24, kernel=5, stride=2, expansion=72, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n    //                Bottleneck(input_channels=40, kernel=5, stride=1, expansion=120, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n    //                Bottleneck(input_channels=40, kernel=5, stride=1, expansion=120, output_channels=40, activation=nn.ReLU(inplace=True), se=True),\n\n\n    //                Bottleneck(input_channels=40, kernel=3, stride=2, expansion=240, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=200, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=184, output_channels=80, activation=HSwish()),\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=184, output_channels=80, activation=HSwish()),\n\n\n\n    //                Bottleneck(input_channels=80, kernel=3, stride=1, expansion=480, output_channels=112, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=112, kernel=3, stride=1, expansion=672, output_channels=112, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=112, kernel=5, stride=2, expansion=672, output_channels=160, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=160, kernel=5, stride=1, expansion=960, output_channels=160, activation=HSwish(), se=True),\n    //                Bottleneck(input_channels=160, kernel=5, stride=1, expansion=960, output_channels=160, activation=HSwish(), se=True),\n    //        )\n    //\n    //        self.final_conv = nn.Sequential(\n    //                nn.Conv2d(in_channels=160, out_channels=960, kernel_size=1, stride=1, bias=False),\n    //                nn.BatchNorm2d(960),\n    //                HSwish(),\n    //        )\n    //\n    //        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n    //\n    //        self.classifier = nn.Sequential(\n    //                nn.Linear(960, 1280),\n    //                HSwish(),\n    //                nn.Dropout(p=dropout_prob, inplace=True),\n    //                nn.Linear(1280, num_classes),\n    //        )\n    //\n    //    def forward(self, x):\n    //        x = self.initial_conv(x)\n    //        x = self.bottlenecks(x)\n    //        x = self.final_conv(x)\n    //        x = self.pool(x)\n    //        x = torch.flatten(x, 1)\n    //        x = self.classifier(x)\n    //        return x\n\n    struct MobileNetV3 : BaseModel {\n    public:\n        MobileNetV3(int input_channels, int num_classes, float dropout_prob = 0.5);\n        torch::Tensor forward(torch::Tensor x);\n\n    private:\n        torch::nn::Sequential initial_conv;\n        torch::nn::Sequential bottlenecks;\n        torch::nn::Sequential final_conv;\n        torch::nn::AdaptiveAvgPool2d pool;\n        torch::nn::Sequential classifier;\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_bae22fedf60f254e94c1517ab3741a15/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/nas-net","text":"<p>FileList &gt; cnn &gt; nas-net</p>"},{"location":"xTorch/dir_bae22fedf60f254e94c1517ab3741a15/#files","title":"Files","text":"Type Name file nas-net-a.h file nas-net-b.h file nas-net-c.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/nas-net/</code></p>"},{"location":"xTorch/nas-net-a_8h/","title":"File nas-net-a.h","text":"<p>FileList &gt; cnn &gt; nas-net &gt; nas-net-a.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/nas-net/nas-net-a.h</code></p>"},{"location":"xTorch/nas-net-a_8h_source/","title":"File nas-net-a.h","text":"<p>File List &gt; cnn &gt; nas-net &gt; nas-net-a.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef NAS_NET_A_H\n#define NAS_NET_A_H\n\n#endif //NAS_NET_A_H\n</code></pre>"},{"location":"xTorch/nas-net-b_8h/","title":"File nas-net-b.h","text":"<p>FileList &gt; cnn &gt; nas-net &gt; nas-net-b.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/nas-net/nas-net-b.h</code></p>"},{"location":"xTorch/nas-net-b_8h_source/","title":"File nas-net-b.h","text":"<p>File List &gt; cnn &gt; nas-net &gt; nas-net-b.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef NAS_NET_B_H\n#define NAS_NET_B_H\n\n#endif //NAS_NET_B_H\n</code></pre>"},{"location":"xTorch/nas-net-c_8h/","title":"File nas-net-c.h","text":"<p>FileList &gt; cnn &gt; nas-net &gt; nas-net-c.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/nas-net/nas-net-c.h</code></p>"},{"location":"xTorch/nas-net-c_8h_source/","title":"File nas-net-c.h","text":"<p>File List &gt; cnn &gt; nas-net &gt; nas-net-c.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef NAS_NET_C_H\n#define NAS_NET_C_H\n\n#endif //NAS_NET_C_H\n</code></pre>"},{"location":"xTorch/dir_d8f74afeea28456534a43cd406cb744b/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/reg-net","text":"<p>FileList &gt; cnn &gt; reg-net</p>"},{"location":"xTorch/dir_d8f74afeea28456534a43cd406cb744b/#files","title":"Files","text":"Type Name file reg-net-x.h file reg-net-y.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/reg-net/</code></p>"},{"location":"xTorch/reg-net-x_8h/","title":"File reg-net-x.h","text":"<p>FileList &gt; cnn &gt; reg-net &gt; reg-net-x.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/reg-net/reg-net-x.h</code></p>"},{"location":"xTorch/reg-net-x_8h_source/","title":"File reg-net-x.h","text":"<p>File List &gt; cnn &gt; reg-net &gt; reg-net-x.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef REG_NET_X_H\n#define REG_NET_X_H\n\n#endif //REG_NET_X_H\n</code></pre>"},{"location":"xTorch/reg-net-y_8h/","title":"File reg-net-y.h","text":"<p>FileList &gt; cnn &gt; reg-net &gt; reg-net-y.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/reg-net/reg-net-y.h</code></p>"},{"location":"xTorch/reg-net-y_8h_source/","title":"File reg-net-y.h","text":"<p>File List &gt; cnn &gt; reg-net &gt; reg-net-y.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef REG_NET_Y_H\n#define REG_NET_Y_H\n\n#endif //REG_NET_Y_H\n</code></pre>"},{"location":"xTorch/dir_43ab8c30072399f09a02fdd1f785b21c/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/resnet","text":"<p>FileList &gt; cnn &gt; resnet</p>"},{"location":"xTorch/dir_43ab8c30072399f09a02fdd1f785b21c/#files","title":"Files","text":"Type Name file res2net.h file resnet-rs.h file resnet-v1.5.h file resnet101.h file resnet1202.h file resnet152.h file resnet18.h file resnet200.h file resnet34.h file resnet50.h file resnext.h file wide-resnet.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/</code></p>"},{"location":"xTorch/res2net_8h/","title":"File res2net.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; res2net.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/res2net_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/res2net_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/res2net.h</code></p>"},{"location":"xTorch/res2net_8h_source/","title":"File res2net.h","text":"<p>File List &gt; cnn &gt; resnet &gt; res2net.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet-rs_8h/","title":"File resnet-rs.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet-rs.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet-rs_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet-rs_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet-rs.h</code></p>"},{"location":"xTorch/resnet-rs_8h_source/","title":"File resnet-rs.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet-rs.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet-v1_85_8h/","title":"File resnet-v1.5.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet-v1.5.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet-v1_85_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet-v1_85_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet-v1.5.h</code></p>"},{"location":"xTorch/resnet-v1_85_8h_source/","title":"File resnet-v1.5.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet-v1.5.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet101_8h/","title":"File resnet101.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet101.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet101_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet101_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet101.h</code></p>"},{"location":"xTorch/resnet101_8h_source/","title":"File resnet101.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet101.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet1202_8h/","title":"File resnet1202.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet1202.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet1202_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet1202_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet1202.h</code></p>"},{"location":"xTorch/resnet1202_8h_source/","title":"File resnet1202.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet1202.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet152_8h/","title":"File resnet152.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet152.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet152_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet152_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet152.h</code></p>"},{"location":"xTorch/resnet152_8h_source/","title":"File resnet152.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet152.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet18_8h/","title":"File resnet18.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet18.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet18_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet18_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet18.h</code></p>"},{"location":"xTorch/resnet18_8h_source/","title":"File resnet18.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet18.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet200_8h/","title":"File resnet200.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet200.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet200_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet200_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet200.h</code></p>"},{"location":"xTorch/resnet200_8h_source/","title":"File resnet200.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet200.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet34_8h/","title":"File resnet34.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet34.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet34_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet34_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet34.h</code></p>"},{"location":"xTorch/resnet34_8h_source/","title":"File resnet34.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet34.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnet50_8h/","title":"File resnet50.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnet50.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnet50_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnet50_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnet50.h</code></p>"},{"location":"xTorch/resnet50_8h_source/","title":"File resnet50.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnet50.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/resnext_8h/","title":"File resnext.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; resnext.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/resnext_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/resnext_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/resnext.h</code></p>"},{"location":"xTorch/resnext_8h_source/","title":"File resnext.h","text":"<p>File List &gt; cnn &gt; resnet &gt; resnext.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/wide-resnet_8h/","title":"File wide-resnet.h","text":"<p>FileList &gt; cnn &gt; resnet &gt; wide-resnet.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/wide-resnet_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/wide-resnet_8h/#classes","title":"Classes","text":"Type Name struct ResNet <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/resnet/wide-resnet.h</code></p>"},{"location":"xTorch/wide-resnet_8h_source/","title":"File wide-resnet.h","text":"<p>File List &gt; cnn &gt; resnet &gt; wide-resnet.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    namespace {\n        struct ResidualBlock : torch::nn::Module {\n            torch::nn::Sequential conv1 = nullptr, conv2 = nullptr, downsample = nullptr;\n            int out_channels;\n            torch::nn::ReLU relu = nullptr;\n            torch::Tensor residual;\n\n            ResidualBlock(int in_channels, int out_channels, int stride = 1,\n                          torch::nn::Sequential downsample = nullptr);\n\n            torch::Tensor forward(torch::Tensor x);\n        };\n    }\n\n    struct ResNet : BaseModel {\n        mutable int inplanes = 64;\n        mutable torch::nn::Sequential conv1 = nullptr;\n        mutable torch::nn::MaxPool2d maxpool = nullptr;\n        mutable torch::nn::AvgPool2d avgpool = nullptr;\n\n        mutable torch::nn::Sequential layer0 = nullptr, layer1 = nullptr, layer2 = nullptr, layer3 = nullptr;\n        mutable torch::nn::Linear fc = nullptr;\n\n        ResNet(vector&lt;int&gt; layers, int num_classes = 10, int in_channels = 3 /* input channels */);\n\n        ResNet(std::vector&lt;int&gt; layers, int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::nn::Sequential makeLayerFromResidualBlock(int planes, int blocks, int stride = 1);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_3c5228e53245123408496854d41e9c05/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/shuffle-net","text":"<p>FileList &gt; cnn &gt; shuffle-net</p>"},{"location":"xTorch/dir_3c5228e53245123408496854d41e9c05/#files","title":"Files","text":"Type Name file shuffle-net-v1.h file shuffle-net-v2.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/shuffle-net/</code></p>"},{"location":"xTorch/shuffle-net-v1_8h/","title":"File shuffle-net-v1.h","text":"<p>FileList &gt; cnn &gt; shuffle-net &gt; shuffle-net-v1.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/shuffle-net/shuffle-net-v1.h</code></p>"},{"location":"xTorch/shuffle-net-v1_8h_source/","title":"File shuffle-net-v1.h","text":"<p>File List &gt; cnn &gt; shuffle-net &gt; shuffle-net-v1.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef SHUFFLE_NET_V1_H\n#define SHUFFLE_NET_V1_H\n\n#endif //SHUFFLE_NET_V1_H\n</code></pre>"},{"location":"xTorch/shuffle-net-v2_8h/","title":"File shuffle-net-v2.h","text":"<p>FileList &gt; cnn &gt; shuffle-net &gt; shuffle-net-v2.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/shuffle-net/shuffle-net-v2.h</code></p>"},{"location":"xTorch/shuffle-net-v2_8h_source/","title":"File shuffle-net-v2.h","text":"<p>File List &gt; cnn &gt; shuffle-net &gt; shuffle-net-v2.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef SHUFFLE_NET_V2_H\n#define SHUFFLE_NET_V2_H\n\n#endif //SHUFFLE_NET_V2_H\n</code></pre>"},{"location":"xTorch/dir_adf2b6225f9d04a14b4e30d5f88c6526/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/squeeze-net","text":"<p>FileList &gt; cnn &gt; squeeze-net</p>"},{"location":"xTorch/dir_adf2b6225f9d04a14b4e30d5f88c6526/#files","title":"Files","text":"Type Name file squeeze-net-v1.0.h file squeeze-net-v1.1.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/squeeze-net/</code></p>"},{"location":"xTorch/squeeze-net-v1_80_8h/","title":"File squeeze-net-v1.0.h","text":"<p>FileList &gt; cnn &gt; squeeze-net &gt; squeeze-net-v1.0.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/squeeze-net/squeeze-net-v1.0.h</code></p>"},{"location":"xTorch/squeeze-net-v1_80_8h_source/","title":"File squeeze-net-v1.0.h","text":"<p>File List &gt; cnn &gt; squeeze-net &gt; squeeze-net-v1.0.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef SQUEEZE_NET_V1_0_H\n#define SQUEEZE_NET_V1_0_H\n\n#endif //SQUEEZE_NET_V1_0_H\n</code></pre>"},{"location":"xTorch/squeeze-net-v1_81_8h/","title":"File squeeze-net-v1.1.h","text":"<p>FileList &gt; cnn &gt; squeeze-net &gt; squeeze-net-v1.1.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/squeeze-net/squeeze-net-v1.1.h</code></p>"},{"location":"xTorch/squeeze-net-v1_81_8h_source/","title":"File squeeze-net-v1.1.h","text":"<p>File List &gt; cnn &gt; squeeze-net &gt; squeeze-net-v1.1.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 4/21/25.\n//\n\n#ifndef SQUEEZE_NET_V1_1_H\n#define SQUEEZE_NET_V1_1_H\n\n#endif //SQUEEZE_NET_V1_1_H\n</code></pre>"},{"location":"xTorch/dir_b3c9663c6f1b69d0648274f31dad4bbc/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/unet","text":"<p>FileList &gt; cnn &gt; unet</p>"},{"location":"xTorch/dir_b3c9663c6f1b69d0648274f31dad4bbc/#files","title":"Files","text":"Type Name file unet.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/unet/</code></p>"},{"location":"xTorch/unet_8h/","title":"File unet.h","text":"<p>FileList &gt; cnn &gt; unet &gt; unet.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> <li><code>#include \"../../../exceptions/implementation.h\"</code></li> </ul>"},{"location":"xTorch/unet_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/unet_8h/#classes","title":"Classes","text":"Type Name struct DoubleConv struct DownSample struct UNet struct UpSample <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/unet/unet.h</code></p>"},{"location":"xTorch/unet_8h_source/","title":"File unet.h","text":"<p>File List &gt; cnn &gt; unet &gt; unet.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n#include \"../../../exceptions/implementation.h\"\n\nnamespace xt::models {\n    //class DoubleConv(nn.Module):\n    //    def __init__(self, in_channels, out_channels):\n    //        super().__init__()\n    //        self.conv_op = nn.Sequential(\n    //                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n    //                nn.ReLU(inplace=True),\n    //                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n    //                nn.ReLU(inplace=True)\n    //        )\n    //\n    //    def forward(self, x):\n    //        return self.conv_op(x)\n\n\n    struct DoubleConv : torch::nn::Module {\n    public:\n        DoubleConv(int in_channels, int out_channels);\n\n        torch::Tensor forward(torch::Tensor input);\n\n    private:\n        torch::nn::Sequential conv_op = nullptr;\n    };\n\n\n    //class DownSample(nn.Module):\n    //    def __init__(self, in_channels, out_channels):\n    //        super().__init__()\n    //        self.conv = DoubleConv(in_channels, out_channels)\n    //        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n    //\n    //    def forward(self, x):\n    //        down = self.conv(x)\n    //        p = self.pool(down)\n    //        return down, p\n\n    struct DownSample : torch::nn::Module {\n    public:\n        DownSample(int in_channels, int out_channels);\n\n        torch::Tensor forward(torch::Tensor input);\n\n    private:\n        DoubleConv conv{0, 0};\n        torch::nn::MaxPool2d pool = nullptr;\n    };\n\n\n    //class UpSample(nn.Module):\n    //    def __init__(self, in_channels, out_channels):\n    //        super().__init__()\n    //        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n    //        self.conv = DoubleConv(in_channels, out_channels)\n    //\n    // def forward(self, x1, x2):\n    //     x1 = self.up(x1)\n    //     x = torch.cat([x1, x2], 1)\n    //     return self.conv(x)\n\n    struct UpSample : torch::nn::Module {\n    public:\n        UpSample(int in_channels, int out_channels);\n\n        torch::Tensor forward(torch::Tensor x1, torch::Tensor x2);\n\n    private:\n        DoubleConv conv{0, 0};\n        torch::nn::ConvTranspose2d up = nullptr;\n    };\n\n\n    //class UNet(nn.Module):\n    //    def __init__(self, in_channels, num_classes):\n    //        super().__init__()\n    //        self.down_convolution_1 = DownSample(in_channels, 64)\n    //        self.down_convolution_2 = DownSample(64, 128)\n    //        self.down_convolution_3 = DownSample(128, 256)\n    //        self.down_convolution_4 = DownSample(256, 512)\n    //\n    //        self.bottle_neck = DoubleConv(512, 1024)\n    //\n    //        self.up_convolution_1 = UpSample(1024, 512)\n    //        self.up_convolution_2 = UpSample(512, 256)\n    //        self.up_convolution_3 = UpSample(256, 128)\n    //        self.up_convolution_4 = UpSample(128, 64)\n    //\n    //        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n    //\n    //    def forward(self, x):\n    //        down_1, p1 = self.down_convolution_1(x)\n    //        down_2, p2 = self.down_convolution_2(p1)\n    //        down_3, p3 = self.down_convolution_3(p2)\n    //        down_4, p4 = self.down_convolution_4(p3)\n    //\n    //        b = self.bottle_neck(p4)\n    //\n    //        up_1 = self.up_convolution_1(b, down_4)\n    //        up_2 = self.up_convolution_2(up_1, down_3)\n    //        up_3 = self.up_convolution_3(up_2, down_2)\n    //        up_4 = self.up_convolution_4(up_3, down_1)\n    //\n    //        out = self.out(up_4)\n    //        return out\n    //\n\n\n    struct UNet : BaseModel {\n    public:\n        UNet(int num_classes/* classes */, int in_channels = 1/*  input channels */);\n        torch::Tensor forward(torch::Tensor input) const override;\n\n    private:\n        DownSample down_convolution_1{0,0};\n        DownSample down_convolution_2{0,0};\n        DownSample down_convolution_3{0,0};\n        DownSample down_convolution_4{0,0};\n\n        DoubleConv bottle_neck{0,0};\n\n        UpSample up_convolution_1{0,0};\n        UpSample up_convolution_2{0,0};\n        UpSample up_convolution_3{0,0};\n        UpSample up_convolution_4{0,0};\n\n        torch::nn::Conv2d out = nullptr;\n    };\n}\n</code></pre>"},{"location":"xTorch/dir_ef7a937debe30c3ca367a3d686ce12d7/","title":"Dir /home/kami/Documents/cpp/models/include/models/cnn/vggnet","text":"<p>FileList &gt; cnn &gt; vggnet</p>"},{"location":"xTorch/dir_ef7a937debe30c3ca367a3d686ce12d7/#files","title":"Files","text":"Type Name file vggnet11.h file vggnet13.h file vggnet16.h file vggnet19.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/vggnet/</code></p>"},{"location":"xTorch/vggnet11_8h/","title":"File vggnet11.h","text":"<p>FileList &gt; cnn &gt; vggnet &gt; vggnet11.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/vggnet11_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/vggnet11_8h/#classes","title":"Classes","text":"Type Name struct VggNet16 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/vggnet/vggnet11.h</code></p>"},{"location":"xTorch/vggnet11_8h_source/","title":"File vggnet11.h","text":"<p>File List &gt; cnn &gt; vggnet &gt; vggnet11.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    struct VggNet16 : BaseModel {\n        mutable torch::nn::Sequential layer1 = nullptr, layer2 = nullptr, layer3 = nullptr, layer4 = nullptr;\n        mutable torch::nn::Sequential layer5 = nullptr;\n        mutable torch::nn::Sequential layer6 = nullptr, layer7 = nullptr, layer8 = nullptr, layer9 = nullptr;\n        mutable torch::nn::Sequential layer10 = nullptr;\n        mutable torch::nn::Sequential layer11 = nullptr, layer12 = nullptr, layer13 = nullptr;\n        mutable torch::nn::Sequential fc = nullptr, fc1 = nullptr, fc2 = nullptr;\n\n        VggNet16(int num_classes /* classes */, int in_channels  /* input channels */);\n        VggNet16(int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/vggnet13_8h/","title":"File vggnet13.h","text":"<p>FileList &gt; cnn &gt; vggnet &gt; vggnet13.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/vggnet13_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/vggnet13_8h/#classes","title":"Classes","text":"Type Name struct VggNet16 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/vggnet/vggnet13.h</code></p>"},{"location":"xTorch/vggnet13_8h_source/","title":"File vggnet13.h","text":"<p>File List &gt; cnn &gt; vggnet &gt; vggnet13.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    struct VggNet16 : BaseModel {\n        mutable torch::nn::Sequential layer1 = nullptr, layer2 = nullptr, layer3 = nullptr, layer4 = nullptr;\n        mutable torch::nn::Sequential layer5 = nullptr;\n        mutable torch::nn::Sequential layer6 = nullptr, layer7 = nullptr, layer8 = nullptr, layer9 = nullptr;\n        mutable torch::nn::Sequential layer10 = nullptr;\n        mutable torch::nn::Sequential layer11 = nullptr, layer12 = nullptr, layer13 = nullptr;\n        mutable torch::nn::Sequential fc = nullptr, fc1 = nullptr, fc2 = nullptr;\n\n        VggNet16(int num_classes /* classes */, int in_channels  /* input channels */);\n        VggNet16(int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/vggnet16_8h/","title":"File vggnet16.h","text":"<p>FileList &gt; cnn &gt; vggnet &gt; vggnet16.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/vggnet16_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/vggnet16_8h/#classes","title":"Classes","text":"Type Name struct VggNet16 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/vggnet/vggnet16.h</code></p>"},{"location":"xTorch/vggnet16_8h_source/","title":"File vggnet16.h","text":"<p>File List &gt; cnn &gt; vggnet &gt; vggnet16.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    struct VggNet16 : BaseModel {\n        mutable torch::nn::Sequential layer1 = nullptr, layer2 = nullptr, layer3 = nullptr, layer4 = nullptr;\n        mutable torch::nn::Sequential layer5 = nullptr;\n        mutable torch::nn::Sequential layer6 = nullptr, layer7 = nullptr, layer8 = nullptr, layer9 = nullptr;\n        mutable torch::nn::Sequential layer10 = nullptr;\n        mutable torch::nn::Sequential layer11 = nullptr, layer12 = nullptr, layer13 = nullptr;\n        mutable torch::nn::Sequential fc = nullptr, fc1 = nullptr, fc2 = nullptr;\n\n        VggNet16(int num_classes /* classes */, int in_channels  /* input channels */);\n        VggNet16(int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/vggnet19_8h/","title":"File vggnet19.h","text":"<p>FileList &gt; cnn &gt; vggnet &gt; vggnet19.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../../base.h\"</code></li> </ul>"},{"location":"xTorch/vggnet19_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/vggnet19_8h/#classes","title":"Classes","text":"Type Name struct VggNet16 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/vggnet/vggnet19.h</code></p>"},{"location":"xTorch/vggnet19_8h_source/","title":"File vggnet19.h","text":"<p>File List &gt; cnn &gt; vggnet &gt; vggnet19.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include \"../../base.h\"\n\n\nusing namespace std;\n\nnamespace xt::models {\n    struct VggNet16 : BaseModel {\n        mutable torch::nn::Sequential layer1 = nullptr, layer2 = nullptr, layer3 = nullptr, layer4 = nullptr;\n        mutable torch::nn::Sequential layer5 = nullptr;\n        mutable torch::nn::Sequential layer6 = nullptr, layer7 = nullptr, layer8 = nullptr, layer9 = nullptr;\n        mutable torch::nn::Sequential layer10 = nullptr;\n        mutable torch::nn::Sequential layer11 = nullptr, layer12 = nullptr, layer13 = nullptr;\n        mutable torch::nn::Sequential fc = nullptr, fc1 = nullptr, fc2 = nullptr;\n\n        VggNet16(int num_classes /* classes */, int in_channels  /* input channels */);\n        VggNet16(int num_classes, int in_channels, std::vector&lt;int64_t&gt; input_shape);\n\n        torch::Tensor forward(torch::Tensor x) const override;\n    };\n}\n</code></pre>"},{"location":"xTorch/cnn_8h/","title":"File cnn.h","text":"<p>FileList &gt; cnn &gt; cnn.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"alexnet/alexnet.h\"</code></li> <li><code>#include \"lenet/lenet5.h\"</code></li> <li><code>#include \"mobilenet/mobilenet.h\"</code></li> <li><code>#include \"resnet/resnet18.h\"</code></li> <li><code>#include \"unet/unet.h\"</code></li> <li><code>#include \"vggnet/vggnet.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/cnn/cnn.h</code></p>"},{"location":"xTorch/cnn_8h_source/","title":"File cnn.h","text":"<p>File List &gt; cnn &gt; cnn.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"alexnet/alexnet.h\"\n#include \"lenet/lenet5.h\"\n#include \"mobilenet/mobilenet.h\"\n#include \"resnet/resnet18.h\"\n#include \"unet/unet.h\"\n#include \"vggnet/vggnet.h\"\n</code></pre>"},{"location":"xTorch/models_2base_8h/","title":"File base.h","text":"<p>FileList &gt; include &gt; models &gt; base.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;torch/script.h&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> <li><code>#include &lt;unordered_set&gt;</code></li> </ul>"},{"location":"xTorch/models_2base_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace models"},{"location":"xTorch/models_2base_8h/#classes","title":"Classes","text":"Type Name class BaseModel class Model <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/base.h</code></p>"},{"location":"xTorch/models_2base_8h_source/","title":"File base.h","text":"<p>File List &gt; include &gt; models &gt; base.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;torch/script.h&gt;\n#include &lt;string&gt;\n#include &lt;vector&gt;\n#include &lt;unordered_map&gt;\n#include &lt;unordered_set&gt;\n\nnamespace xt::models {\n\nclass BaseModel: public torch::nn::Module {\n  public:\n  BaseModel();\n   virtual  torch::Tensor forward(torch::Tensor input) const = 0;\n};\n\n\nclass Model : public BaseModel {\n\n\n  public:\n    Model(int a);\n    torch::Tensor forward(torch::Tensor input) const override;\n\nprivate :\n    int a;\n};\n\n\n}\n</code></pre>"},{"location":"xTorch/models_8h/","title":"File models.h","text":"<p>FileList &gt; include &gt; models &gt; models.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"base.h\"</code></li> <li><code>#include \"cnn/cnn.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/models/models.h</code></p>"},{"location":"xTorch/models_8h_source/","title":"File models.h","text":"<p>File List &gt; include &gt; models &gt; models.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"base.h\"\n#include \"cnn/cnn.h\"\n</code></pre>"},{"location":"xTorch/dir_9b1ced676d335869719a7bfb99e201c3/","title":"Dir /home/kami/Documents/cpp/models/include/temp","text":"<p>FileList &gt; include &gt; temp</p>"},{"location":"xTorch/dir_9b1ced676d335869719a7bfb99e201c3/#files","title":"Files","text":"Type Name file temp.h file test-dataset.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/temp/</code></p>"},{"location":"xTorch/temp_8h/","title":"File temp.h","text":"<p>FileList &gt; include &gt; temp &gt; temp.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"test-dataset.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/temp/temp.h</code></p>"},{"location":"xTorch/temp_8h_source/","title":"File temp.h","text":"<p>File List &gt; include &gt; temp &gt; temp.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"test-dataset.h\"\n</code></pre>"},{"location":"xTorch/test-dataset_8h/","title":"File test-dataset.h","text":"<p>FileList &gt; include &gt; temp &gt; test-dataset.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> </ul>"},{"location":"xTorch/test-dataset_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace temp"},{"location":"xTorch/test-dataset_8h/#classes","title":"Classes","text":"Type Name class TestDataset <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/temp/test-dataset.h</code></p>"},{"location":"xTorch/test-dataset_8h_source/","title":"File test-dataset.h","text":"<p>File List &gt; include &gt; temp &gt; test-dataset.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;torch/torch.h&gt;\n\nnamespace xt::temp {\n\nclass TestDataset {\n\n  public:\n    TestDataset();\n//    ~TestDataset();\n    torch::Tensor forward(torch::Tensor input);\n};\n\n}\n\n</code></pre>"},{"location":"xTorch/dir_73f622148a13e0576f0e4ec926ecde91/","title":"Dir /home/kami/Documents/cpp/models/include/trainers","text":"<p>FileList &gt; include &gt; trainers</p>"},{"location":"xTorch/dir_73f622148a13e0576f0e4ec926ecde91/#files","title":"Files","text":"Type Name file trainer.h file trainers.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/trainers/</code></p>"},{"location":"xTorch/trainer_8h/","title":"File trainer.h","text":"<p>FileList &gt; include &gt; trainers &gt; trainer.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;torch/torch.h&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include \"../data-loaders/data-loader.h\"</code></li> <li><code>#include \"../models/base.h\"</code></li> <li><code>#include \"../datasets/base/base.h\"</code></li> </ul>"},{"location":"xTorch/trainer_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt"},{"location":"xTorch/trainer_8h/#classes","title":"Classes","text":"Type Name class Trainer <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/trainers/trainer.h</code></p>"},{"location":"xTorch/trainer_8h_source/","title":"File trainer.h","text":"<p>File List &gt; include &gt; trainers &gt; trainer.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;torch/torch.h&gt;\n#include &lt;iostream&gt;\n#include &lt;filesystem&gt;\n\n#include &lt;memory&gt;  // For std::shared_ptr\n#include &lt;string&gt;  // For std::string\n#include \"../data-loaders/data-loader.h\"\n#include \"../models/base.h\"\n#include \"../datasets/base/base.h\"\n\n\n// Forward declarations (assume these classes exist elsewhere)\n//class Optimizer;\n//class LossFunction;\n\nnamespace xt {\n\n//    template &lt;typename Dataset&gt;\n//    void check_dataset_type(const Dataset&amp; dataset) {\n//        if constexpr (std::is_same_v&lt;Dataset, xt::data::datasets::BaseDataset&gt;) {\n//            std::cout &lt;&lt; \"The object is a MNIST dataset\" &lt;&lt; std::endl;\n//        } else if constexpr (std::is_same_v&lt;Dataset, torch::data::datasets::MapDataset&lt;xt::data::datasets::BaseDataset, torch::data::transforms::Stack&lt;&gt;&gt;&gt;) {\n//            std::cout &lt;&lt; \"The object is a transformed MNIST dataset\" &lt;&lt; std::endl;\n//        } else {\n//            std::cout &lt;&lt; \"The object is of an unknown type\" &lt;&lt; std::endl;\n//        }\n//    }\n\n\n\n    class Trainer {\n    public:\n        // Default constructor\n        Trainer();\n\n        // Setter methods with fluent interface\n        Trainer&amp; set_max_epochs(int maxEpochs);\n        Trainer&amp; set_optimizer(torch::optim::Optimizer *optimizer);\n        Trainer&amp; set_loss_fn(std::function&lt;torch::Tensor(torch::Tensor, torch::Tensor)&gt; lossFn);\n        Trainer&amp; enable_checkpoint(const std::string&amp; path, int interval);\n        template &lt;typename Dataset&gt;\n//        void fit(torch::ext::models::BaseModel *model , xt::DataLoader&lt;Dataset&gt;&amp;  train_loader);\n//        template &lt;typename Dataset&gt;\n        void fit(xt::models::BaseModel *model , xt::DataLoader&lt;Dataset&gt;&amp;  train_loader) {\n\n            torch::Device device(torch::kCPU);\n            model-&gt;to(device);\n            model-&gt;train();\n            for (size_t epoch = 0; epoch != this-&gt;max_epochs_; ++epoch) {\n                cout &lt;&lt; \"epoch: \" &lt;&lt; epoch &lt;&lt; endl;\n                int a = 1;\n                for (auto&amp; batch : train_loader) {\n                    torch::Tensor data, targets;\n                    data = batch.data;\n                    targets = batch.target;\n                    this-&gt;optimizer_-&gt;zero_grad();\n                    torch::Tensor output;\n                    output = model-&gt;forward(data);\n                    torch::Tensor loss;\n                    loss = this-&gt;loss_fn_(output, targets);\n                    loss.backward();\n                    this-&gt;optimizer_-&gt;step();\n                    a++;\n\n                }\n                cout &lt;&lt; \"interval: \" &lt;&lt; a &lt;&lt; endl;\n            }\n        }\n\n\n    private:\n        int max_epochs_;                         // Maximum number of training epochs\n        torch::optim::Optimizer *optimizer_;  // Optimizer object\n        std::function&lt;torch::Tensor(torch::Tensor, torch::Tensor)&gt; loss_fn_;\n//        std::shared_ptr&lt;torch::nn::CrossEntropyLoss&gt; lossFn_;  // Loss function object\n        bool checkpoint_enabled_;                // Flag for checkpointing status\n        std::string checkpoint_path_;            // Path for saving checkpoints\n        int checkpoint_interval_;                // Interval for checkpointing\n    };\n\n} // namespace xt\n\n\n\n</code></pre>"},{"location":"xTorch/trainers_8h/","title":"File trainers.h","text":"<p>FileList &gt; include &gt; trainers &gt; trainers.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"trainer.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/trainers/trainers.h</code></p>"},{"location":"xTorch/trainers_8h_source/","title":"File trainers.h","text":"<p>File List &gt; include &gt; trainers &gt; trainers.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"trainer.h\"\n</code></pre>"},{"location":"xTorch/dir_de1d6215dd8b8d2c901daadc91a23b6e/","title":"Dir /home/kami/Documents/cpp/models/include/transforms","text":"<p>FileList &gt; include &gt; transforms</p>"},{"location":"xTorch/dir_de1d6215dd8b8d2c901daadc91a23b6e/#files","title":"Files","text":"Type Name file compose.h file convert.h file crop.h file cutout.h file flip.h file gaussian.h file grayscale.h file jitter.h file lambda.h file normalize.h file pad.h file resize.h file rotation.h file transforms.h"},{"location":"xTorch/dir_de1d6215dd8b8d2c901daadc91a23b6e/#directories","title":"Directories","text":"Type Name dir base <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/</code></p>"},{"location":"xTorch/dir_20071092909b95390d4afb4a22f58717/","title":"Dir /home/kami/Documents/cpp/models/include/transforms/base","text":"<p>FileList &gt; base</p>"},{"location":"xTorch/dir_20071092909b95390d4afb4a22f58717/#files","title":"Files","text":"Type Name file base.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/base/</code></p>"},{"location":"xTorch/transforms_2base_2base_8h/","title":"File base.h","text":"<p>FileList &gt; base &gt; base.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../compose.h\"</code></li> <li><code>#include \"../convert.h\"</code></li> <li><code>#include \"../crop.h\"</code></li> <li><code>#include \"../cutout.h\"</code></li> <li><code>#include \"../flip.h\"</code></li> <li><code>#include \"../gaussian.h\"</code></li> <li><code>#include \"../grayscale.h\"</code></li> <li><code>#include \"../jitter.h\"</code></li> <li><code>#include \"../lambda.h\"</code></li> <li><code>#include \"../normalize.h\"</code></li> <li><code>#include \"../pad.h\"</code></li> <li><code>#include \"../resize.h\"</code></li> <li><code>#include \"../rotation.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/base/base.h</code></p>"},{"location":"xTorch/transforms_2base_2base_8h_source/","title":"File base.h","text":"<p>File List &gt; base &gt; base.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../compose.h\"\n#include \"../convert.h\"\n#include \"../crop.h\"\n#include \"../cutout.h\"\n#include \"../flip.h\"\n#include \"../gaussian.h\"\n#include \"../grayscale.h\"\n#include \"../jitter.h\"\n#include \"../lambda.h\"\n#include \"../normalize.h\"\n#include \"../pad.h\"\n#include \"../resize.h\"\n#include \"../rotation.h\"\n\n\n</code></pre>"},{"location":"xTorch/compose_8h/","title":"File compose.h","text":"<p>FileList &gt; include &gt; transforms &gt; compose.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/compose_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/compose_8h/#classes","title":"Classes","text":"Type Name class Compose A class to compose multiple tensor transformations into a single callable pipeline. <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/compose.h</code></p>"},{"location":"xTorch/compose_8h_source/","title":"File compose.h","text":"<p>File List &gt; include &gt; transforms &gt; compose.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n    class Compose {\n    public:\n        using TransformFunc = std::function&lt;torch::Tensor(torch::Tensor)&gt;;\n\n        Compose();\n\n        Compose(std::vector&lt;TransformFunc&gt; transforms);\n\n        torch::Tensor operator()(torch::Tensor input) const;\n\n    private:\n        std::vector&lt;TransformFunc&gt; transforms;\n    };\n}\n</code></pre>"},{"location":"xTorch/convert_8h/","title":"File convert.h","text":"<p>FileList &gt; include &gt; transforms &gt; convert.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/convert_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/convert_8h/#classes","title":"Classes","text":"Type Name struct ToTensor <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/convert.h</code></p>"},{"location":"xTorch/convert_8h_source/","title":"File convert.h","text":"<p>File List &gt; include &gt; transforms &gt; convert.h</p> <p>Go to the documentation of this file</p> <pre><code>\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n\n\n    struct ToTensor {\n    public:\n        torch::Tensor operator()(const cv::Mat&amp; image) const;\n    };\n\n\n}\n</code></pre>"},{"location":"xTorch/crop_8h/","title":"File crop.h","text":"<p>FileList &gt; include &gt; transforms &gt; crop.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/crop_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/crop_8h/#classes","title":"Classes","text":"Type Name struct CenterCrop struct RandomCrop struct RandomCrop2 <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/crop.h</code></p>"},{"location":"xTorch/crop_8h_source/","title":"File crop.h","text":"<p>File List &gt; include &gt; transforms &gt; crop.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n    struct CenterCrop {\n    public:\n        CenterCrop(std::vector&lt;int64_t&gt; size);\n\n        torch::Tensor operator()(torch::Tensor input);\n\n    private:\n        std::vector&lt;int64_t&gt; size;\n    };\n\n\n    struct RandomCrop {\n    public:\n        RandomCrop(std::vector&lt;int64_t&gt; size);\n\n        torch::Tensor operator()(torch::Tensor input);\n\n    private:\n        std::vector&lt;int64_t&gt; size;\n    };\n\n\n    struct RandomCrop2 {\n    private:\n        int crop_height;\n        int crop_width;\n\n    public:\n        RandomCrop2(int height, int width);\n\n        torch::Tensor operator()(const torch::Tensor &amp;input_tensor);\n    };\n\n\n\n\n\n}\n</code></pre>"},{"location":"xTorch/cutout_8h/","title":"File cutout.h","text":"<p>FileList &gt; include &gt; transforms &gt; cutout.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/cutout_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/cutout_8h/#classes","title":"Classes","text":"Type Name struct Cutout <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/cutout.h</code></p>"},{"location":"xTorch/cutout_8h_source/","title":"File cutout.h","text":"<p>File List &gt; include &gt; transforms &gt; cutout.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n    struct Cutout {\n    public:\n        Cutout(int num_holes = 1, int hole_size = 16);\n\n        torch::Tensor operator()(const torch::Tensor&amp; input_tensor) const;\n    private:\n        int num_holes;\n        int hole_size;\n\n    };\n\n}\n</code></pre>"},{"location":"xTorch/flip_8h/","title":"File flip.h","text":"<p>FileList &gt; include &gt; transforms &gt; flip.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/flip_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/flip_8h/#classes","title":"Classes","text":"Type Name struct HorizontalFlip struct RandomFlip struct VerticalFlip <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/flip.h</code></p>"},{"location":"xTorch/flip_8h_source/","title":"File flip.h","text":"<p>File List &gt; include &gt; transforms &gt; flip.h</p> <p>Go to the documentation of this file</p> <pre><code>\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n    struct HorizontalFlip {\n    public:\n        HorizontalFlip();\n\n        torch::Tensor operator()(torch::Tensor input);\n    };\n\n\n    struct VerticalFlip {\n    public:\n        VerticalFlip();\n\n        torch::Tensor operator()(torch::Tensor input);\n    };\n\n\n\n    struct RandomFlip {\n    private:\n        double horizontal_prob;\n        double vertical_prob;\n\n    public:\n        RandomFlip(double h_prob = 0.5, double v_prob = 0.0);\n\n        torch::Tensor operator()(const torch::Tensor &amp;input_tensor);\n    };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/gaussian_8h/","title":"File gaussian.h","text":"<p>FileList &gt; include &gt; transforms &gt; gaussian.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/gaussian_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/gaussian_8h/#classes","title":"Classes","text":"Type Name struct GaussianBlur struct GaussianBlurOpenCV struct GaussianNoise struct RandomGaussianBlur <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/gaussian.h</code></p>"},{"location":"xTorch/gaussian_8h_source/","title":"File gaussian.h","text":"<p>File List &gt; include &gt; transforms &gt; gaussian.h</p> <p>Go to the documentation of this file</p> <pre><code>\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n    struct GaussianBlur {\n    public:\n        GaussianBlur(std::vector&lt;int64_t&gt; kernel_size, float sigma);\n\n        torch::Tensor operator()(torch::Tensor input);\n\n    private:\n        std::vector&lt;int64_t&gt; kernel_size;\n        float sigma;\n\n        torch::Tensor generate_gaussian_kernel(int64_t k_h, int64_t k_w, float sigma, torch::Device device);\n    };\n\n\n    struct GaussianBlurOpenCV {\n    public:\n        GaussianBlurOpenCV(int ksize, double sigma_val);\n\n        torch::Tensor operator()(const torch::Tensor &amp;input_tensor);\n\n    private:\n        cv::Size kernel_size;\n        double sigma;\n    };\n\n\n    struct RandomGaussianBlur {\n    private:\n        std::vector&lt;int&gt; kernel_sizes; // List of odd kernel sizes to choose from\n        double sigma_min;\n        double sigma_max;\n\n    public:\n        RandomGaussianBlur(std::vector&lt;int&gt; sizes = {3, 5}, double sigma_min = 0.1, double sigma_max = 2.0);\n\n        torch::Tensor operator()(const torch::Tensor &amp;input_tensor);\n    };\n\n\n    struct GaussianNoise {\n    public:\n        GaussianNoise(float mean, float std);\n\n        torch::Tensor operator()(torch::Tensor input);\n\n    private:\n        float mean;\n        float std;\n    };\n\n\n}\n</code></pre>"},{"location":"xTorch/grayscale_8h/","title":"File grayscale.h","text":"<p>FileList &gt; include &gt; transforms &gt; grayscale.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/grayscale_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/grayscale_8h/#classes","title":"Classes","text":"Type Name struct Grayscale struct GrayscaleToRGB A functor to convert a grayscale tensor to an RGB tensor. struct ToGray <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/grayscale.h</code></p>"},{"location":"xTorch/grayscale_8h_source/","title":"File grayscale.h","text":"<p>File List &gt; include &gt; transforms &gt; grayscale.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n\n    struct GrayscaleToRGB {\n    public:\n        torch::Tensor operator()(const torch::Tensor &amp;tensor);\n    };\n\n    struct Grayscale {\n    public:\n        Grayscale();\n\n        torch::Tensor operator()(torch::Tensor input);\n    };\n\n    struct ToGray {\n        torch::Tensor operator()(const torch::Tensor&amp; color_tensor) const;\n    };\n\n\n}\n</code></pre>"},{"location":"xTorch/jitter_8h/","title":"File jitter.h","text":"<p>FileList &gt; include &gt; transforms &gt; jitter.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/jitter_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/jitter_8h/#classes","title":"Classes","text":"Type Name struct ColorJitter <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/jitter.h</code></p>"},{"location":"xTorch/jitter_8h_source/","title":"File jitter.h","text":"<p>File List &gt; include &gt; transforms &gt; jitter.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n    struct ColorJitter {\n    public:\n        ColorJitter(float brightness = 0.0f,\n                    float contrast = 0.0f,\n                    float saturation = 0.0f);\n\n        torch::Tensor operator()(const torch::Tensor&amp; input_tensor) const;\n    private:\n\n        float brightness;\n        float contrast;\n        float saturation;\n\n    };\n\n}\n</code></pre>"},{"location":"xTorch/lambda_8h/","title":"File lambda.h","text":"<p>FileList &gt; include &gt; transforms &gt; lambda.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/lambda_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/lambda_8h/#classes","title":"Classes","text":"Type Name struct Lambda <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/lambda.h</code></p>"},{"location":"xTorch/lambda_8h_source/","title":"File lambda.h","text":"<p>File List &gt; include &gt; transforms &gt; lambda.h</p> <p>Go to the documentation of this file</p> <pre><code>\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n    struct Lambda {\n    public:\n        Lambda(std::function&lt;torch::Tensor(torch::Tensor)&gt; transform);\n\n        torch::Tensor operator()(torch::Tensor input);\n\n    private:\n        std::function&lt;torch::Tensor(torch::Tensor)&gt; transform;\n    };\n\n\n}\n</code></pre>"},{"location":"xTorch/normalize_8h/","title":"File normalize.h","text":"<p>FileList &gt; include &gt; transforms &gt; normalize.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/normalize_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/normalize_8h/#classes","title":"Classes","text":"Type Name struct Normalize <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/normalize.h</code></p>"},{"location":"xTorch/normalize_8h_source/","title":"File normalize.h","text":"<p>File List &gt; include &gt; transforms &gt; normalize.h</p> <p>Go to the documentation of this file</p> <pre><code>\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n    struct Normalize {\n    public:\n        Normalize(std::vector&lt;float&gt; mean, std::vector&lt;float&gt; std);\n        torch::Tensor operator()(const torch::Tensor&amp; tensor) const;\n    private:\n        std::vector&lt;float&gt; mean;\n        std::vector&lt;float&gt; std;\n\n    };\n\n}\n</code></pre>"},{"location":"xTorch/pad_8h/","title":"File pad.h","text":"<p>FileList &gt; include &gt; transforms &gt; pad.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/pad_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/pad_8h/#classes","title":"Classes","text":"Type Name struct Pad A functor to pad a tensor with a specified padding configuration. <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/pad.h</code></p>"},{"location":"xTorch/pad_8h_source/","title":"File pad.h","text":"<p>File List &gt; include &gt; transforms &gt; pad.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n    struct Pad {\n    public:\n        Pad(std::vector&lt;int64_t&gt; padding);\n\n        torch::Tensor operator()(torch::Tensor input);\n\n    private:\n        std::vector&lt;int64_t&gt; padding;\n    };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/resize_8h/","title":"File resize.h","text":"<p>FileList &gt; include &gt; transforms &gt; resize.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/resize_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/resize_8h/#classes","title":"Classes","text":"Type Name struct Resize A functor to resize a tensor image to a specified size. <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/resize.h</code></p>"},{"location":"xTorch/resize_8h_source/","title":"File resize.h","text":"<p>File List &gt; include &gt; transforms &gt; resize.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n\n    struct Resize {\n    public:\n        Resize(std::vector&lt;int64_t&gt; size);\n\n        torch::Tensor operator()(torch::Tensor img);\n\n    private:\n        std::vector&lt;int64_t&gt; size; \n    };\n\n\n\n\n}\n</code></pre>"},{"location":"xTorch/rotation_8h/","title":"File rotation.h","text":"<p>FileList &gt; include &gt; transforms &gt; rotation.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"../headers/transforms.h\"</code></li> </ul>"},{"location":"xTorch/rotation_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace data namespace transforms"},{"location":"xTorch/rotation_8h/#classes","title":"Classes","text":"Type Name struct Rotation <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/rotation.h</code></p>"},{"location":"xTorch/rotation_8h_source/","title":"File rotation.h","text":"<p>File List &gt; include &gt; transforms &gt; rotation.h</p> <p>Go to the documentation of this file</p> <pre><code>\n#include \"../headers/transforms.h\"\n\nnamespace xt::data::transforms {\n\n    struct Rotation {\n    public:\n        Rotation(double angle_deg);\n\n        torch::Tensor operator()(const torch::Tensor &amp;input_tensor);\n\n        private :\n            double angle; // Rotation angle in degrees\n    };\n\n\n    // struct Rotation {\n    // public:\n    //     Rotation(float angle);\n    //\n    //     torch::Tensor operator()(torch::Tensor input);\n    //\n    // private:\n    //     float angle;\n    // };\n\n\n\n}\n</code></pre>"},{"location":"xTorch/transforms_2transforms_8h/","title":"File transforms.h","text":"<p>FileList &gt; include &gt; transforms &gt; transforms.h</p> <p>Go to the source code of this file</p> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/transforms/transforms.h</code></p>"},{"location":"xTorch/transforms_2transforms_8h_source/","title":"File transforms.h","text":"<p>File List &gt; include &gt; transforms &gt; transforms.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n//#include \"compose.h\"\n//#include \"convert.h\"\n//#include \"crop.h\"\n//#include \"cutout.h\"\n//#include \"flip.h\"\n//#include \"gaussian.h\"\n//#include \"grayscale.h\"\n//#include \"jitter.h\"\n//#include \"lambda.h\"\n//#include \"normalize.h\"\n//#include \"pad.h\"\n//#include \"resize.h\"\n//#include \"rotation.h\"\n//\n\n\n</code></pre>"},{"location":"xTorch/dir_0ad255a918b7fba820a1ddafed6fa637/","title":"Dir /home/kami/Documents/cpp/models/include/types","text":"<p>FileList &gt; include &gt; types</p>"},{"location":"xTorch/dir_0ad255a918b7fba820a1ddafed6fa637/#files","title":"Files","text":"Type Name file arguments.h file enums.h file types.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/types/</code></p>"},{"location":"xTorch/arguments_8h/","title":"File arguments.h","text":"<p>FileList &gt; include &gt; types &gt; arguments.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;torch/data.h&gt;</code></li> <li><code>#include \"enums.h\"</code></li> </ul>"},{"location":"xTorch/arguments_8h/#classes","title":"Classes","text":"Type Name struct DatasetArguments <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/types/arguments.h</code></p>"},{"location":"xTorch/arguments_8h_source/","title":"File arguments.h","text":"<p>File List &gt; include &gt; types &gt; arguments.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;vector&gt;\n#include &lt;torch/data.h&gt;\n#include \"enums.h\"\nusing namespace std;\n\n\nstruct DatasetArguments {\n    DataMode mode = DataMode::TRAIN;\n    bool download = false;\n    vector&lt;torch::data::transforms::Lambda&lt;torch::data::Example&lt;&gt; &gt; &gt; transforms  = {};\n\n};\n</code></pre>"},{"location":"xTorch/enums_8h/","title":"File enums.h","text":"<p>FileList &gt; include &gt; types &gt; enums.h</p> <p>Go to the source code of this file</p>"},{"location":"xTorch/enums_8h/#public-types","title":"Public Types","text":"Type Name enum DataMode"},{"location":"xTorch/enums_8h/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"xTorch/enums_8h/#enum-datamode","title":"enum DataMode","text":"<pre><code>enum DataMode {\n    TRAIN = 1,\n    VALIDATION = 2,\n    TEST = 3\n};\n</code></pre> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/types/enums.h</code></p>"},{"location":"xTorch/enums_8h_source/","title":"File enums.h","text":"<p>File List &gt; include &gt; types &gt; enums.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\nenum class DataMode {\n    TRAIN = 1,\n    VALIDATION = 2,\n    TEST = 3,\n};\n</code></pre>"},{"location":"xTorch/types_8h/","title":"File types.h","text":"<p>FileList &gt; include &gt; types &gt; types.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"arguments.h\"</code></li> <li><code>#include \"enums.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/types/types.h</code></p>"},{"location":"xTorch/types_8h_source/","title":"File types.h","text":"<p>File List &gt; include &gt; types &gt; types.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n\n#include \"arguments.h\"\n#include \"enums.h\"\n</code></pre>"},{"location":"xTorch/dir_821002d4f10779a80d4fb17bc32f21f1/","title":"Dir /home/kami/Documents/cpp/models/include/utils","text":"<p>FileList &gt; include &gt; utils</p>"},{"location":"xTorch/dir_821002d4f10779a80d4fb17bc32f21f1/#files","title":"Files","text":"Type Name file base.h file downloader.h file extract.h file filesystem.h file md5.h file string.h file utils.h <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/</code></p>"},{"location":"xTorch/utils_2base_8h/","title":"File base.h","text":"<p>FileList &gt; include &gt; utils &gt; base.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"extract.h\"</code></li> <li><code>#include \"downloader.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/base.h</code></p>"},{"location":"xTorch/utils_2base_8h_source/","title":"File base.h","text":"<p>File List &gt; include &gt; utils &gt; base.h</p> <p>Go to the documentation of this file</p> <pre><code>//\n// Created by kami on 2/8/25.\n//\n\n#ifndef DCGAN_BASE_H\n#define DCGAN_BASE_H\n\n#include \"extract.h\"\n#include \"downloader.h\"\n#endif //DCGAN_BASE_H\n</code></pre>"},{"location":"xTorch/downloader_8h/","title":"File downloader.h","text":"<p>FileList &gt; include &gt; utils &gt; downloader.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;curl/curl.h&gt;</code></li> </ul>"},{"location":"xTorch/downloader_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace utils <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/downloader.h</code></p>"},{"location":"xTorch/downloader_8h_source/","title":"File downloader.h","text":"<p>File List &gt; include &gt; utils &gt; downloader.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;vector&gt;\n#include &lt;fstream&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;filesystem&gt;\n#include &lt;curl/curl.h&gt;\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::utils {\n    std::tuple&lt;bool, std::string&gt; download(std::string &amp;url, std::string outPath);\n\n    std::string rebuild_google_drive_link(std::string gid);\n\n    std::tuple&lt;bool, std::string&gt; download_from_gdrive(std::string gid, std::string outPath);\n}\n</code></pre>"},{"location":"xTorch/extract_8h/","title":"File extract.h","text":"<p>FileList &gt; include &gt; utils &gt; extract.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;zip.h&gt;</code></li> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;zlib.h&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;tar.h&gt;</code></li> <li><code>#include &lt;archive.h&gt;</code></li> <li><code>#include &lt;archive_entry.h&gt;</code></li> <li><code>#include &lt;sys/stat.h&gt;</code></li> <li><code>#include &lt;unistd.h&gt;</code></li> <li><code>#include &lt;libtar.h&gt;</code></li> <li><code>#include &lt;fcntl.h&gt;</code></li> <li><code>#include &lt;lzma.h&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;stdexcept&gt;</code></li> </ul>"},{"location":"xTorch/extract_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace utils <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/extract.h</code></p>"},{"location":"xTorch/extract_8h_source/","title":"File extract.h","text":"<p>File List &gt; include &gt; utils &gt; extract.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;iostream&gt;\n#include &lt;zip.h&gt;\n#include &lt;filesystem&gt;\n#include &lt;zlib.h&gt;\n#include &lt;fstream&gt;\n#include &lt;tar.h&gt;\n#include &lt;archive.h&gt;\n#include &lt;archive_entry.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;libtar.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;lzma.h&gt;\n#include &lt;iostream&gt;\n#include &lt;fstream&gt;\n#include &lt;vector&gt;\n#include &lt;stdexcept&gt;\n#include &lt;archive.h&gt;\n#include &lt;archive_entry.h&gt;\n#include &lt;fstream&gt;\n#include &lt;iostream&gt;\n#include &lt;filesystem&gt;\n\n\nusing namespace std;\nnamespace fs = std::filesystem;\n\nnamespace xt::utils {\n    void extractXZ(const std::string &amp;inputFile, const std::string &amp;outputFile);\n\n    std::tuple&lt;bool, string&gt; extractGzip(const std::string &amp;inFile, const std::string &amp;outFile = \"\");\n\n    bool extractTar(const std::string &amp;tarFile, const std::string &amp;outPath = \"./\");\n\n    bool extractZip(const std::string &amp;inFile, const std::string &amp;outPath = \"./\");\n\n    bool extractTgz(const std::string &amp;inFile, const std::string &amp;outPath = \"./\");\n\n    bool extract(const std::string &amp;inFile, const std::string &amp;outFile = \"\");\n\n}\n</code></pre>"},{"location":"xTorch/filesystem_8h/","title":"File filesystem.h","text":"<p>FileList &gt; include &gt; utils &gt; filesystem.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;filesystem&gt;</code></li> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> </ul>"},{"location":"xTorch/filesystem_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace utils namespace fs <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/filesystem.h</code></p>"},{"location":"xTorch/filesystem_8h_source/","title":"File filesystem.h","text":"<p>File List &gt; include &gt; utils &gt; filesystem.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;filesystem&gt;\n#include &lt;algorithm&gt;\n#include &lt;iostream&gt;\n\nnamespace fs = std::filesystem;\n\nnamespace xt::utils::fs {\n\n    std::size_t countFiles(const std::filesystem::path&amp; path , bool recursive = true);\n\n}\n</code></pre>"},{"location":"xTorch/md5_8h/","title":"File md5.h","text":"<p>FileList &gt; include &gt; utils &gt; md5.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;iomanip&gt;</code></li> <li><code>#include &lt;openssl/evp.h&gt;</code></li> <li><code>#include &lt;openssl/err.h&gt;</code></li> </ul>"},{"location":"xTorch/md5_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace utils <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/md5.h</code></p>"},{"location":"xTorch/md5_8h_source/","title":"File md5.h","text":"<p>File List &gt; include &gt; utils &gt; md5.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include &lt;iostream&gt;\n#include &lt;fstream&gt;\n//#include &lt;openssl/md5.h&gt;\n#include &lt;iomanip&gt;\n#include &lt;openssl/evp.h&gt;\n#include &lt;openssl/err.h&gt;\n\nnamespace xt::utils {\n    std::string get_md5_checksum(const std::string &amp;filename);\n}\n</code></pre>"},{"location":"xTorch/string_8h/","title":"File string.h","text":"<p>FileList &gt; include &gt; utils &gt; string.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;sstream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> </ul>"},{"location":"xTorch/string_8h/#namespaces","title":"Namespaces","text":"Type Name namespace xt namespace utils namespace string <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/string.h</code></p>"},{"location":"xTorch/string_8h_source/","title":"File string.h","text":"<p>File List &gt; include &gt; utils &gt; string.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n#include &lt;iostream&gt;\n//#include &lt;string&gt;\n#include &lt;sstream&gt;\n#include &lt;vector&gt;\nusing namespace std;\nnamespace xt::utils::string {\n    vector&lt;std::string&gt; split(const std::string&amp; str, const std::string&amp; delim);\n    std::string trim(std::string&amp; str);\n\n}\n\n\n</code></pre>"},{"location":"xTorch/utils_8h/","title":"File utils.h","text":"<p>FileList &gt; include &gt; utils &gt; utils.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"base.h\"</code></li> <li><code>#include \"downloader.h\"</code></li> <li><code>#include \"extract.h\"</code></li> <li><code>#include \"filesystem.h\"</code></li> <li><code>#include \"md5.h\"</code></li> <li><code>#include \"string.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/utils/utils.h</code></p>"},{"location":"xTorch/utils_8h_source/","title":"File utils.h","text":"<p>File List &gt; include &gt; utils &gt; utils.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"base.h\"\n#include \"downloader.h\"\n#include \"extract.h\"\n#include \"filesystem.h\"\n#include \"md5.h\"\n#include \"string.h\"\n</code></pre>"},{"location":"xTorch/xtorch_8h/","title":"File xtorch.h","text":"<p>FileList &gt; include &gt; xtorch.h</p> <p>Go to the source code of this file</p> <ul> <li><code>#include \"data-loaders/data-loaders.h\"</code></li> <li><code>#include \"datasets/datasets.h\"</code></li> <li><code>#include \"media/media.h\"</code></li> <li><code>#include \"models/models.h\"</code></li> <li><code>#include \"trainers/trainers.h\"</code></li> <li><code>#include \"transforms/transforms.h\"</code></li> <li><code>#include \"types/types.h\"</code></li> <li><code>#include \"utils/utils.h\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>/home/kami/Documents/cpp/models/include/xtorch.h</code></p>"},{"location":"xTorch/xtorch_8h_source/","title":"File xtorch.h","text":"<p>File List &gt; include &gt; xtorch.h</p> <p>Go to the documentation of this file</p> <pre><code>#pragma once\n\n#include \"data-loaders/data-loaders.h\"\n#include \"datasets/datasets.h\"\n#include \"media/media.h\"\n#include \"models/models.h\"\n#include \"trainers/trainers.h\"\n#include \"transforms/transforms.h\"\n#include \"types/types.h\"\n#include \"utils/utils.h\"\n\n\n\n\n\n</code></pre>"},{"location":"xTorch/namespaces/","title":"Namespace List","text":"<p>Here is a list of all namespaces with brief descriptions:</p> <ul> <li>namespace std </li> <li>namespace torch <ul> <li>namespace data <ul> <li>namespace datasets </li> </ul> </li> <li>namespace ext <ul> <li>namespace media <ul> <li>namespace image </li> <li>namespace opencv <ul> <li>namespace videos </li> </ul> </li> </ul> </li> </ul> </li> <li>namespace nn </li> </ul> </li> <li>namespace xt <ul> <li>namespace data <ul> <li>namespace datasets </li> <li>namespace transforms </li> </ul> </li> <li>namespace models </li> <li>namespace temp </li> <li>namespace utils <ul> <li>namespace fs </li> <li>namespace string </li> </ul> </li> </ul> </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> <li>namespace models </li> </ul>"},{"location":"xTorch/classes/","title":"Class Index","text":""},{"location":"xTorch/classes/#a","title":"a","text":"<ul> <li>AgNews (xt::data::datasets)</li> <li>AlexNet (xt::models)</li> <li>AmazonReview (xt::data::datasets)</li> <li>AudioDataset (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#b","title":"b","text":"<ul> <li>BaseDataset (xt::data::datasets)</li> <li>BaseModel (xt::models)</li> <li>Bottleneck (xt::models)</li> </ul>"},{"location":"xTorch/classes/#c","title":"c","text":"<ul> <li>Caltech101 (xt::data::datasets)</li> <li>Caltech256 (xt::data::datasets)</li> <li>CarlaStereo (xt::data::datasets)</li> <li>CelebA (xt::data::datasets)</li> <li>CenterCrop (xt::data::transforms)</li> <li>CIFAR10 (xt::data::datasets)</li> <li>CIFAR100 (xt::data::datasets)</li> <li>Cityscapes (xt::data::datasets)</li> <li>CMUArctic (xt::data::datasets)</li> <li>CocoCaptions (xt::data::datasets)</li> <li>CocoDetection (xt::data::datasets)</li> <li>COLA (xt::data::datasets)</li> <li>ColorJitter (xt::data::transforms)</li> <li>CommonVoice (xt::data::datasets)</li> <li>Compose (xt::data::transforms)</li> <li>CoNLL2000Chunking (xt::data::datasets)</li> <li>Country211 (xt::data::datasets)</li> <li>CremaD (xt::data::datasets)</li> <li>CREStereo (xt::data::datasets)</li> <li>CSVDataset (xt::data::datasets)</li> <li>Cutout (xt::data::transforms)</li> </ul>"},{"location":"xTorch/classes/#d","title":"d","text":"<ul> <li>DataLoader (xt)</li> <li>DatasetArguments</li> <li>DBPedia (xt::data::datasets)</li> <li>DoubleConv (xt::models)</li> <li>DownSample (xt::models)</li> <li>DTD (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#e","title":"e","text":"<ul> <li>EDFDataset (xt::data::datasets)</li> <li>EMNIST (xt::data::datasets)</li> <li>EnWik (xt::data::datasets)</li> <li>ESC (xt::data::datasets)</li> <li>ETH3DStereo (xt::data::datasets)</li> <li>EuroSAT (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#f","title":"f","text":"<ul> <li>FakeData (xt::data::datasets)</li> <li>FallingThingsStereo (xt::data::datasets)</li> <li>FashionMNIST (xt::data::datasets)</li> <li>FER2013 (xt::data::datasets)</li> <li>FGVCAircraft (xt::data::datasets)</li> <li>Flickr30k (xt::data::datasets)</li> <li>Flickr8k (xt::data::datasets)</li> <li>Flowers102 (xt::data::datasets)</li> <li>FlyingChairs (xt::data::datasets)</li> <li>FlyingThings3D (xt::data::datasets)</li> <li>Food101 (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#g","title":"g","text":"<ul> <li>GaussianBlur (xt::data::transforms)</li> <li>GaussianBlurOpenCV (xt::data::transforms)</li> <li>GaussianNoise (xt::data::transforms)</li> <li>Grayscale (xt::data::transforms)</li> <li>GrayscaleToRGB (xt::data::transforms)</li> <li>GTSRB (xt::data::datasets)</li> <li>GTZAN (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#h","title":"h","text":"<ul> <li>HD1K (xt::data::datasets)</li> <li>HMDB51 (xt::data::datasets)</li> <li>HorizontalFlip (xt::data::transforms)</li> <li>HSigmoid (xt::models)</li> <li>HSwish (xt::models)</li> </ul>"},{"location":"xTorch/classes/#i","title":"i","text":"<ul> <li>ImageFolder (xt::data::datasets)</li> <li>ImageNet (xt::data::datasets)</li> <li>Imagenette (xt::data::datasets)</li> <li>IMDB (xt::data::datasets)</li> <li>INaturalist (xt::data::datasets)</li> <li>InStereo2k (xt::data::datasets)</li> <li>IWSLT (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#k","title":"k","text":"<ul> <li>Kinetics (xt::data::datasets)</li> <li>Kitti (xt::data::datasets)</li> <li>Kitti2012Stereo (xt::data::datasets)</li> <li>Kitti2015Stereo (xt::data::datasets)</li> <li>KittiFlow (xt::data::datasets)</li> <li>KMNIST (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#l","title":"l","text":"<ul> <li>Lambda (xt::data::transforms)</li> <li>LeNet5 (xt::models)</li> <li>LFW (xt::data::datasets)</li> <li>LFWPairs (xt::data::datasets)</li> <li>LFWPeople (xt::data::datasets)</li> <li>LibriSpeech (xt::data::datasets)</li> <li>LjSpeech (xt::data::datasets)</li> <li>LSUN (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#m","title":"m","text":"<ul> <li>Middlebury2014Stereo (xt::data::datasets)</li> <li>MNIST (xt::data::datasets)</li> <li>MNISTBase (xt::data::datasets)</li> <li>MNLI (xt::data::datasets)</li> <li>MobileNetV3 (xt::models)</li> <li>Model (xt::models)</li> <li>MovingMNIST (xt::data::datasets)</li> <li>MRPC (xt::data::datasets)</li> <li>MULTI (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#n","title":"n","text":"<ul> <li>Normalize (xt::data::transforms)</li> <li>NotImplementedException</li> </ul>"},{"location":"xTorch/classes/#o","title":"o","text":"<ul> <li>Omniglot (xt::data::datasets)</li> <li>OxfordIIITPet (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#p","title":"p","text":"<ul> <li>Pad (xt::data::transforms)</li> <li>PCAM (xt::data::datasets)</li> <li>PennTreebank (xt::data::datasets)</li> <li>PhotoTour (xt::data::datasets)</li> <li>Places365 (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#q","title":"q","text":"<ul> <li>QMNIST (xt::data::datasets)</li> <li>QNLI (xt::data::datasets)</li> <li>QQP (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#r","title":"r","text":"<ul> <li>RandomCrop (xt::data::transforms)</li> <li>RandomCrop2 (xt::data::transforms)</li> <li>RandomFlip (xt::data::transforms)</li> <li>RandomGaussianBlur (xt::data::transforms)</li> <li>RenderedSST2 (xt::data::datasets)</li> <li>Resize (xt::data::transforms)</li> <li>ResNet (xt::models)</li> <li>Rotation (xt::data::transforms)</li> <li>RTE (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#s","title":"s","text":"<ul> <li>SBDataset (xt::data::datasets)</li> <li>SBU (xt::data::datasets)</li> <li>SceneFlowStereo (xt::data::datasets)</li> <li>SEMEION (xt::data::datasets)</li> <li>Sintel (xt::data::datasets)</li> <li>SintelStereo (xt::data::datasets)</li> <li>SNLI (xt::data::datasets)</li> <li>SogouNews (xt::data::datasets)</li> <li>SpeechCommands (xt::data::datasets)</li> <li>SqueezeExcite (xt::models)</li> <li>SST (xt::data::datasets)</li> <li>StackedAudioDataset (xt::data::datasets)</li> <li>StackedCSVDataset (xt::data::datasets)</li> <li>StackedEDFDataset (xt::data::datasets)</li> <li>StackedTextDataset (xt::data::datasets)</li> <li>StackedTimeSeriesDataset (xt::data::datasets)</li> <li>StackedVideoDataset (xt::data::datasets)</li> <li>StanfordCars (xt::data::datasets)</li> <li>STL10 (xt::data::datasets)</li> <li>STSB (xt::data::datasets)</li> <li>SUN397 (xt::data::datasets)</li> <li>SVHN (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#t","title":"t","text":"<ul> <li>Tedlium (xt::data::datasets)</li> <li>TensorDataset (xt::data::datasets)</li> <li>TestDataset (xt::temp)</li> <li>TextDataset (xt::data::datasets)</li> <li>TimeSeriesDataset (xt::data::datasets)</li> <li>TIMIT (xt::data::datasets)</li> <li>ToGray (xt::data::transforms)</li> <li>ToTensor (xt::data::transforms)</li> <li>Trainer (xt)</li> </ul>"},{"location":"xTorch/classes/#u","title":"u","text":"<ul> <li>UCF101 (xt::data::datasets)</li> <li>UDPOS (xt::data::datasets)</li> <li>UNet (xt::models)</li> <li>UpSample (xt::models)</li> <li>UrbanSound (xt::data::datasets)</li> <li>USPS (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#v","title":"v","text":"<ul> <li>VCTK (xt::data::datasets)</li> <li>VerticalFlip (xt::data::transforms)</li> <li>VggNet16 (xt::models)</li> <li>VideoDataset (xt::data::datasets)</li> <li>VOCDetection (xt::data::datasets)</li> <li>VOCSegmentation (xt::data::datasets)</li> <li>VoxCeleb (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#w","title":"w","text":"<ul> <li>WIDERFace (xt::data::datasets)</li> <li>WikiText (xt::data::datasets)</li> <li>WMT (xt::data::datasets)</li> <li>WNLI (xt::data::datasets)</li> </ul>"},{"location":"xTorch/classes/#y","title":"y","text":"<ul> <li>YahooAnswers (xt::data::datasets)</li> <li>YelpReview (xt::data::datasets)</li> <li>YesNo (xt::data::datasets)</li> </ul>"},{"location":"xTorch/hierarchy/","title":"Class Hierarchy","text":"<p>This inheritance list is sorted roughly, but not completely, alphabetically:</p> <ul> <li>class xt::Trainer </li> <li>class xt::data::transforms::Compose A class to compose multiple tensor transformations into a single callable pipeline. </li> <li>class xt::temp::TestDataset </li> <li>struct DatasetArguments </li> <li>struct xt::data::transforms::CenterCrop </li> <li>struct xt::data::transforms::ColorJitter </li> <li>struct xt::data::transforms::Cutout </li> <li>struct xt::data::transforms::GaussianBlur </li> <li>struct xt::data::transforms::GaussianBlurOpenCV </li> <li>struct xt::data::transforms::GaussianNoise </li> <li>struct xt::data::transforms::Grayscale </li> <li>struct xt::data::transforms::GrayscaleToRGB A functor to convert a grayscale tensor to an RGB tensor. </li> <li>struct xt::data::transforms::HorizontalFlip </li> <li>struct xt::data::transforms::Lambda </li> <li>struct xt::data::transforms::Normalize </li> <li>struct xt::data::transforms::Pad A functor to pad a tensor with a specified padding configuration. </li> <li>struct xt::data::transforms::RandomCrop </li> <li>struct xt::data::transforms::RandomCrop2 </li> <li>struct xt::data::transforms::RandomFlip </li> <li>struct xt::data::transforms::RandomGaussianBlur </li> <li>struct xt::data::transforms::Resize A functor to resize a tensor image to a specified size. </li> <li>struct xt::data::transforms::Rotation </li> <li>struct xt::data::transforms::ToGray </li> <li>struct xt::data::transforms::ToTensor </li> <li>struct xt::data::transforms::VerticalFlip </li> <li>class std::logic_error <ul> <li>class NotImplementedException </li> </ul> </li> <li>class torch::data::DataLoaderBase&lt; Dataset, Dataset::BatchType, std::vector&lt; size_t &gt; &gt; <ul> <li>class xt::DataLoader </li> </ul> </li> <li>class torch::data::Dataset&lt; BaseDataset &gt; <ul> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> <li>class xt::data::datasets::BaseDataset <ul> <li>class xt::data::datasets::AgNews </li> <li>class xt::data::datasets::AmazonReview </li> <li>class xt::data::datasets::CIFAR10 </li> <li>class xt::data::datasets::CIFAR100 </li> <li>class xt::data::datasets::CMUArctic </li> <li>class xt::data::datasets::COLA </li> <li>class xt::data::datasets::CREStereo </li> <li>class xt::data::datasets::CSVDataset </li> <li>class xt::data::datasets::Caltech101 </li> <li>class xt::data::datasets::Caltech256 </li> <li>class xt::data::datasets::CarlaStereo </li> <li>class xt::data::datasets::CelebA </li> <li>class xt::data::datasets::Cityscapes </li> <li>class xt::data::datasets::CoNLL2000Chunking </li> <li>class xt::data::datasets::CocoCaptions </li> <li>class xt::data::datasets::CocoDetection </li> <li>class xt::data::datasets::CommonVoice </li> <li>class xt::data::datasets::Country211 </li> <li>class xt::data::datasets::CremaD </li> <li>class xt::data::datasets::DBPedia </li> <li>class xt::data::datasets::DTD </li> <li>class xt::data::datasets::EDFDataset </li> <li>class xt::data::datasets::ESC </li> <li>class xt::data::datasets::ETH3DStereo </li> <li>class xt::data::datasets::EnWik </li> <li>class xt::data::datasets::EuroSAT </li> <li>class xt::data::datasets::FER2013 </li> <li>class xt::data::datasets::FGVCAircraft </li> <li>class xt::data::datasets::FakeData </li> <li>class xt::data::datasets::FallingThingsStereo </li> <li>class xt::data::datasets::Flickr30k </li> <li>class xt::data::datasets::Flickr8k </li> <li>class xt::data::datasets::Flowers102 </li> <li>class xt::data::datasets::FlyingChairs </li> <li>class xt::data::datasets::FlyingThings3D </li> <li>class xt::data::datasets::Food101 </li> <li>class xt::data::datasets::GTSRB </li> <li>class xt::data::datasets::GTZAN </li> <li>class xt::data::datasets::HD1K </li> <li>class xt::data::datasets::HMDB51 </li> <li>class xt::data::datasets::IMDB </li> <li>class xt::data::datasets::INaturalist </li> <li>class xt::data::datasets::IWSLT </li> <li>class xt::data::datasets::ImageFolder </li> <li>class xt::data::datasets::ImageNet </li> <li>class xt::data::datasets::Imagenette </li> <li>class xt::data::datasets::InStereo2k </li> <li>class xt::data::datasets::Kinetics </li> <li>class xt::data::datasets::Kitti </li> <li>class xt::data::datasets::Kitti2012Stereo </li> <li>class xt::data::datasets::Kitti2015Stereo </li> <li>class xt::data::datasets::KittiFlow </li> <li>class xt::data::datasets::LFW <ul> <li>class xt::data::datasets::LFWPairs </li> <li>class xt::data::datasets::LFWPeople </li> </ul> </li> <li>class xt::data::datasets::LSUN </li> <li>class xt::data::datasets::LibriSpeech </li> <li>class xt::data::datasets::LjSpeech </li> <li>class xt::data::datasets::MNISTBase <ul> <li>class xt::data::datasets::EMNIST </li> <li>class xt::data::datasets::FashionMNIST </li> <li>class xt::data::datasets::KMNIST </li> <li>class xt::data::datasets::MNIST </li> <li>class xt::data::datasets::QMNIST </li> </ul> </li> <li>class xt::data::datasets::MNLI </li> <li>class xt::data::datasets::MRPC </li> <li>class xt::data::datasets::MULTI </li> <li>class xt::data::datasets::Middlebury2014Stereo </li> <li>class xt::data::datasets::MovingMNIST </li> <li>class xt::data::datasets::Omniglot </li> <li>class xt::data::datasets::OxfordIIITPet </li> <li>class xt::data::datasets::PCAM </li> <li>class xt::data::datasets::PennTreebank </li> <li>class xt::data::datasets::PhotoTour </li> <li>class xt::data::datasets::Places365 </li> <li>class xt::data::datasets::QNLI </li> <li>class xt::data::datasets::QQP </li> <li>class xt::data::datasets::RTE </li> <li>class xt::data::datasets::RenderedSST2 </li> <li>class xt::data::datasets::SBDataset </li> <li>class xt::data::datasets::SBU </li> <li>class xt::data::datasets::SEMEION </li> <li>class xt::data::datasets::SNLI </li> <li>class xt::data::datasets::SST </li> <li>class xt::data::datasets::STL10 </li> <li>class xt::data::datasets::STSB </li> <li>class xt::data::datasets::SUN397 </li> <li>class xt::data::datasets::SVHN </li> <li>class xt::data::datasets::SceneFlowStereo </li> <li>class xt::data::datasets::Sintel </li> <li>class xt::data::datasets::SintelStereo </li> <li>class xt::data::datasets::SogouNews </li> <li>class xt::data::datasets::SpeechCommands </li> <li>class xt::data::datasets::StackedAudioDataset </li> <li>class xt::data::datasets::StackedCSVDataset </li> <li>class xt::data::datasets::StackedEDFDataset </li> <li>class xt::data::datasets::StackedTextDataset </li> <li>class xt::data::datasets::StackedTimeSeriesDataset </li> <li>class xt::data::datasets::StackedVideoDataset </li> <li>class xt::data::datasets::StanfordCars </li> <li>class xt::data::datasets::TIMIT </li> <li>class xt::data::datasets::Tedlium </li> <li>class xt::data::datasets::TensorDataset </li> <li>class xt::data::datasets::TextDataset </li> <li>class xt::data::datasets::TimeSeriesDataset </li> <li>class xt::data::datasets::UCF101 </li> <li>class xt::data::datasets::UDPOS </li> <li>class xt::data::datasets::USPS </li> <li>class xt::data::datasets::UrbanSound </li> <li>class xt::data::datasets::VCTK </li> <li>class xt::data::datasets::VOCDetection </li> <li>class xt::data::datasets::VOCSegmentation </li> <li>class xt::data::datasets::VideoDataset </li> <li>class xt::data::datasets::VoxCeleb </li> <li>class xt::data::datasets::WIDERFace </li> <li>class xt::data::datasets::WMT </li> <li>class xt::data::datasets::WNLI </li> <li>class xt::data::datasets::WikiText </li> <li>class xt::data::datasets::YahooAnswers </li> <li>class xt::data::datasets::YelpReview </li> <li>class xt::data::datasets::YesNo </li> </ul> </li> </ul> </li> <li>class torch::data::datasets::Dataset&lt; AudioDataset &gt; <ul> <li>class xt::data::datasets::AudioDataset </li> </ul> </li> <li>class torch::nn::Module <ul> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>struct xt::models::Bottleneck </li> <li>struct xt::models::Bottleneck </li> <li>struct xt::models::Bottleneck </li> <li>struct xt::models::DoubleConv </li> <li>struct xt::models::DownSample </li> <li>struct xt::models::HSigmoid </li> <li>struct xt::models::HSigmoid </li> <li>struct xt::models::HSigmoid </li> <li>struct xt::models::HSwish </li> <li>struct xt::models::HSwish </li> <li>struct xt::models::HSwish </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>struct xt::models::SqueezeExcite </li> <li>struct xt::models::SqueezeExcite </li> <li>struct xt::models::SqueezeExcite </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>struct xt::models::UpSample </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> <li>class xt::models::BaseModel <ul> <li>struct xt::models::AlexNet </li> <li>struct xt::models::LeNet5 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>struct xt::models::MobileNetV3 </li> <li>class xt::models::Model </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::ResNet </li> <li>struct xt::models::UNet </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> <li>struct xt::models::VggNet16 </li> </ul> </li> </ul> </li> </ul>"},{"location":"xTorch/modules/","title":"Modules","text":"<p>No modules found.</p>"},{"location":"xTorch/pages/","title":"Related Pages","text":"<p>Here is a list of all related documentation pages:</p>"},{"location":"xTorch/class_members/","title":"Class Members","text":""},{"location":"xTorch/class_members/#a","title":"a","text":"<ul> <li>AgNews (xt::data::datasets::AgNews)</li> <li>AmazonReview (xt::data::datasets::AmazonReview)</li> <li>AudioDataset (xt::data::datasets::AudioDataset)</li> <li>archive_file_md5 (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT, xt::data::datasets::QMNIST)</li> <li>archive_file_name (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT)</li> <li>annot_file (xt::data::datasets::LFW)</li> <li>ANNOTATIONS_FILE (xt::data::datasets::WIDERFace)</li> <li>angle (xt::data::transforms::Rotation)</li> <li>AlexNet (xt::models::AlexNet)</li> <li>a (xt::models::Model)</li> <li>avgpool (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_members/#b","title":"b","text":"<ul> <li>Base (xt::DataLoader)</li> <li>BatchRequestType (xt::DataLoader)</li> <li>BatchType (xt::DataLoader)</li> <li>batch_size_ (xt::DataLoader)</li> <li>BaseDataset (xt::data::datasets::BaseDataset)</li> <li>brightness (xt::data::transforms::ColorJitter)</li> <li>BaseModel (xt::models::BaseModel)</li> <li>Bottleneck (xt::models::Bottleneck)</li> <li>bottleneck (xt::models::Bottleneck)</li> <li>bottlenecks (xt::models::MobileNetV3)</li> <li>bottle_neck (xt::models::UNet)</li> </ul>"},{"location":"xTorch/class_members/#c","title":"c","text":"<ul> <li>current_index_ (xt::DataLoader)</li> <li>checkpoint_enabled_ (xt::Trainer)</li> <li>checkpoint_interval_ (xt::Trainer)</li> <li>checkpoint_path_ (xt::Trainer)</li> <li>check_resources (xt::data::datasets::AgNews, xt::data::datasets::AmazonReview, xt::data::datasets::CMUArctic, xt::data::datasets::COLA, xt::data::datasets::CREStereo, xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CarlaStereo, xt::data::datasets::CelebA, xt::data::datasets::Cityscapes, xt::data::datasets::CoNLL2000Chunking, xt::data::datasets::CocoCaptions, xt::data::datasets::CocoDetection, xt::data::datasets::CommonVoice, xt::data::datasets::CremaD, xt::data::datasets::DBPedia, xt::data::datasets::DTD, xt::data::datasets::EMNIST, xt::data::datasets::ESC, xt::data::datasets::ETH3DStereo, xt::data::datasets::EnWik, xt::data::datasets::EuroSAT, xt::data::datasets::FER2013, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Flickr30k, xt::data::datasets::Flickr8k, xt::data::datasets::Flowers102, xt::data::datasets::FlyingChairs, xt::data::datasets::FlyingThings3D, xt::data::datasets::Food101, xt::data::datasets::GTSRB, xt::data::datasets::GTZAN, xt::data::datasets::HD1K, xt::data::datasets::HMDB51, xt::data::datasets::IMDB, xt::data::datasets::INaturalist, xt::data::datasets::IWSLT, xt::data::datasets::ImageNet, xt::data::datasets::Imagenette, xt::data::datasets::InStereo2k, xt::data::datasets::KMNIST, xt::data::datasets::Kinetics, xt::data::datasets::Kitti, xt::data::datasets::Kitti2012Stereo, xt::data::datasets::Kitti2015Stereo, xt::data::datasets::KittiFlow, xt::data::datasets::LFW, xt::data::datasets::LFWPairs, xt::data::datasets::LFWPeople, xt::data::datasets::LSUN, xt::data::datasets::LibriSpeech, xt::data::datasets::LjSpeech, xt::data::datasets::MNIST, xt::data::datasets::MNLI, xt::data::datasets::MRPC, xt::data::datasets::MULTI, xt::data::datasets::Middlebury2014Stereo, xt::data::datasets::MovingMNIST, xt::data::datasets::Omniglot, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PennTreebank, xt::data::datasets::PhotoTour, xt::data::datasets::Places365, xt::data::datasets::QMNIST, xt::data::datasets::QNLI, xt::data::datasets::QQP, xt::data::datasets::RTE, xt::data::datasets::RenderedSST2, xt::data::datasets::SBDataset, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::SNLI, xt::data::datasets::SST, xt::data::datasets::STL10, xt::data::datasets::STSB, xt::data::datasets::SUN397, xt::data::datasets::SVHN, xt::data::datasets::SceneFlowStereo, xt::data::datasets::Sintel, xt::data::datasets::SintelStereo, xt::data::datasets::SogouNews, xt::data::datasets::SpeechCommands, xt::data::datasets::StanfordCars, xt::data::datasets::TIMIT, xt::data::datasets::Tedlium, xt::data::datasets::UCF101, xt::data::datasets::UDPOS, xt::data::datasets::USPS, xt::data::datasets::UrbanSound, xt::data::datasets::VCTK, xt::data::datasets::VOCDetection, xt::data::datasets::VOCSegmentation, xt::data::datasets::VoxCeleb, xt::data::datasets::WIDERFace, xt::data::datasets::WMT, xt::data::datasets::WNLI, xt::data::datasets::WikiText, xt::data::datasets::YahooAnswers, xt::data::datasets::YelpReview, xt::data::datasets::YesNo)</li> <li>compose (xt::data::datasets::BaseDataset)</li> <li>CIFAR10 (xt::data::datasets::CIFAR10)</li> <li>CIFAR100 (xt::data::datasets::CIFAR100)</li> <li>CMUArctic (xt::data::datasets::CMUArctic)</li> <li>COLA (xt::data::datasets::COLA)</li> <li>CREStereo (xt::data::datasets::CREStereo)</li> <li>CSVDataset (xt::data::datasets::CSVDataset)</li> <li>Caltech101 (xt::data::datasets::Caltech101)</li> <li>Caltech256 (xt::data::datasets::Caltech256)</li> <li>CarlaStereo (xt::data::datasets::CarlaStereo)</li> <li>CelebA (xt::data::datasets::CelebA)</li> <li>Cityscapes (xt::data::datasets::Cityscapes)</li> <li>CoNLL2000Chunking (xt::data::datasets::CoNLL2000Chunking)</li> <li>CocoCaptions (xt::data::datasets::CocoCaptions)</li> <li>CocoDetection (xt::data::datasets::CocoDetection)</li> <li>CommonVoice (xt::data::datasets::CommonVoice)</li> <li>Country211 (xt::data::datasets::Country211)</li> <li>CremaD (xt::data::datasets::CremaD)</li> <li>classes_map (xt::data::datasets::Food101)</li> <li>classes_name (xt::data::datasets::Food101)</li> <li>checksums (xt::data::datasets::LFW)</li> <li>class_names_file (xt::data::datasets::STL10)</li> <li>CenterCrop (xt::data::transforms::CenterCrop)</li> <li>ColorJitter (xt::data::transforms::ColorJitter)</li> <li>contrast (xt::data::transforms::ColorJitter)</li> <li>Compose (xt::data::transforms::Compose)</li> <li>Cutout (xt::data::transforms::Cutout)</li> <li>crop_height (xt::data::transforms::RandomCrop2)</li> <li>crop_width (xt::data::transforms::RandomCrop2)</li> <li>conv_op (xt::models::DoubleConv)</li> <li>conv (xt::models::DownSample, xt::models::UpSample)</li> <li>classifier (xt::models::MobileNetV3)</li> <li>conv1 (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_members/#d","title":"d","text":"<ul> <li>download (DatasetArguments, xt::data::datasets::BaseDataset)</li> <li>DataLoader (xt::DataLoader)</li> <li>dataset_ptr_ (xt::DataLoader)</li> <li>drop_last_ (xt::DataLoader)</li> <li>data (xt::data::datasets::BaseDataset)</li> <li>dataset_path (xt::data::datasets::BaseDataset, xt::data::datasets::QMNIST)</li> <li>dataset_folder_name (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CelebA, xt::data::datasets::Country211, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Food101, xt::data::datasets::INaturalist, xt::data::datasets::Imagenette, xt::data::datasets::KMNIST, xt::data::datasets::Kitti, xt::data::datasets::LFW, xt::data::datasets::MNIST, xt::data::datasets::Middlebury2014Stereo, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PhotoTour, xt::data::datasets::QMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397, xt::data::datasets::SceneFlowStereo, xt::data::datasets::WIDERFace)</li> <li>dataset_file_md5 (xt::data::datasets::Country211, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::Food101, xt::data::datasets::MovingMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397)</li> <li>dataset_file_name (xt::data::datasets::Country211, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::Food101, xt::data::datasets::MovingMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397)</li> <li>DBPedia (xt::data::datasets::DBPedia)</li> <li>DTD (xt::data::datasets::DTD)</li> <li>downsample (xt::models::Bottleneck)</li> <li>DoubleConv (xt::models::DoubleConv)</li> <li>DownSample (xt::models::DownSample)</li> <li>down_convolution_1 (xt::models::UNet)</li> <li>down_convolution_2 (xt::models::UNet)</li> <li>down_convolution_3 (xt::models::UNet)</li> <li>down_convolution_4 (xt::models::UNet)</li> </ul>"},{"location":"xTorch/class_members/#e","title":"e","text":"<ul> <li>enable_checkpoint (xt::Trainer)</li> <li>EDFDataset (xt::data::datasets::EDFDataset)</li> <li>EMNIST (xt::data::datasets::EMNIST)</li> <li>ESC (xt::data::datasets::ESC)</li> <li>ETH3DStereo (xt::data::datasets::ETH3DStereo)</li> <li>EnWik (xt::data::datasets::EnWik)</li> <li>EuroSAT (xt::data::datasets::EuroSAT)</li> </ul>"},{"location":"xTorch/class_members/#f","title":"f","text":"<ul> <li>fit (xt::Trainer)</li> <li>file_paths (xt::data::datasets::AudioDataset)</li> <li>FER2013 (xt::data::datasets::FER2013)</li> <li>FGVCAircraft (xt::data::datasets::FGVCAircraft)</li> <li>FakeData (xt::data::datasets::FakeData)</li> <li>FallingThingsStereo (xt::data::datasets::FallingThingsStereo)</li> <li>FashionMNIST (xt::data::datasets::FashionMNIST)</li> <li>files (xt::data::datasets::FashionMNIST, xt::data::datasets::KMNIST, xt::data::datasets::MNIST)</li> <li>Flickr30k (xt::data::datasets::Flickr30k)</li> <li>Flickr8k (xt::data::datasets::Flickr8k)</li> <li>Flowers102 (xt::data::datasets::Flowers102)</li> <li>FlyingChairs (xt::data::datasets::FlyingChairs)</li> <li>FlyingThings3D (xt::data::datasets::FlyingThings3D)</li> <li>Food101 (xt::data::datasets::Food101)</li> <li>file_dict (xt::data::datasets::LFW)</li> <li>filename (xt::data::datasets::SBDataset)</li> <li>folds_list_file (xt::data::datasets::STL10)</li> <li>fc (xt::models::AlexNet, xt::models::ResNet, xt::models::VggNet16)</li> <li>fc1 (xt::models::AlexNet, xt::models::LeNet5, xt::models::VggNet16)</li> <li>fc2 (xt::models::AlexNet, xt::models::LeNet5, xt::models::VggNet16)</li> <li>forward (xt::models::AlexNet, xt::models::BaseModel, xt::models::Bottleneck, xt::models::DoubleConv, xt::models::DownSample, xt::models::HSigmoid, xt::models::HSwish, xt::models::LeNet5, xt::models::MobileNetV3, xt::models::Model, xt::models::ResNet, xt::models::SqueezeExcite, xt::models::UNet, xt::models::UpSample, xt::models::VggNet16, xt::temp::TestDataset)</li> <li>fc3 (xt::models::LeNet5)</li> <li>final_conv (xt::models::MobileNetV3)</li> </ul>"},{"location":"xTorch/class_members/#g","title":"g","text":"<ul> <li>get_batch_request (xt::DataLoader)</li> <li>get (xt::data::datasets::AudioDataset, xt::data::datasets::BaseDataset, xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100)</li> <li>generate_data (xt::data::datasets::FakeData)</li> <li>GTSRB (xt::data::datasets::GTSRB)</li> <li>GTZAN (xt::data::datasets::GTZAN)</li> <li>GaussianBlur (xt::data::transforms::GaussianBlur)</li> <li>generate_gaussian_kernel (xt::data::transforms::GaussianBlur)</li> <li>GaussianBlurOpenCV (xt::data::transforms::GaussianBlurOpenCV)</li> <li>GaussianNoise (xt::data::transforms::GaussianNoise)</li> <li>Grayscale (xt::data::transforms::Grayscale)</li> </ul>"},{"location":"xTorch/class_members/#h","title":"h","text":"<ul> <li>HD1K (xt::data::datasets::HD1K)</li> <li>HMDB51 (xt::data::datasets::HMDB51)</li> <li>hole_size (xt::data::transforms::Cutout)</li> <li>HorizontalFlip (xt::data::transforms::HorizontalFlip)</li> <li>horizontal_prob (xt::data::transforms::RandomFlip)</li> <li>HSigmoid (xt::models::HSigmoid)</li> <li>HSwish (xt::models::HSwish)</li> </ul>"},{"location":"xTorch/class_members/#i","title":"i","text":"<ul> <li>indices_ (xt::DataLoader)</li> <li>images_number (xt::data::datasets::Food101)</li> <li>IMDB (xt::data::datasets::IMDB)</li> <li>INaturalist (xt::data::datasets::INaturalist)</li> <li>IWSLT (xt::data::datasets::IWSLT)</li> <li>ImageFolder (xt::data::datasets::ImageFolder)</li> <li>ImageNet (xt::data::datasets::ImageNet)</li> <li>Imagenette (xt::data::datasets::Imagenette)</li> <li>InStereo2k (xt::data::datasets::InStereo2k)</li> <li>image_dir_name (xt::data::datasets::Kitti)</li> <li>initial_conv (xt::models::MobileNetV3)</li> <li>inplanes (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_members/#k","title":"k","text":"<ul> <li>KMNIST (xt::data::datasets::KMNIST)</li> <li>Kinetics (xt::data::datasets::Kinetics)</li> <li>Kitti (xt::data::datasets::Kitti)</li> <li>Kitti2012Stereo (xt::data::datasets::Kitti2012Stereo)</li> <li>Kitti2015Stereo (xt::data::datasets::Kitti2015Stereo)</li> <li>KittiFlow (xt::data::datasets::KittiFlow)</li> <li>kernel_size (xt::data::transforms::GaussianBlur, xt::data::transforms::GaussianBlurOpenCV)</li> <li>kernel_sizes (xt::data::transforms::RandomGaussianBlur)</li> </ul>"},{"location":"xTorch/class_members/#l","title":"l","text":"<ul> <li>loss_fn_ (xt::Trainer)</li> <li>load_data (xt::data::datasets::AgNews, xt::data::datasets::AmazonReview, xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::CMUArctic, xt::data::datasets::COLA, xt::data::datasets::CREStereo, xt::data::datasets::CSVDataset, xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CarlaStereo, xt::data::datasets::CelebA, xt::data::datasets::Cityscapes, xt::data::datasets::CoNLL2000Chunking, xt::data::datasets::CocoCaptions, xt::data::datasets::CocoDetection, xt::data::datasets::CommonVoice, xt::data::datasets::CremaD, xt::data::datasets::DBPedia, xt::data::datasets::DTD, xt::data::datasets::EDFDataset, xt::data::datasets::EMNIST, xt::data::datasets::ESC, xt::data::datasets::ETH3DStereo, xt::data::datasets::EnWik, xt::data::datasets::EuroSAT, xt::data::datasets::FER2013, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Flickr30k, xt::data::datasets::Flickr8k, xt::data::datasets::Flowers102, xt::data::datasets::FlyingChairs, xt::data::datasets::FlyingThings3D, xt::data::datasets::Food101, xt::data::datasets::GTSRB, xt::data::datasets::GTZAN, xt::data::datasets::HD1K, xt::data::datasets::HMDB51, xt::data::datasets::IMDB, xt::data::datasets::INaturalist, xt::data::datasets::IWSLT, xt::data::datasets::ImageFolder, xt::data::datasets::ImageNet, xt::data::datasets::Imagenette, xt::data::datasets::InStereo2k, xt::data::datasets::KMNIST, xt::data::datasets::Kinetics, xt::data::datasets::Kitti, xt::data::datasets::Kitti2012Stereo, xt::data::datasets::Kitti2015Stereo, xt::data::datasets::KittiFlow, xt::data::datasets::LFW, xt::data::datasets::LFWPairs, xt::data::datasets::LFWPeople, xt::data::datasets::LSUN, xt::data::datasets::LibriSpeech, xt::data::datasets::LjSpeech, xt::data::datasets::MNIST, xt::data::datasets::MNLI, xt::data::datasets::MRPC, xt::data::datasets::MULTI, xt::data::datasets::Middlebury2014Stereo, xt::data::datasets::MovingMNIST, xt::data::datasets::Omniglot, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PennTreebank, xt::data::datasets::PhotoTour, xt::data::datasets::Places365, xt::data::datasets::QMNIST, xt::data::datasets::QNLI, xt::data::datasets::QQP, xt::data::datasets::RTE, xt::data::datasets::RenderedSST2, xt::data::datasets::SBDataset, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::SNLI, xt::data::datasets::SST, xt::data::datasets::STL10, xt::data::datasets::STSB, xt::data::datasets::SUN397, xt::data::datasets::SVHN, xt::data::datasets::SceneFlowStereo, xt::data::datasets::Sintel, xt::data::datasets::SintelStereo, xt::data::datasets::SogouNews, xt::data::datasets::SpeechCommands, xt::data::datasets::StackedAudioDataset, xt::data::datasets::StackedCSVDataset, xt::data::datasets::StackedEDFDataset, xt::data::datasets::StackedTextDataset, xt::data::datasets::StackedTimeSeriesDataset, xt::data::datasets::StackedVideoDataset, xt::data::datasets::StanfordCars, xt::data::datasets::TIMIT, xt::data::datasets::Tedlium, xt::data::datasets::TensorDataset, xt::data::datasets::TextDataset, xt::data::datasets::TimeSeriesDataset, xt::data::datasets::UCF101, xt::data::datasets::UDPOS, xt::data::datasets::USPS, xt::data::datasets::UrbanSound, xt::data::datasets::VCTK, xt::data::datasets::VOCDetection, xt::data::datasets::VOCSegmentation, xt::data::datasets::VideoDataset, xt::data::datasets::VoxCeleb, xt::data::datasets::WIDERFace, xt::data::datasets::WMT, xt::data::datasets::WNLI, xt::data::datasets::WikiText, xt::data::datasets::YahooAnswers, xt::data::datasets::YelpReview, xt::data::datasets::YesNo)</li> <li>labels (xt::data::datasets::AudioDataset, xt::data::datasets::BaseDataset)</li> <li>labels_name (xt::data::datasets::CSVDataset, xt::data::datasets::EDFDataset, xt::data::datasets::ImageFolder, xt::data::datasets::Imagenette, xt::data::datasets::StackedAudioDataset, xt::data::datasets::StackedCSVDataset, xt::data::datasets::StackedEDFDataset, xt::data::datasets::StackedTextDataset, xt::data::datasets::StackedTimeSeriesDataset, xt::data::datasets::StackedVideoDataset, xt::data::datasets::TensorDataset, xt::data::datasets::TextDataset, xt::data::datasets::TimeSeriesDataset, xt::data::datasets::VideoDataset)</li> <li>load_sub_folders (xt::data::datasets::CSVDataset, xt::data::datasets::EDFDataset, xt::data::datasets::ImageFolder, xt::data::datasets::StackedAudioDataset, xt::data::datasets::StackedCSVDataset, xt::data::datasets::StackedEDFDataset, xt::data::datasets::StackedTextDataset, xt::data::datasets::StackedTimeSeriesDataset, xt::data::datasets::StackedVideoDataset, xt::data::datasets::TensorDataset, xt::data::datasets::TextDataset, xt::data::datasets::TimeSeriesDataset, xt::data::datasets::VideoDataset)</li> <li>load_classes (xt::data::datasets::Food101)</li> <li>label_type (xt::data::datasets::ImageFolder)</li> <li>labels_dir_name (xt::data::datasets::Kitti)</li> <li>LFW (xt::data::datasets::LFW)</li> <li>LFWPairs (xt::data::datasets::LFWPairs)</li> <li>LFWPeople (xt::data::datasets::LFWPeople)</li> <li>LSUN (xt::data::datasets::LSUN)</li> <li>LibriSpeech (xt::data::datasets::LibriSpeech)</li> <li>LjSpeech (xt::data::datasets::LjSpeech)</li> <li>Lambda (xt::data::transforms::Lambda)</li> <li>layer1 (xt::models::AlexNet, xt::models::LeNet5, xt::models::ResNet, xt::models::VggNet16)</li> <li>layer2 (xt::models::AlexNet, xt::models::LeNet5, xt::models::ResNet, xt::models::VggNet16)</li> <li>layer3 (xt::models::AlexNet, xt::models::ResNet, xt::models::VggNet16)</li> <li>layer4 (xt::models::AlexNet, xt::models::VggNet16)</li> <li>layer5 (xt::models::AlexNet, xt::models::VggNet16)</li> <li>LeNet5 (xt::models::LeNet5)</li> <li>layer0 (xt::models::ResNet)</li> <li>layer10 (xt::models::VggNet16)</li> <li>layer11 (xt::models::VggNet16)</li> <li>layer12 (xt::models::VggNet16)</li> <li>layer13 (xt::models::VggNet16)</li> <li>layer6 (xt::models::VggNet16)</li> <li>layer7 (xt::models::VggNet16)</li> <li>layer8 (xt::models::VggNet16)</li> <li>layer9 (xt::models::VggNet16)</li> </ul>"},{"location":"xTorch/class_members/#m","title":"m","text":"<ul> <li>mode (DatasetArguments, xt::data::datasets::BaseDataset)</li> <li>max_epochs_ (xt::Trainer)</li> <li>MNIST (xt::data::datasets::MNIST)</li> <li>MNISTBase (xt::data::datasets::MNISTBase)</li> <li>MNLI (xt::data::datasets::MNLI)</li> <li>MRPC (xt::data::datasets::MRPC)</li> <li>MULTI (xt::data::datasets::MULTI)</li> <li>Middlebury2014Stereo (xt::data::datasets::Middlebury2014Stereo)</li> <li>MovingMNIST (xt::data::datasets::MovingMNIST)</li> <li>md5 (xt::data::datasets::SBDataset)</li> <li>mean (xt::data::transforms::GaussianNoise, xt::data::transforms::Normalize)</li> <li>MobileNetV3 (xt::models::MobileNetV3)</li> <li>Model (xt::models::Model)</li> <li>makeLayerFromResidualBlock (xt::models::ResNet)</li> <li>maxpool (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_members/#n","title":"n","text":"<ul> <li>NotImplementedException (NotImplementedException)</li> <li>names (xt::data::datasets::LFW)</li> <li>num_holes (xt::data::transforms::Cutout)</li> <li>Normalize (xt::data::transforms::Normalize)</li> </ul>"},{"location":"xTorch/class_members/#o","title":"o","text":"<ul> <li>optimizer_ (xt::Trainer)</li> <li>Omniglot (xt::data::datasets::Omniglot)</li> <li>OxfordIIITPet (xt::data::datasets::OxfordIIITPet)</li> <li>operator() (xt::data::transforms::CenterCrop, xt::data::transforms::ColorJitter, xt::data::transforms::Compose, xt::data::transforms::Cutout, xt::data::transforms::GaussianBlur, xt::data::transforms::GaussianBlurOpenCV, xt::data::transforms::GaussianNoise, xt::data::transforms::Grayscale, xt::data::transforms::GrayscaleToRGB, xt::data::transforms::HorizontalFlip, xt::data::transforms::Lambda, xt::data::transforms::Normalize, xt::data::transforms::Pad, xt::data::transforms::RandomCrop, xt::data::transforms::RandomCrop2, xt::data::transforms::RandomFlip, xt::data::transforms::RandomGaussianBlur, xt::data::transforms::Resize, xt::data::transforms::Rotation, xt::data::transforms::ToGray, xt::data::transforms::ToTensor, xt::data::transforms::VerticalFlip)</li> <li>out (xt::models::UNet)</li> </ul>"},{"location":"xTorch/class_members/#p","title":"p","text":"<ul> <li>PCAM (xt::data::datasets::PCAM)</li> <li>PennTreebank (xt::data::datasets::PennTreebank)</li> <li>PhotoTour (xt::data::datasets::PhotoTour)</li> <li>Places365 (xt::data::datasets::Places365)</li> <li>Pad (xt::data::transforms::Pad)</li> <li>padding (xt::data::transforms::Pad)</li> <li>pool (xt::models::DownSample, xt::models::MobileNetV3)</li> </ul>"},{"location":"xTorch/class_members/#q","title":"q","text":"<ul> <li>QMNIST (xt::data::datasets::QMNIST)</li> <li>QNLI (xt::data::datasets::QNLI)</li> <li>QQP (xt::data::datasets::QQP)</li> </ul>"},{"location":"xTorch/class_members/#r","title":"r","text":"<ul> <li>reset (xt::DataLoader)</li> <li>reset_indices (xt::DataLoader)</li> <li>root (xt::data::datasets::BaseDataset)</li> <li>resources (xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CelebA, xt::data::datasets::FashionMNIST, xt::data::datasets::INaturalist, xt::data::datasets::Imagenette, xt::data::datasets::KMNIST, xt::data::datasets::Kitti, xt::data::datasets::MNIST, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PhotoTour, xt::data::datasets::QMNIST, xt::data::datasets::SVHN, xt::data::datasets::USPS, xt::data::datasets::WIDERFace)</li> <li>read_images (xt::data::datasets::MNISTBase)</li> <li>read_labels (xt::data::datasets::MNISTBase)</li> <li>RTE (xt::data::datasets::RTE)</li> <li>RenderedSST2 (xt::data::datasets::RenderedSST2)</li> <li>RandomCrop (xt::data::transforms::RandomCrop)</li> <li>RandomCrop2 (xt::data::transforms::RandomCrop2)</li> <li>RandomFlip (xt::data::transforms::RandomFlip)</li> <li>RandomGaussianBlur (xt::data::transforms::RandomGaussianBlur)</li> <li>Resize (xt::data::transforms::Resize)</li> <li>Rotation (xt::data::transforms::Rotation)</li> <li>relu6 (xt::models::HSigmoid, xt::models::HSwish)</li> <li>ResNet (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_members/#s","title":"s","text":"<ul> <li>shuffle_ (xt::DataLoader)</li> <li>set_loss_fn (xt::Trainer)</li> <li>set_max_epochs (xt::Trainer)</li> <li>set_optimizer (xt::Trainer)</li> <li>size (xt::data::datasets::AudioDataset, xt::data::datasets::BaseDataset, xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::transforms::CenterCrop, xt::data::transforms::RandomCrop, xt::data::transforms::Resize)</li> <li>shape_ (xt::data::datasets::FakeData)</li> <li>size_ (xt::data::datasets::FakeData)</li> <li>SBDataset (xt::data::datasets::SBDataset)</li> <li>SBU (xt::data::datasets::SBU)</li> <li>SEMEION (xt::data::datasets::SEMEION)</li> <li>SNLI (xt::data::datasets::SNLI)</li> <li>SST (xt::data::datasets::SST)</li> <li>STL10 (xt::data::datasets::STL10)</li> <li>splits (xt::data::datasets::STL10)</li> <li>STSB (xt::data::datasets::STSB)</li> <li>SUN397 (xt::data::datasets::SUN397)</li> <li>SVHN (xt::data::datasets::SVHN)</li> <li>SceneFlowStereo (xt::data::datasets::SceneFlowStereo)</li> <li>Sintel (xt::data::datasets::Sintel)</li> <li>SintelStereo (xt::data::datasets::SintelStereo)</li> <li>SogouNews (xt::data::datasets::SogouNews)</li> <li>SpeechCommands (xt::data::datasets::SpeechCommands)</li> <li>StackedAudioDataset (xt::data::datasets::StackedAudioDataset)</li> <li>StackedCSVDataset (xt::data::datasets::StackedCSVDataset)</li> <li>StackedEDFDataset (xt::data::datasets::StackedEDFDataset)</li> <li>StackedTextDataset (xt::data::datasets::StackedTextDataset)</li> <li>StackedTimeSeriesDataset (xt::data::datasets::StackedTimeSeriesDataset)</li> <li>StackedVideoDataset (xt::data::datasets::StackedVideoDataset)</li> <li>StanfordCars (xt::data::datasets::StanfordCars)</li> <li>saturation (xt::data::transforms::ColorJitter)</li> <li>sigma (xt::data::transforms::GaussianBlur, xt::data::transforms::GaussianBlurOpenCV)</li> <li>std (xt::data::transforms::GaussianNoise, xt::data::transforms::Normalize)</li> <li>sigma_max (xt::data::transforms::RandomGaussianBlur)</li> <li>sigma_min (xt::data::transforms::RandomGaussianBlur)</li> <li>SE (xt::models::SqueezeExcite)</li> <li>SqueezeExcite (xt::models::SqueezeExcite)</li> </ul>"},{"location":"xTorch/class_members/#t","title":"t","text":"<ul> <li>transforms (DatasetArguments, xt::data::datasets::BaseDataset, xt::data::transforms::Compose)</li> <li>Trainer (xt::Trainer)</li> <li>TransformType (xt::data::datasets::BaseDataset)</li> <li>test_file_name (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100)</li> <li>train_file_names (xt::data::datasets::CIFAR10)</li> <li>train_file_name (xt::data::datasets::CIFAR100)</li> <li>type (xt::data::datasets::Imagenette)</li> <li>transform_data (xt::data::datasets::MNIST)</li> <li>t (xt::data::datasets::PCAM)</li> <li>test_list (xt::data::datasets::STL10)</li> <li>train_list (xt::data::datasets::STL10)</li> <li>TIMIT (xt::data::datasets::TIMIT)</li> <li>Tedlium (xt::data::datasets::Tedlium)</li> <li>TensorDataset (xt::data::datasets::TensorDataset)</li> <li>TextDataset (xt::data::datasets::TextDataset)</li> <li>TimeSeriesDataset (xt::data::datasets::TimeSeriesDataset)</li> <li>TransformFunc (xt::data::transforms::Compose)</li> <li>transform (xt::data::transforms::Lambda)</li> <li>TestDataset (xt::temp::TestDataset)</li> </ul>"},{"location":"xTorch/class_members/#u","title":"u","text":"<ul> <li>url (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::Country211, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Food101, xt::data::datasets::KMNIST, xt::data::datasets::Kitti, xt::data::datasets::LFW, xt::data::datasets::MNIST, xt::data::datasets::MovingMNIST, xt::data::datasets::QMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBDataset, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397)</li> <li>UCF101 (xt::data::datasets::UCF101)</li> <li>UDPOS (xt::data::datasets::UDPOS)</li> <li>USPS (xt::data::datasets::USPS)</li> <li>UrbanSound (xt::data::datasets::UrbanSound)</li> <li>UNet (xt::models::UNet)</li> <li>up_convolution_1 (xt::models::UNet)</li> <li>up_convolution_2 (xt::models::UNet)</li> <li>up_convolution_3 (xt::models::UNet)</li> <li>up_convolution_4 (xt::models::UNet)</li> <li>UpSample (xt::models::UpSample)</li> <li>up (xt::models::UpSample)</li> </ul>"},{"location":"xTorch/class_members/#v","title":"v","text":"<ul> <li>voc_split_filename (xt::data::datasets::SBDataset)</li> <li>voc_split_md5 (xt::data::datasets::SBDataset)</li> <li>voc_train_url (xt::data::datasets::SBDataset)</li> <li>VCTK (xt::data::datasets::VCTK)</li> <li>VOCDetection (xt::data::datasets::VOCDetection)</li> <li>VOCSegmentation (xt::data::datasets::VOCSegmentation)</li> <li>VideoDataset (xt::data::datasets::VideoDataset)</li> <li>VoxCeleb (xt::data::datasets::VoxCeleb)</li> <li>vertical_prob (xt::data::transforms::RandomFlip)</li> <li>VerticalFlip (xt::data::transforms::VerticalFlip)</li> <li>VggNet16 (xt::models::VggNet16)</li> </ul>"},{"location":"xTorch/class_members/#w","title":"w","text":"<ul> <li>WIDERFace (xt::data::datasets::WIDERFace)</li> <li>WMT (xt::data::datasets::WMT)</li> <li>WNLI (xt::data::datasets::WNLI)</li> <li>WikiText (xt::data::datasets::WikiText)</li> </ul>"},{"location":"xTorch/class_members/#x","title":"x","text":"<ul> <li>x_indices (xt::data::datasets::CSVDataset)</li> </ul>"},{"location":"xTorch/class_members/#y","title":"y","text":"<ul> <li>y_indices (xt::data::datasets::CSVDataset)</li> <li>YahooAnswers (xt::data::datasets::YahooAnswers)</li> <li>YelpReview (xt::data::datasets::YelpReview)</li> <li>YesNo (xt::data::datasets::YesNo)</li> </ul>"},{"location":"xTorch/class_members/#_","title":"_","text":"<ul> <li>_VALID_TARGET_TYPES (xt::data::datasets::OxfordIIITPet)</li> </ul>"},{"location":"xTorch/class_member_functions/","title":"Class Member Functions","text":""},{"location":"xTorch/class_member_functions/#a","title":"a","text":"<ul> <li>AgNews (xt::data::datasets::AgNews)</li> <li>AmazonReview (xt::data::datasets::AmazonReview)</li> <li>AudioDataset (xt::data::datasets::AudioDataset)</li> <li>AlexNet (xt::models::AlexNet)</li> </ul>"},{"location":"xTorch/class_member_functions/#b","title":"b","text":"<ul> <li>BaseDataset (xt::data::datasets::BaseDataset)</li> <li>BaseModel (xt::models::BaseModel)</li> <li>Bottleneck (xt::models::Bottleneck)</li> </ul>"},{"location":"xTorch/class_member_functions/#c","title":"c","text":"<ul> <li>check_resources (xt::data::datasets::AgNews, xt::data::datasets::AmazonReview, xt::data::datasets::CMUArctic, xt::data::datasets::COLA, xt::data::datasets::CREStereo, xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CarlaStereo, xt::data::datasets::CelebA, xt::data::datasets::Cityscapes, xt::data::datasets::CoNLL2000Chunking, xt::data::datasets::CocoCaptions, xt::data::datasets::CocoDetection, xt::data::datasets::CommonVoice, xt::data::datasets::CremaD, xt::data::datasets::DBPedia, xt::data::datasets::DTD, xt::data::datasets::EMNIST, xt::data::datasets::ESC, xt::data::datasets::ETH3DStereo, xt::data::datasets::EnWik, xt::data::datasets::EuroSAT, xt::data::datasets::FER2013, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Flickr30k, xt::data::datasets::Flickr8k, xt::data::datasets::Flowers102, xt::data::datasets::FlyingChairs, xt::data::datasets::FlyingThings3D, xt::data::datasets::Food101, xt::data::datasets::GTSRB, xt::data::datasets::GTZAN, xt::data::datasets::HD1K, xt::data::datasets::HMDB51, xt::data::datasets::IMDB, xt::data::datasets::INaturalist, xt::data::datasets::IWSLT, xt::data::datasets::ImageNet, xt::data::datasets::Imagenette, xt::data::datasets::InStereo2k, xt::data::datasets::KMNIST, xt::data::datasets::Kinetics, xt::data::datasets::Kitti, xt::data::datasets::Kitti2012Stereo, xt::data::datasets::Kitti2015Stereo, xt::data::datasets::KittiFlow, xt::data::datasets::LFW, xt::data::datasets::LFWPairs, xt::data::datasets::LFWPeople, xt::data::datasets::LSUN, xt::data::datasets::LibriSpeech, xt::data::datasets::LjSpeech, xt::data::datasets::MNIST, xt::data::datasets::MNLI, xt::data::datasets::MRPC, xt::data::datasets::MULTI, xt::data::datasets::Middlebury2014Stereo, xt::data::datasets::MovingMNIST, xt::data::datasets::Omniglot, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PennTreebank, xt::data::datasets::PhotoTour, xt::data::datasets::Places365, xt::data::datasets::QMNIST, xt::data::datasets::QNLI, xt::data::datasets::QQP, xt::data::datasets::RTE, xt::data::datasets::RenderedSST2, xt::data::datasets::SBDataset, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::SNLI, xt::data::datasets::SST, xt::data::datasets::STL10, xt::data::datasets::STSB, xt::data::datasets::SUN397, xt::data::datasets::SVHN, xt::data::datasets::SceneFlowStereo, xt::data::datasets::Sintel, xt::data::datasets::SintelStereo, xt::data::datasets::SogouNews, xt::data::datasets::SpeechCommands, xt::data::datasets::StanfordCars, xt::data::datasets::TIMIT, xt::data::datasets::Tedlium, xt::data::datasets::UCF101, xt::data::datasets::UDPOS, xt::data::datasets::USPS, xt::data::datasets::UrbanSound, xt::data::datasets::VCTK, xt::data::datasets::VOCDetection, xt::data::datasets::VOCSegmentation, xt::data::datasets::VoxCeleb, xt::data::datasets::WIDERFace, xt::data::datasets::WMT, xt::data::datasets::WNLI, xt::data::datasets::WikiText, xt::data::datasets::YahooAnswers, xt::data::datasets::YelpReview, xt::data::datasets::YesNo)</li> <li>CIFAR10 (xt::data::datasets::CIFAR10)</li> <li>CIFAR100 (xt::data::datasets::CIFAR100)</li> <li>CMUArctic (xt::data::datasets::CMUArctic)</li> <li>COLA (xt::data::datasets::COLA)</li> <li>CREStereo (xt::data::datasets::CREStereo)</li> <li>CSVDataset (xt::data::datasets::CSVDataset)</li> <li>Caltech101 (xt::data::datasets::Caltech101)</li> <li>Caltech256 (xt::data::datasets::Caltech256)</li> <li>CarlaStereo (xt::data::datasets::CarlaStereo)</li> <li>CelebA (xt::data::datasets::CelebA)</li> <li>Cityscapes (xt::data::datasets::Cityscapes)</li> <li>CoNLL2000Chunking (xt::data::datasets::CoNLL2000Chunking)</li> <li>CocoCaptions (xt::data::datasets::CocoCaptions)</li> <li>CocoDetection (xt::data::datasets::CocoDetection)</li> <li>CommonVoice (xt::data::datasets::CommonVoice)</li> <li>Country211 (xt::data::datasets::Country211)</li> <li>CremaD (xt::data::datasets::CremaD)</li> <li>CenterCrop (xt::data::transforms::CenterCrop)</li> <li>ColorJitter (xt::data::transforms::ColorJitter)</li> <li>Compose (xt::data::transforms::Compose)</li> <li>Cutout (xt::data::transforms::Cutout)</li> </ul>"},{"location":"xTorch/class_member_functions/#d","title":"d","text":"<ul> <li>DataLoader (xt::DataLoader)</li> <li>DBPedia (xt::data::datasets::DBPedia)</li> <li>DTD (xt::data::datasets::DTD)</li> <li>DoubleConv (xt::models::DoubleConv)</li> <li>DownSample (xt::models::DownSample)</li> </ul>"},{"location":"xTorch/class_member_functions/#e","title":"e","text":"<ul> <li>enable_checkpoint (xt::Trainer)</li> <li>EDFDataset (xt::data::datasets::EDFDataset)</li> <li>EMNIST (xt::data::datasets::EMNIST)</li> <li>ESC (xt::data::datasets::ESC)</li> <li>ETH3DStereo (xt::data::datasets::ETH3DStereo)</li> <li>EnWik (xt::data::datasets::EnWik)</li> <li>EuroSAT (xt::data::datasets::EuroSAT)</li> </ul>"},{"location":"xTorch/class_member_functions/#f","title":"f","text":"<ul> <li>fit (xt::Trainer)</li> <li>FER2013 (xt::data::datasets::FER2013)</li> <li>FGVCAircraft (xt::data::datasets::FGVCAircraft)</li> <li>FakeData (xt::data::datasets::FakeData)</li> <li>FallingThingsStereo (xt::data::datasets::FallingThingsStereo)</li> <li>FashionMNIST (xt::data::datasets::FashionMNIST)</li> <li>Flickr30k (xt::data::datasets::Flickr30k)</li> <li>Flickr8k (xt::data::datasets::Flickr8k)</li> <li>Flowers102 (xt::data::datasets::Flowers102)</li> <li>FlyingChairs (xt::data::datasets::FlyingChairs)</li> <li>FlyingThings3D (xt::data::datasets::FlyingThings3D)</li> <li>Food101 (xt::data::datasets::Food101)</li> <li>forward (xt::models::AlexNet, xt::models::BaseModel, xt::models::Bottleneck, xt::models::DoubleConv, xt::models::DownSample, xt::models::HSigmoid, xt::models::HSwish, xt::models::LeNet5, xt::models::MobileNetV3, xt::models::Model, xt::models::ResNet, xt::models::SqueezeExcite, xt::models::UNet, xt::models::UpSample, xt::models::VggNet16, xt::temp::TestDataset)</li> </ul>"},{"location":"xTorch/class_member_functions/#g","title":"g","text":"<ul> <li>get_batch_request (xt::DataLoader)</li> <li>get (xt::data::datasets::AudioDataset, xt::data::datasets::BaseDataset, xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100)</li> <li>generate_data (xt::data::datasets::FakeData)</li> <li>GTSRB (xt::data::datasets::GTSRB)</li> <li>GTZAN (xt::data::datasets::GTZAN)</li> <li>GaussianBlur (xt::data::transforms::GaussianBlur)</li> <li>generate_gaussian_kernel (xt::data::transforms::GaussianBlur)</li> <li>GaussianBlurOpenCV (xt::data::transforms::GaussianBlurOpenCV)</li> <li>GaussianNoise (xt::data::transforms::GaussianNoise)</li> <li>Grayscale (xt::data::transforms::Grayscale)</li> </ul>"},{"location":"xTorch/class_member_functions/#h","title":"h","text":"<ul> <li>HD1K (xt::data::datasets::HD1K)</li> <li>HMDB51 (xt::data::datasets::HMDB51)</li> <li>HorizontalFlip (xt::data::transforms::HorizontalFlip)</li> <li>HSigmoid (xt::models::HSigmoid)</li> <li>HSwish (xt::models::HSwish)</li> </ul>"},{"location":"xTorch/class_member_functions/#i","title":"i","text":"<ul> <li>IMDB (xt::data::datasets::IMDB)</li> <li>INaturalist (xt::data::datasets::INaturalist)</li> <li>IWSLT (xt::data::datasets::IWSLT)</li> <li>ImageFolder (xt::data::datasets::ImageFolder)</li> <li>ImageNet (xt::data::datasets::ImageNet)</li> <li>Imagenette (xt::data::datasets::Imagenette)</li> <li>InStereo2k (xt::data::datasets::InStereo2k)</li> </ul>"},{"location":"xTorch/class_member_functions/#k","title":"k","text":"<ul> <li>KMNIST (xt::data::datasets::KMNIST)</li> <li>Kinetics (xt::data::datasets::Kinetics)</li> <li>Kitti (xt::data::datasets::Kitti)</li> <li>Kitti2012Stereo (xt::data::datasets::Kitti2012Stereo)</li> <li>Kitti2015Stereo (xt::data::datasets::Kitti2015Stereo)</li> <li>KittiFlow (xt::data::datasets::KittiFlow)</li> </ul>"},{"location":"xTorch/class_member_functions/#l","title":"l","text":"<ul> <li>load_data (xt::data::datasets::AgNews, xt::data::datasets::AmazonReview, xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::CMUArctic, xt::data::datasets::COLA, xt::data::datasets::CREStereo, xt::data::datasets::CSVDataset, xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CarlaStereo, xt::data::datasets::CelebA, xt::data::datasets::Cityscapes, xt::data::datasets::CoNLL2000Chunking, xt::data::datasets::CocoCaptions, xt::data::datasets::CocoDetection, xt::data::datasets::CommonVoice, xt::data::datasets::CremaD, xt::data::datasets::DBPedia, xt::data::datasets::DTD, xt::data::datasets::EDFDataset, xt::data::datasets::EMNIST, xt::data::datasets::ESC, xt::data::datasets::ETH3DStereo, xt::data::datasets::EnWik, xt::data::datasets::EuroSAT, xt::data::datasets::FER2013, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Flickr30k, xt::data::datasets::Flickr8k, xt::data::datasets::Flowers102, xt::data::datasets::FlyingChairs, xt::data::datasets::FlyingThings3D, xt::data::datasets::Food101, xt::data::datasets::GTSRB, xt::data::datasets::GTZAN, xt::data::datasets::HD1K, xt::data::datasets::HMDB51, xt::data::datasets::IMDB, xt::data::datasets::INaturalist, xt::data::datasets::IWSLT, xt::data::datasets::ImageFolder, xt::data::datasets::ImageNet, xt::data::datasets::Imagenette, xt::data::datasets::InStereo2k, xt::data::datasets::KMNIST, xt::data::datasets::Kinetics, xt::data::datasets::Kitti, xt::data::datasets::Kitti2012Stereo, xt::data::datasets::Kitti2015Stereo, xt::data::datasets::KittiFlow, xt::data::datasets::LFW, xt::data::datasets::LFWPairs, xt::data::datasets::LFWPeople, xt::data::datasets::LSUN, xt::data::datasets::LibriSpeech, xt::data::datasets::LjSpeech, xt::data::datasets::MNIST, xt::data::datasets::MNLI, xt::data::datasets::MRPC, xt::data::datasets::MULTI, xt::data::datasets::Middlebury2014Stereo, xt::data::datasets::MovingMNIST, xt::data::datasets::Omniglot, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PennTreebank, xt::data::datasets::PhotoTour, xt::data::datasets::Places365, xt::data::datasets::QMNIST, xt::data::datasets::QNLI, xt::data::datasets::QQP, xt::data::datasets::RTE, xt::data::datasets::RenderedSST2, xt::data::datasets::SBDataset, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::SNLI, xt::data::datasets::SST, xt::data::datasets::STL10, xt::data::datasets::STSB, xt::data::datasets::SUN397, xt::data::datasets::SVHN, xt::data::datasets::SceneFlowStereo, xt::data::datasets::Sintel, xt::data::datasets::SintelStereo, xt::data::datasets::SogouNews, xt::data::datasets::SpeechCommands, xt::data::datasets::StackedAudioDataset, xt::data::datasets::StackedCSVDataset, xt::data::datasets::StackedEDFDataset, xt::data::datasets::StackedTextDataset, xt::data::datasets::StackedTimeSeriesDataset, xt::data::datasets::StackedVideoDataset, xt::data::datasets::StanfordCars, xt::data::datasets::TIMIT, xt::data::datasets::Tedlium, xt::data::datasets::TensorDataset, xt::data::datasets::TextDataset, xt::data::datasets::TimeSeriesDataset, xt::data::datasets::UCF101, xt::data::datasets::UDPOS, xt::data::datasets::USPS, xt::data::datasets::UrbanSound, xt::data::datasets::VCTK, xt::data::datasets::VOCDetection, xt::data::datasets::VOCSegmentation, xt::data::datasets::VideoDataset, xt::data::datasets::VoxCeleb, xt::data::datasets::WIDERFace, xt::data::datasets::WMT, xt::data::datasets::WNLI, xt::data::datasets::WikiText, xt::data::datasets::YahooAnswers, xt::data::datasets::YelpReview, xt::data::datasets::YesNo)</li> <li>load_classes (xt::data::datasets::Food101)</li> <li>LFW (xt::data::datasets::LFW)</li> <li>LFWPairs (xt::data::datasets::LFWPairs)</li> <li>LFWPeople (xt::data::datasets::LFWPeople)</li> <li>LSUN (xt::data::datasets::LSUN)</li> <li>LibriSpeech (xt::data::datasets::LibriSpeech)</li> <li>LjSpeech (xt::data::datasets::LjSpeech)</li> <li>Lambda (xt::data::transforms::Lambda)</li> <li>LeNet5 (xt::models::LeNet5)</li> </ul>"},{"location":"xTorch/class_member_functions/#m","title":"m","text":"<ul> <li>MNIST (xt::data::datasets::MNIST)</li> <li>MNISTBase (xt::data::datasets::MNISTBase)</li> <li>MNLI (xt::data::datasets::MNLI)</li> <li>MRPC (xt::data::datasets::MRPC)</li> <li>MULTI (xt::data::datasets::MULTI)</li> <li>Middlebury2014Stereo (xt::data::datasets::Middlebury2014Stereo)</li> <li>MovingMNIST (xt::data::datasets::MovingMNIST)</li> <li>MobileNetV3 (xt::models::MobileNetV3)</li> <li>Model (xt::models::Model)</li> <li>makeLayerFromResidualBlock (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_member_functions/#n","title":"n","text":"<ul> <li>NotImplementedException (NotImplementedException)</li> <li>Normalize (xt::data::transforms::Normalize)</li> </ul>"},{"location":"xTorch/class_member_functions/#o","title":"o","text":"<ul> <li>Omniglot (xt::data::datasets::Omniglot)</li> <li>OxfordIIITPet (xt::data::datasets::OxfordIIITPet)</li> <li>operator() (xt::data::transforms::CenterCrop, xt::data::transforms::ColorJitter, xt::data::transforms::Compose, xt::data::transforms::Cutout, xt::data::transforms::GaussianBlur, xt::data::transforms::GaussianBlurOpenCV, xt::data::transforms::GaussianNoise, xt::data::transforms::Grayscale, xt::data::transforms::GrayscaleToRGB, xt::data::transforms::HorizontalFlip, xt::data::transforms::Lambda, xt::data::transforms::Normalize, xt::data::transforms::Pad, xt::data::transforms::RandomCrop, xt::data::transforms::RandomCrop2, xt::data::transforms::RandomFlip, xt::data::transforms::RandomGaussianBlur, xt::data::transforms::Resize, xt::data::transforms::Rotation, xt::data::transforms::ToGray, xt::data::transforms::ToTensor, xt::data::transforms::VerticalFlip)</li> </ul>"},{"location":"xTorch/class_member_functions/#p","title":"p","text":"<ul> <li>PCAM (xt::data::datasets::PCAM)</li> <li>PennTreebank (xt::data::datasets::PennTreebank)</li> <li>PhotoTour (xt::data::datasets::PhotoTour)</li> <li>Places365 (xt::data::datasets::Places365)</li> <li>Pad (xt::data::transforms::Pad)</li> </ul>"},{"location":"xTorch/class_member_functions/#q","title":"q","text":"<ul> <li>QMNIST (xt::data::datasets::QMNIST)</li> <li>QNLI (xt::data::datasets::QNLI)</li> <li>QQP (xt::data::datasets::QQP)</li> </ul>"},{"location":"xTorch/class_member_functions/#r","title":"r","text":"<ul> <li>reset (xt::DataLoader)</li> <li>reset_indices (xt::DataLoader)</li> <li>read_images (xt::data::datasets::MNISTBase)</li> <li>read_labels (xt::data::datasets::MNISTBase)</li> <li>RTE (xt::data::datasets::RTE)</li> <li>RenderedSST2 (xt::data::datasets::RenderedSST2)</li> <li>RandomCrop (xt::data::transforms::RandomCrop)</li> <li>RandomCrop2 (xt::data::transforms::RandomCrop2)</li> <li>RandomFlip (xt::data::transforms::RandomFlip)</li> <li>RandomGaussianBlur (xt::data::transforms::RandomGaussianBlur)</li> <li>Resize (xt::data::transforms::Resize)</li> <li>Rotation (xt::data::transforms::Rotation)</li> <li>ResNet (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_member_functions/#s","title":"s","text":"<ul> <li>set_loss_fn (xt::Trainer)</li> <li>set_max_epochs (xt::Trainer)</li> <li>set_optimizer (xt::Trainer)</li> <li>size (xt::data::datasets::AudioDataset, xt::data::datasets::BaseDataset, xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100)</li> <li>SBDataset (xt::data::datasets::SBDataset)</li> <li>SBU (xt::data::datasets::SBU)</li> <li>SEMEION (xt::data::datasets::SEMEION)</li> <li>SNLI (xt::data::datasets::SNLI)</li> <li>SST (xt::data::datasets::SST)</li> <li>STL10 (xt::data::datasets::STL10)</li> <li>STSB (xt::data::datasets::STSB)</li> <li>SUN397 (xt::data::datasets::SUN397)</li> <li>SVHN (xt::data::datasets::SVHN)</li> <li>SceneFlowStereo (xt::data::datasets::SceneFlowStereo)</li> <li>Sintel (xt::data::datasets::Sintel)</li> <li>SintelStereo (xt::data::datasets::SintelStereo)</li> <li>SogouNews (xt::data::datasets::SogouNews)</li> <li>SpeechCommands (xt::data::datasets::SpeechCommands)</li> <li>StackedAudioDataset (xt::data::datasets::StackedAudioDataset)</li> <li>StackedCSVDataset (xt::data::datasets::StackedCSVDataset)</li> <li>StackedEDFDataset (xt::data::datasets::StackedEDFDataset)</li> <li>StackedTextDataset (xt::data::datasets::StackedTextDataset)</li> <li>StackedTimeSeriesDataset (xt::data::datasets::StackedTimeSeriesDataset)</li> <li>StackedVideoDataset (xt::data::datasets::StackedVideoDataset)</li> <li>StanfordCars (xt::data::datasets::StanfordCars)</li> <li>SqueezeExcite (xt::models::SqueezeExcite)</li> </ul>"},{"location":"xTorch/class_member_functions/#t","title":"t","text":"<ul> <li>Trainer (xt::Trainer)</li> <li>transform_data (xt::data::datasets::MNIST)</li> <li>TIMIT (xt::data::datasets::TIMIT)</li> <li>Tedlium (xt::data::datasets::Tedlium)</li> <li>TensorDataset (xt::data::datasets::TensorDataset)</li> <li>TextDataset (xt::data::datasets::TextDataset)</li> <li>TimeSeriesDataset (xt::data::datasets::TimeSeriesDataset)</li> <li>TestDataset (xt::temp::TestDataset)</li> </ul>"},{"location":"xTorch/class_member_functions/#u","title":"u","text":"<ul> <li>UCF101 (xt::data::datasets::UCF101)</li> <li>UDPOS (xt::data::datasets::UDPOS)</li> <li>USPS (xt::data::datasets::USPS)</li> <li>UrbanSound (xt::data::datasets::UrbanSound)</li> <li>UNet (xt::models::UNet)</li> <li>UpSample (xt::models::UpSample)</li> </ul>"},{"location":"xTorch/class_member_functions/#v","title":"v","text":"<ul> <li>VCTK (xt::data::datasets::VCTK)</li> <li>VOCDetection (xt::data::datasets::VOCDetection)</li> <li>VOCSegmentation (xt::data::datasets::VOCSegmentation)</li> <li>VideoDataset (xt::data::datasets::VideoDataset)</li> <li>VoxCeleb (xt::data::datasets::VoxCeleb)</li> <li>VerticalFlip (xt::data::transforms::VerticalFlip)</li> <li>VggNet16 (xt::models::VggNet16)</li> </ul>"},{"location":"xTorch/class_member_functions/#w","title":"w","text":"<ul> <li>WIDERFace (xt::data::datasets::WIDERFace)</li> <li>WMT (xt::data::datasets::WMT)</li> <li>WNLI (xt::data::datasets::WNLI)</li> <li>WikiText (xt::data::datasets::WikiText)</li> </ul>"},{"location":"xTorch/class_member_functions/#y","title":"y","text":"<ul> <li>YahooAnswers (xt::data::datasets::YahooAnswers)</li> <li>YelpReview (xt::data::datasets::YelpReview)</li> <li>YesNo (xt::data::datasets::YesNo)</li> </ul>"},{"location":"xTorch/class_member_variables/","title":"Class Member Variables","text":""},{"location":"xTorch/class_member_variables/#a","title":"a","text":"<ul> <li>archive_file_md5 (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT, xt::data::datasets::QMNIST)</li> <li>archive_file_name (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT)</li> <li>annot_file (xt::data::datasets::LFW)</li> <li>ANNOTATIONS_FILE (xt::data::datasets::WIDERFace)</li> <li>angle (xt::data::transforms::Rotation)</li> <li>a (xt::models::Model)</li> <li>avgpool (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#b","title":"b","text":"<ul> <li>batch_size_ (xt::DataLoader)</li> <li>brightness (xt::data::transforms::ColorJitter)</li> <li>bottleneck (xt::models::Bottleneck)</li> <li>bottlenecks (xt::models::MobileNetV3)</li> <li>bottle_neck (xt::models::UNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#c","title":"c","text":"<ul> <li>current_index_ (xt::DataLoader)</li> <li>checkpoint_enabled_ (xt::Trainer)</li> <li>checkpoint_interval_ (xt::Trainer)</li> <li>checkpoint_path_ (xt::Trainer)</li> <li>compose (xt::data::datasets::BaseDataset)</li> <li>classes_map (xt::data::datasets::Food101)</li> <li>classes_name (xt::data::datasets::Food101)</li> <li>checksums (xt::data::datasets::LFW)</li> <li>class_names_file (xt::data::datasets::STL10)</li> <li>contrast (xt::data::transforms::ColorJitter)</li> <li>crop_height (xt::data::transforms::RandomCrop2)</li> <li>crop_width (xt::data::transforms::RandomCrop2)</li> <li>conv_op (xt::models::DoubleConv)</li> <li>conv (xt::models::DownSample, xt::models::UpSample)</li> <li>classifier (xt::models::MobileNetV3)</li> <li>conv1 (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#d","title":"d","text":"<ul> <li>download (DatasetArguments, xt::data::datasets::BaseDataset)</li> <li>dataset_ptr_ (xt::DataLoader)</li> <li>drop_last_ (xt::DataLoader)</li> <li>data (xt::data::datasets::BaseDataset)</li> <li>dataset_path (xt::data::datasets::BaseDataset, xt::data::datasets::QMNIST)</li> <li>dataset_folder_name (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CelebA, xt::data::datasets::Country211, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Food101, xt::data::datasets::INaturalist, xt::data::datasets::Imagenette, xt::data::datasets::KMNIST, xt::data::datasets::Kitti, xt::data::datasets::LFW, xt::data::datasets::MNIST, xt::data::datasets::Middlebury2014Stereo, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PhotoTour, xt::data::datasets::QMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397, xt::data::datasets::SceneFlowStereo, xt::data::datasets::WIDERFace)</li> <li>dataset_file_md5 (xt::data::datasets::Country211, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::Food101, xt::data::datasets::MovingMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397)</li> <li>dataset_file_name (xt::data::datasets::Country211, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::Food101, xt::data::datasets::MovingMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397)</li> <li>downsample (xt::models::Bottleneck)</li> <li>down_convolution_1 (xt::models::UNet)</li> <li>down_convolution_2 (xt::models::UNet)</li> <li>down_convolution_3 (xt::models::UNet)</li> <li>down_convolution_4 (xt::models::UNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#f","title":"f","text":"<ul> <li>file_paths (xt::data::datasets::AudioDataset)</li> <li>files (xt::data::datasets::FashionMNIST, xt::data::datasets::KMNIST, xt::data::datasets::MNIST)</li> <li>file_dict (xt::data::datasets::LFW)</li> <li>filename (xt::data::datasets::SBDataset)</li> <li>folds_list_file (xt::data::datasets::STL10)</li> <li>fc (xt::models::AlexNet, xt::models::ResNet, xt::models::VggNet16)</li> <li>fc1 (xt::models::AlexNet, xt::models::LeNet5, xt::models::VggNet16)</li> <li>fc2 (xt::models::AlexNet, xt::models::LeNet5, xt::models::VggNet16)</li> <li>fc3 (xt::models::LeNet5)</li> <li>final_conv (xt::models::MobileNetV3)</li> </ul>"},{"location":"xTorch/class_member_variables/#h","title":"h","text":"<ul> <li>hole_size (xt::data::transforms::Cutout)</li> <li>horizontal_prob (xt::data::transforms::RandomFlip)</li> </ul>"},{"location":"xTorch/class_member_variables/#i","title":"i","text":"<ul> <li>indices_ (xt::DataLoader)</li> <li>images_number (xt::data::datasets::Food101)</li> <li>image_dir_name (xt::data::datasets::Kitti)</li> <li>initial_conv (xt::models::MobileNetV3)</li> <li>inplanes (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#k","title":"k","text":"<ul> <li>kernel_size (xt::data::transforms::GaussianBlur, xt::data::transforms::GaussianBlurOpenCV)</li> <li>kernel_sizes (xt::data::transforms::RandomGaussianBlur)</li> </ul>"},{"location":"xTorch/class_member_variables/#l","title":"l","text":"<ul> <li>loss_fn_ (xt::Trainer)</li> <li>labels (xt::data::datasets::AudioDataset, xt::data::datasets::BaseDataset)</li> <li>labels_name (xt::data::datasets::CSVDataset, xt::data::datasets::EDFDataset, xt::data::datasets::ImageFolder, xt::data::datasets::Imagenette, xt::data::datasets::StackedAudioDataset, xt::data::datasets::StackedCSVDataset, xt::data::datasets::StackedEDFDataset, xt::data::datasets::StackedTextDataset, xt::data::datasets::StackedTimeSeriesDataset, xt::data::datasets::StackedVideoDataset, xt::data::datasets::TensorDataset, xt::data::datasets::TextDataset, xt::data::datasets::TimeSeriesDataset, xt::data::datasets::VideoDataset)</li> <li>load_sub_folders (xt::data::datasets::CSVDataset, xt::data::datasets::EDFDataset, xt::data::datasets::ImageFolder, xt::data::datasets::StackedAudioDataset, xt::data::datasets::StackedCSVDataset, xt::data::datasets::StackedEDFDataset, xt::data::datasets::StackedTextDataset, xt::data::datasets::StackedTimeSeriesDataset, xt::data::datasets::StackedVideoDataset, xt::data::datasets::TensorDataset, xt::data::datasets::TextDataset, xt::data::datasets::TimeSeriesDataset, xt::data::datasets::VideoDataset)</li> <li>label_type (xt::data::datasets::ImageFolder)</li> <li>labels_dir_name (xt::data::datasets::Kitti)</li> <li>layer1 (xt::models::AlexNet, xt::models::LeNet5, xt::models::ResNet, xt::models::VggNet16)</li> <li>layer2 (xt::models::AlexNet, xt::models::LeNet5, xt::models::ResNet, xt::models::VggNet16)</li> <li>layer3 (xt::models::AlexNet, xt::models::ResNet, xt::models::VggNet16)</li> <li>layer4 (xt::models::AlexNet, xt::models::VggNet16)</li> <li>layer5 (xt::models::AlexNet, xt::models::VggNet16)</li> <li>layer0 (xt::models::ResNet)</li> <li>layer10 (xt::models::VggNet16)</li> <li>layer11 (xt::models::VggNet16)</li> <li>layer12 (xt::models::VggNet16)</li> <li>layer13 (xt::models::VggNet16)</li> <li>layer6 (xt::models::VggNet16)</li> <li>layer7 (xt::models::VggNet16)</li> <li>layer8 (xt::models::VggNet16)</li> <li>layer9 (xt::models::VggNet16)</li> </ul>"},{"location":"xTorch/class_member_variables/#m","title":"m","text":"<ul> <li>mode (DatasetArguments, xt::data::datasets::BaseDataset)</li> <li>max_epochs_ (xt::Trainer)</li> <li>md5 (xt::data::datasets::SBDataset)</li> <li>mean (xt::data::transforms::GaussianNoise, xt::data::transforms::Normalize)</li> <li>maxpool (xt::models::ResNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#n","title":"n","text":"<ul> <li>names (xt::data::datasets::LFW)</li> <li>num_holes (xt::data::transforms::Cutout)</li> </ul>"},{"location":"xTorch/class_member_variables/#o","title":"o","text":"<ul> <li>optimizer_ (xt::Trainer)</li> <li>out (xt::models::UNet)</li> </ul>"},{"location":"xTorch/class_member_variables/#p","title":"p","text":"<ul> <li>padding (xt::data::transforms::Pad)</li> <li>pool (xt::models::DownSample, xt::models::MobileNetV3)</li> </ul>"},{"location":"xTorch/class_member_variables/#r","title":"r","text":"<ul> <li>root (xt::data::datasets::BaseDataset)</li> <li>resources (xt::data::datasets::Caltech101, xt::data::datasets::Caltech256, xt::data::datasets::CelebA, xt::data::datasets::FashionMNIST, xt::data::datasets::INaturalist, xt::data::datasets::Imagenette, xt::data::datasets::KMNIST, xt::data::datasets::Kitti, xt::data::datasets::MNIST, xt::data::datasets::OxfordIIITPet, xt::data::datasets::PCAM, xt::data::datasets::PhotoTour, xt::data::datasets::QMNIST, xt::data::datasets::SVHN, xt::data::datasets::USPS, xt::data::datasets::WIDERFace)</li> <li>relu6 (xt::models::HSigmoid, xt::models::HSwish)</li> </ul>"},{"location":"xTorch/class_member_variables/#s","title":"s","text":"<ul> <li>shuffle_ (xt::DataLoader)</li> <li>shape_ (xt::data::datasets::FakeData)</li> <li>size_ (xt::data::datasets::FakeData)</li> <li>splits (xt::data::datasets::STL10)</li> <li>size (xt::data::transforms::CenterCrop, xt::data::transforms::RandomCrop, xt::data::transforms::Resize)</li> <li>saturation (xt::data::transforms::ColorJitter)</li> <li>sigma (xt::data::transforms::GaussianBlur, xt::data::transforms::GaussianBlurOpenCV)</li> <li>std (xt::data::transforms::GaussianNoise, xt::data::transforms::Normalize)</li> <li>sigma_max (xt::data::transforms::RandomGaussianBlur)</li> <li>sigma_min (xt::data::transforms::RandomGaussianBlur)</li> <li>SE (xt::models::SqueezeExcite)</li> </ul>"},{"location":"xTorch/class_member_variables/#t","title":"t","text":"<ul> <li>transforms (DatasetArguments, xt::data::datasets::BaseDataset, xt::data::transforms::Compose)</li> <li>test_file_name (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100)</li> <li>train_file_names (xt::data::datasets::CIFAR10)</li> <li>train_file_name (xt::data::datasets::CIFAR100)</li> <li>type (xt::data::datasets::Imagenette)</li> <li>t (xt::data::datasets::PCAM)</li> <li>test_list (xt::data::datasets::STL10)</li> <li>train_list (xt::data::datasets::STL10)</li> <li>transform (xt::data::transforms::Lambda)</li> </ul>"},{"location":"xTorch/class_member_variables/#u","title":"u","text":"<ul> <li>url (xt::data::datasets::CIFAR10, xt::data::datasets::CIFAR100, xt::data::datasets::Country211, xt::data::datasets::EMNIST, xt::data::datasets::EuroSAT, xt::data::datasets::FGVCAircraft, xt::data::datasets::FallingThingsStereo, xt::data::datasets::FashionMNIST, xt::data::datasets::Food101, xt::data::datasets::KMNIST, xt::data::datasets::Kitti, xt::data::datasets::LFW, xt::data::datasets::MNIST, xt::data::datasets::MovingMNIST, xt::data::datasets::QMNIST, xt::data::datasets::RenderedSST2, xt::data::datasets::SBDataset, xt::data::datasets::SBU, xt::data::datasets::SEMEION, xt::data::datasets::STL10, xt::data::datasets::SUN397)</li> <li>up_convolution_1 (xt::models::UNet)</li> <li>up_convolution_2 (xt::models::UNet)</li> <li>up_convolution_3 (xt::models::UNet)</li> <li>up_convolution_4 (xt::models::UNet)</li> <li>up (xt::models::UpSample)</li> </ul>"},{"location":"xTorch/class_member_variables/#v","title":"v","text":"<ul> <li>voc_split_filename (xt::data::datasets::SBDataset)</li> <li>voc_split_md5 (xt::data::datasets::SBDataset)</li> <li>voc_train_url (xt::data::datasets::SBDataset)</li> <li>vertical_prob (xt::data::transforms::RandomFlip)</li> </ul>"},{"location":"xTorch/class_member_variables/#x","title":"x","text":"<ul> <li>x_indices (xt::data::datasets::CSVDataset)</li> </ul>"},{"location":"xTorch/class_member_variables/#y","title":"y","text":"<ul> <li>y_indices (xt::data::datasets::CSVDataset)</li> </ul>"},{"location":"xTorch/class_member_variables/#_","title":"_","text":"<ul> <li>_VALID_TARGET_TYPES (xt::data::datasets::OxfordIIITPet)</li> </ul>"},{"location":"xTorch/class_member_typedefs/","title":"Class Member Typedefs","text":""},{"location":"xTorch/class_member_typedefs/#b","title":"b","text":"<ul> <li>Base (xt::DataLoader)</li> <li>BatchRequestType (xt::DataLoader)</li> <li>BatchType (xt::DataLoader)</li> </ul>"},{"location":"xTorch/class_member_typedefs/#t","title":"t","text":"<ul> <li>TransformType (xt::data::datasets::BaseDataset)</li> <li>TransformFunc (xt::data::transforms::Compose)</li> </ul>"},{"location":"xTorch/class_member_enums/","title":"Class Member Enums","text":"<p>Nothing related to Class Member Enums found.</p>"},{"location":"xTorch/namespace_members/","title":"Namespace Members","text":""},{"location":"xTorch/namespace_members/#c","title":"c","text":"<ul> <li>convertImageToTensor (torch::ext::media::opencv)</li> <li>create_resize_transform (xt::data::transforms)</li> <li>countFiles (xt::utils::fs)</li> </ul>"},{"location":"xTorch/namespace_members/#d","title":"d","text":"<ul> <li>download (xt::utils)</li> <li>download_from_gdrive (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_members/#e","title":"e","text":"<ul> <li>extractFrames (torch::ext::media::opencv::videos)</li> <li>extractVideoFramesAsTensor (torch::ext::media::opencv::videos)</li> <li>extract (xt::utils)</li> <li>extractGzip (xt::utils)</li> <li>extractTar (xt::utils)</li> <li>extractTgz (xt::utils)</li> <li>extractXZ (xt::utils)</li> <li>extractZip (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_members/#g","title":"g","text":"<ul> <li>getImageTypeValue (xt::data::datasets)</li> <li>get_md5_checksum (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_members/#i","title":"i","text":"<ul> <li>is_transformed_dataset (xt)</li> <li>ImageType (xt::data::datasets)</li> <li>ImageTypeToString (xt::data::datasets)</li> </ul>"},{"location":"xTorch/namespace_members/#l","title":"l","text":"<ul> <li>LabelsType (xt::data::datasets)</li> </ul>"},{"location":"xTorch/namespace_members/#n","title":"n","text":"<ul> <li>normalize (xt::data::transforms)</li> </ul>"},{"location":"xTorch/namespace_members/#r","title":"r","text":"<ul> <li>resize (torch::ext::media::image, xt::data::transforms)</li> <li>resize_tensor (xt::data::transforms)</li> <li>rebuild_google_drive_link (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_members/#s","title":"s","text":"<ul> <li>split (xt::utils::string)</li> </ul>"},{"location":"xTorch/namespace_members/#t","title":"t","text":"<ul> <li>transform_dataset (xt::data)</li> <li>trim (xt::utils::string)</li> </ul>"},{"location":"xTorch/namespace_member_functions/","title":"Namespace Member Functions","text":""},{"location":"xTorch/namespace_member_functions/#c","title":"c","text":"<ul> <li>convertImageToTensor (torch::ext::media::opencv)</li> <li>create_resize_transform (xt::data::transforms)</li> <li>countFiles (xt::utils::fs)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#d","title":"d","text":"<ul> <li>download (xt::utils)</li> <li>download_from_gdrive (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#e","title":"e","text":"<ul> <li>extractFrames (torch::ext::media::opencv::videos)</li> <li>extractVideoFramesAsTensor (torch::ext::media::opencv::videos)</li> <li>extract (xt::utils)</li> <li>extractGzip (xt::utils)</li> <li>extractTar (xt::utils)</li> <li>extractTgz (xt::utils)</li> <li>extractXZ (xt::utils)</li> <li>extractZip (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#g","title":"g","text":"<ul> <li>getImageTypeValue (xt::data::datasets)</li> <li>get_md5_checksum (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#i","title":"i","text":"<ul> <li>is_transformed_dataset (xt)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#n","title":"n","text":"<ul> <li>normalize (xt::data::transforms)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#r","title":"r","text":"<ul> <li>resize (torch::ext::media::image, xt::data::transforms)</li> <li>resize_tensor (xt::data::transforms)</li> <li>rebuild_google_drive_link (xt::utils)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#s","title":"s","text":"<ul> <li>split (xt::utils::string)</li> </ul>"},{"location":"xTorch/namespace_member_functions/#t","title":"t","text":"<ul> <li>transform_dataset (xt::data)</li> <li>trim (xt::utils::string)</li> </ul>"},{"location":"xTorch/namespace_member_variables/","title":"Namespace Member Variables","text":""},{"location":"xTorch/namespace_member_variables/#i","title":"i","text":"<ul> <li>ImageTypeToString (xt::data::datasets)</li> </ul>"},{"location":"xTorch/namespace_member_typedefs/","title":"Namespace Member Typedefs","text":"<p>Nothing related to Namespace Member Typedefs found.</p>"},{"location":"xTorch/namespace_member_enums/","title":"Namespace Member Enums","text":""},{"location":"xTorch/namespace_member_enums/#i","title":"i","text":"<ul> <li>ImageType (xt::data::datasets)</li> </ul>"},{"location":"xTorch/namespace_member_enums/#l","title":"l","text":"<ul> <li>LabelsType (xt::data::datasets)</li> </ul>"},{"location":"xTorch/functions/","title":"Functions","text":"<p>Nothing related to Functions found.</p>"},{"location":"xTorch/macros/","title":"Macros","text":"<p>Nothing related to Macros found.</p>"},{"location":"xTorch/variables/","title":"Variables","text":""},{"location":"xTorch/variables/#d","title":"d","text":"<ul> <li>DataMode (enums.h)</li> </ul>"},{"location":"xTorch/links/","title":"Links","text":"<ul> <li>Related Pages</li> <li>Modules</li> <li>Class List</li> <li>Namespace ListNamespace List</li> <li>Namespace Members</li> <li>Namespace Member Functions</li> <li>Namespace Member Variables</li> <li>Namespace Member Typedefs</li> <li>Namespace Member Enumerations</li> <li>Class Index</li> <li>Class Hierarchy</li> <li>Class Members</li> <li>Class Member Functions</li> <li>Class Member Variables</li> <li>Class Member Typedefs</li> <li>Class Member Enumerations</li> <li>Files</li> <li>File Variables</li> <li>File Functions</li> <li>File Macros</li> </ul>"}]}